[{"post_id":"6a242623-b37d-496b-b3fd-56f9b8a2ae35","version":15,"title":"Reading notes: Highly Available Transactions: Virtues and Limitations","markdown_content":"For a long time I wanted to learn more about consistency models. There is a nice recap on [Jepsen's website](https://jepsen.io/consistency). Aphyr mostly references back to 2 papers, this reading note is about the one from [Bailis, Davidson, Fekete et al](http://www.vldb.org/pvldb/vol7/p181-bailis.pdf). The paper does more than only describing consistency levels, it shows that the theoretical limits of high availability and consistency levels is not yet reach.\r\n\r\n## High availability\r\n\r\nWhy does the paper focus on high availability? Since high levels of consistency require communication between nodes, applications depending on it have two limits:\r\n\r\n1. Large disruption of popular services like Reddit or Heroku originated in network partitions\r\n2. Application latency is limited by the regions where nodes are deployed\r\n\r\nMany databases offer default isolation that are relatively weak. For instance Postgres defaults to Read Committed (RC) within transactions and MySQL to Repeatable Read (RR). Since applications do not require higher levels of isolation like Serializability, one can wonder: what is the highest level of isolation we can achieve without paying the price of consensus?\r\n\r\nA system provides high availability when users contacting non-failing server eventually receives a response from that server under any network partition. Under this definition, users can contact multiple correct server during a transaction. The paper adds the definition of sticky availability: users always contact the same replica. Authors note that this is pretty much always the case for databases. So it's a low cost constraint under which systems can achieve higher consistency models.\r\n\r\nThe paper also defines some liveness properties and transactions, but I think it goes too much in details to be explained here.\r\n\r\n## Achievable ACID Isolation for high available systems\r\n\r\nThis part is really the crux of the paper, what got me to read it in the first place. It explains isolations and the anomalies they avoid.\r\n\r\n### Read Uncommitted\r\n\r\nRead uncommitted (RU) is the lowest isolation defined in [Generalized Isolation Level Definitions](http://bnrg.cs.berkeley.edu/~adj/cs262/papers/icde00.pdf). Let's consider two transactions:\r\n\r\n- T1: w_x(1) w_y(1)\r\n- T2: w_x(2) w_y(2)\r\n\r\nThe RU isolation forces all writes from transaction T1 to be applied before or after transaction T2.\r\n\r\nThe reason of this constraint is that if both transaction gets aborted, the recovery would not restore overwritten data. Let's imagine this non RU compliant application of writes with T1 being aborted then T2:\r\n\r\nw_x(1) w_x(2) T1_abort(w_x(null)) T2_abort(w_x(1))\r\n\r\nWhen T1 aborts first, it restores `null` original value of `x`. Then T2 aborts and restore the preceding value it snapshots: `1`. The resulting history would result in a \"Dirty write\": write was performed without any transactions!\r\n\r\nThis isolation level does not have any restrictions on reads. It means that transactions can read data from aborted transaction, infamous \"Dirty Reads\".\r\n\r\n### Read Committed\r\n\r\nRead Committed (RC) is the default isolation of many databases. In addition to forbid dirty writes, it ensures no dirty reads are allowed. Let's consider the following transactions running at the same time:\r\n\r\n- T1: w_x(1) w_x(2)\r\n- T2: w_x(3)\r\n- T3: r_x(a)\r\n\r\nThe possible values possible to read for the last transactions cannot be uncommitted writes. Therefor `a ∈ { null, 2, 3 }`, either no transaction is committed, it reads the last write of T1 or last write from T2.\r\n\r\nThis level of isolation is usually provided through locks, but the paper note that it could be done otherwise. Unfortunately, ANSI SQL RC also requires recency and monotonicity, which are harder to achieve in a high-level setup (especially recency).\r\n\r\n### Repeatable Read\r\n\r\nRC can still permit serializability anomalies like fuzzy reads, Repeatable Reads (RR) prevents them. Consider this example:\r\n\r\n- T1: w_x(1)\r\n- T2: w_x(2)\r\n- T3: r_x(1) r_x(a)\r\n\r\nUnder RC, `a ∈ { 1, 2 }` depending on whether T2 transaction committed. To avoid that situation, RR isolation requires that transactions are isolated from other transactions. This level of isolation is also achieveable in theory using sticky highly available transactions. It doesn't require replicas to talk to one another.\r\n\r\n*Note*: This definition of RR is not coherent for SQL standard, so the author use Item Cut Isolation (ICI) instead.\r\n\r\n### Monotonic Atomic View\r\n\r\nIsolations are not the only guarantees provided by ACID models. Monotonic Atomic View (MAV) is the atomic allows guarantees in session. If a transaction is visible to another, all writes should also be visible. Given:\r\n\r\n- T1: w_x(1) w_y(1) w_z(1)\r\n- T2: r_x(a) r_y(1) r_x(b) w_z(c)\r\n\r\nUnder RC, `a, b, c  ∈ { null, 1 }` but MAV inforces that `b = c = 1`. This is required by the atomicity: either all operations in a transaction occured or none. Note that Postgres respects MAV under at RC level.\r\n\r\nThis level of guarantee is trivial to achieve in a single node database like Postgres, but is much more difficult to achieve in distributed conditions. The paper suggests an implementation that does not require a blocking coordination.\r\n\r\n### Session Guarantees\r\n\r\nA session corresponds to the view of a single client. High available transaction can guarantee:\r\n\r\n- Monotonic reads: You can't read values back in the past\r\n- Monotonic writes: writes are visible in the order they are submitted\r\n- Writes follow reads: if a session observes T1, commits T2 and another session observes T2, it should also observe T1. It means that sessions cannot rewrite their past\r\n- Read your writes: clients should see the last version of a value they updated or a overriden value by another client\r\n- Pipelined random access memory (PRAM): combination of monotonic reads, writes and read your writes\r\n- Causal consistency: All the above\r\n\r\nThe sessions guarantees can be achieved for sticky high available transactions.\r\n\r\n## Other ACID Isolation\r\n\r\nWe did not tackle two serial anomaly yet: Lost Update and Write Skew. First let's look at a lost update case:\r\n\r\n- T1: r_x(a) w_x(a + 2)\r\n- T2: w_x(2)\r\n\r\nIf T1 read `a = 1` before T2 but T2's write is applied before T1's, the database ends up with `x = 3`. We lost the write of T2. It is a serial anomaly because if you apply T1 then T2 or T2 then T1 you should not have this result. This anomaly is quite common when you use 'Read Then Update' pattern, as I illustrated in one of my [latest post](https://sadraskol.com/posts/when-business-rules-become-technical-problems).\r\n\r\nSnapshot Isolation (SI) or RR (for Postgresql) prevent Lost updates.\r\n\r\nWrite skew are a generalization of lost update when multiple keys are involved. Consider the following:\r\n\r\n- T1: r_y(0) w_x(1)\r\n- T2: r_x(0) w_y(1)\r\n\r\nIf both transactions commit, no update are lost. But you can't find an order under which T1 and T2 can be applied serially. Only Serializable isolation can prevent such cases.\r\n\r\nThese two isolation cannot be achieved by distributed systems without sacrificing availability at some point. We are limited here by the [CAP theorem](https://en.wikipedia.org/wiki/CAP_theorem).\r\n\r\n## Conclusion\r\n\r\nThe paper summarizes the consistency models with the following graph:\r\n\r\n<figure>\r\n<img src=\"https://sadraskol.s3.eu-central-1.amazonaws.com/consistency.png\"/>\r\n<figcaption>Graph of consistency levels, in order of constraints for the system</figcaption>\r\n</figure>\r\n\r\nBlack and white models are achievable by highly available systems. Blue one can also be achieved by sticky clients. Red models require some coordination: they are unavailable consistency models.\r\n\r\nThis paper is a must read for anyone who wants to get into distributed systems and understand the tradeoffs from a theoratical point of view but also gives practical implementations. I didn't cover the part of the paper talking about the performance of an implementation of a high available transaction system, but it's also worth a look.\r\n\r\nThis was a blast, and I can't wait to read the more on the theory of consistency levels. This paper uplifts my soul and I confinced me to go deeper in the theory of consistency in distributed systems.","language":"en","shareable":false,"publication_date":"2020-10-30T08:35:26.898445+00:00","current_slug":"reading-notes-highly-available-transactions-virtues-and-limitations","previous_slugs":[]},{"post_id":"891d969c-0c5e-4e6e-a729-3b86fb460603","version":8,"title":"Reading notes: Common Ground and Coordination in Joint Activity","markdown_content":"This paper is less technical and more on collaboration on common tasks. The main author is famous doctor in psychology [Gary Klein](https://en.wikipedia.org/wiki/Gary_A._Klein). This paper was part of Lorin Hochstein's [blog](https://surfingcomplexity.blog/), but I couldn't get my hand on where I found it precisely. Anyway, let's get into the paper.\r\n\r\n## Joint activity\r\n\r\nThe paper starts with the idea that communication between experts is mystery to anyone external to the domain or even the team. The performance of a team depends on coordination, and the paper tries to explore issues of coordination. Previous papers focused on coordination, meaning people having the same goal, this paper will introduce joint activities: participants do not have to have the same goal.\r\n\r\nThe paper divides joint activities in three domain:\r\n\r\n1. Criteria for a joint activity: the basic compact\r\n2. Requirements for joint activity: common ground\r\n3. Choreography of joint activity: phases\r\n\r\n## Basic compact\r\n\r\nThe basic compact is an agreement to support coordination. It constitutes a level of commitment of all parties. The base compact requires reinforcement and renewal. It is not eternal, it breaks when the goals are meet, when a party retires from the joint activity or participants disagree.\r\n\r\nThe goal of the basic compact is for every participants to relax their short-time goal to achieve the common goal. For instance, a car will let a pedestrian cross the road to ensure safety at the cost of being on time for an appointment.\r\n\r\nUnder the basic compact, parties are confident that others carry out their responsabilities of coordination tasks. Depending on the strength of coordination needed, the basic compact will adapt.\r\n\r\n## Common ground\r\n\r\nCommon ground is the mutual knowledge shared between parties. The basic compact includes an expectation that any faulty knowledge is repaired when detected. This knowledge spans from beliefs, assumptions, expertise, means of commmunication, etc.\r\n\r\nCommon ground is a process of testing, tailoring and repairing. The paper lists what the author consider the most important types of knowledge:\r\n\r\n- The role and functions of each participants\r\n- The routines taht the team is capable of executing\r\n- The skills and compeetencies of each participant\r\n- The goals of the participants, including thir commitment to the success of the team activity\r\n- The \"stance\" of each pariticpant (e.g., his or her perception of time pressure, level of fatigue, and competing priorities)\r\n\r\nThis part is really similar to the tasks of a manager as described by Lara Hogan, that I [reviewed before](https://sadraskol.com/posts/lara-hogan-s-resilient-management-reading-notes).\r\n\r\n## Choreography of joint activity\r\n\r\nThe choreography of joint activity lays in 3 phases: an entry, a body of action and an exit. The transitions between and tasks in a phase require passing messages between phases. They form the signals of the joint activity. The signals only works if the others notice them.\r\n\r\nI didn't take note for this part, so I'm skipping to the next part.\r\n\r\n## Failures in joint activity\r\n\r\nFailing to achieve the joint activity can have multiple reasons, but it all boils down to a failure in one of the three pillars of joint activity.\r\n\r\nYou can have breakdown of common ground if the partial knowledge between parties is not mended. Failing to signal an abandonment of the joint activity can also mean a failure for the group.\r\n\r\n## Conclusion\r\n\r\nThe paper is quite long and I struggled to get to the end of it. It ends on reasons why automating tasks is difficult given machines can violate common ground without knowing it. The machine needs to be predictable to its operator. The cost of coordination needs to be taken into account.\r\n\r\nI did not enjoy the reading of this paper as I am quite ignorant in this discipline. As an ignorant I felt the paper using very specific to prove very general points. Since I don't understand the field, I could not get into it.\r\n\r\nIt was really interesting to let my imagination weave concepts during the reading and extrapolating to my day to day tasks.","language":"en","shareable":false,"publication_date":"2020-10-26T19:59:03.170210+00:00","current_slug":"reading-notes-common-ground-and-coordination-in-joint-activity","previous_slugs":[]},{"post_id":"1254b3d7-003d-48a7-867e-4da5bdb813b6","version":21,"title":"Reading notes: scalable state-machine replication","markdown_content":"This article is about my second paper reading. I really enjoyed my [first one](https://sadraskol.com/posts/reading-notes-extreme-modelling-in-practice), and I was excited to read another one. I couldn't make my mind up until I spotted Murat Demirbas' [reading list](https://muratbuffalo.blogspot.com/2020/08/my-distributed-systems-seminars-reading.html). Since an expert on distributed systems will make his own review, I'll be able to compare and check for improvement in my own reading. Let's go!\r\n\r\n### Background and challenges\r\n\r\n[Scalable State-Machine Replication (S-SMR)](https://www.inf.usi.ch/faculty/pedone/Paper/2014/2014DSNa.pdf) is a paper showing a generic way of providing SMR while partitionning the application state. Why would you do that? SMR algorithms offer a reliable way of building fault-tolerant systems. Unfortunately they suffer from scalability issues. To mitigate those issues, you can partition the state, which improve the systems throughput. The goal of the paper is to show that both SMR and partitionning can be used to improve the throughput of a system compared to a single node solution like Zookeeper.\r\n\r\nThey are 2 challenges to overcome:\r\n\r\n1. Keeping the linear order of commands accross and within partitions. SMR offer linearizability (more on this later) and S-SMR should as well\r\n2. Optimizing requests through cache, fine tuning of parameters, etc. to mitigate impacts on latency\r\n\r\n### Definitions\r\n\r\nThe paper goes on defining the assumptions of the systems and definitions. It considers asynchronous systems (see Asynchrony in the [work of Leslie Lamport](https://sadraskol.com/posts/reading-notes-concurrency-the-works-of-leslie-lamport)) which does not suffer Byzantine failures, and communications offer **atomic multicast**.\r\n\r\nSay server s sends a message to a group of server R (receivers). We consider the two primitives `multicast(R, m)` and `deliver(m)` where **R** is the server or group of server and **m** is the message. **Atomic multicast** means:\r\n\r\n1. if r delivers m, then all correct servers in R deliver m (agreement)\r\n2. if s is correct and multicasts m to R, all correct r in R deliver m (validity)\r\n3. if r delivers m then m', r' in R delivers m then m'\r\n\r\nI had some problems understanding difference between agreement and validity. I already read it somewhere but my mind just skipped it. To be honest the [wikipedia entry](https://en.wikipedia.org/wiki/Atomic_broadcast) did not help me here, I hope I find another reading to understand the definitions better.\r\n\r\nThe paper goes on defining linearizability. Fortunately I knew this one before. The definition of the paper is okay but, I could not understand it without prior knowledge. To make it short, a system is linearizable if it behaves like a single thread (you can find a coherent order for command execution to stand) and the order of execution of commands is respected. It's like a real time single thread.\r\n\r\n[Kyle Kingsbury explains it much better](https://www.youtube.com/watch?v=tRc0O9VgzB0).\r\n\r\n### The S-SMR\r\n\r\nAlthough the paper starts with a general idea of how the algorithm works, i'll start introducing the detailed algorithm:\r\n\r\n```\r\n// Client side of code here: before command C is submitted, clients asks the oracle\r\ndests <- oracle(C)\r\nmulticasts(dests, C)\r\nwait for response of from one server\r\n\r\n// for each server of partition P, 3 processes run\r\nupon deliver(C)\r\n  others = dests \\ {P}\r\n  multicasts(others, signal(C))\r\n  for each operation op in C do\r\n    if op is read(v) then\r\n      if v belongs to P then\r\n        multicasts(others, {v, C.id})\r\n      else\r\n        wait_until v belongs to received_variables(C)\r\n        update v with value in received_variables(C)\r\n    execute op\r\n  wait until received_signals(C) == others\r\n  send reply to client\r\n\r\nupon deliver(signal(C)) from partition P'\r\n  received_signals(C) <- received_signals(C) \\union {P'}\r\n\r\nupon deliver({v, C.id}) from partition P'\r\n  received_variables(C) <- received_variables(C) \\union {v}\r\n```\r\n\r\nLet's break down every primitives of the algorithm.\r\n\r\nBatgirl... I mean the oracle can tell which partitions have to be queried to fulfill command C. A naive approach is to return all partitions. It would be costly, so you need to take time to implement a query analyser for that purpose. Unfortunately, the paper does not go in details on the ways to achieve that.\r\n\r\nTo answer the query, the server executes every operation of the command sequentially. If the operation is a reading of a value belonging to the partition, the server sends the value to other partitions. If the value is not from the current partition, the server waits for other partition to send the value. Then the server executes the operation.\r\n\r\nNote that the server can execute a write operation without any need from other partitions. This property is an interesting property that will be discussed in the optimization part.\r\n\r\nThere is one part still unexplained in this algorithm: what is the use of the `signal(C)` and `received_signals`? The short answer is: provide linearizability. The paper shines at explaining this part. It uses this schema:\r\n\r\n<figure><img src=\"https://sadraskol.s3.eu-central-1.amazonaws.com/linearizability.png\"/><figcaption>Example showing how <code>signal(C)</code> ensures linearizability</figcaption></figure>\r\n\r\nIn the example on the left, Cy happens before Cxy because of causation: `x = 10` so Cy < Cxy. In real time, Cy happens after Cx so Cx < Cy < Cxy. But Cx happens after Cxy because of causation: `y = 20` so Cxy < Cx. The only sequential execution of commands available is Cy < Cxy < Cx. Since it breaks real time order of execution of requests, the system would not be linearizable (although it would be serializable, since a sequence exists).\r\n\r\nTo fix this problem, signal(C) is shared between partitions allowing to \"pause\" a partition until other partitions receives the command. This behavior introduces latency, as later discussed.\r\n\r\n### Optimizations\r\n\r\nThe primitives of the algorithm are set. As mentioned, with a naïve oracle the scalability cannot be achieved. The authors are very aware of this problem and suggest a couple of optimizations.\r\n\r\nThe first possible optimization is in writing the oracle. Unfortunately, the paper only assumes an optimal oracle is possible, there is no discussion regarding the assumption made. I guess they used an optimal oracle for Zookeeper, who knows ¯\\\\_(ツ)\\_/¯\r\n\r\nThe second optimization is rather easy given an oracle: since the server receiving C already know which variables are read during the command and the partitions it should send values to, it can multicast to every partitions each values it has ownership on. Each partitions have less waiting for values it does not have ownership.\r\n\r\nAlso since write operations are executed on every partitions, there is no need to query servers for subsequent reads on a value.\r\n\r\nMoreover the requests of format `multicasts(others, {v, C.id})` can be used as `signal(C)` instead of using a dedicated request.\r\n\r\nA single answer from a server is sufficient to finish a command for the client. I haven't wrapped my head around the correctness of such claim. The author seem confident it is, I trust them only because I don't have time to find a failure scenario.\r\n\r\nFinally, servers can make extensive use of two types of caching: conservative caching and speculative caching. Speculative caching assumes the existence of rollback on operation execution. Also it's unclear whether each algorithm were implemented in Eyrie (the implementation of S-SMR of the authors in Java).\r\n\r\nAll optimization techniques are food for thoughts and show case a lot of opportunities to optimize the general approach. It's a shame there is no evaluation on the impact of each optimizations.\r\n\r\nThe paper goes on to prove that the algorithm is correct. I won't go in details on how they do it. As a non academic, I do not have the courage to decypher it again. \r\n\r\n### Implementation & Performance evaluation\r\n\r\nThe two last parts span most of the content of the paper. The first thing that I noted is that they use a Multi Ring Paxos as base for the SMR. There is no explanation why this implementation and not another one, say [raft](https://raft.github.io/). It has some implication since performance depends heavily on the tuning of Multi Ring Paxos. \r\n\r\nThey benchmarked performances for two types of mesurement: Throughput and Latency. The benchmarks run against an instance of Zookeeper, ZKsmr, and Volery (implementation of S-SMR for Zookeeper) of 1, 2, 4 and 8 partitions.\r\n\r\nThe weird parameter for me in this benchmark is the dimension choosen for the messages: they compared the mesurements for messages of 100 bytes, 1000 bytes and 10000 bytes. It seems odd since it does not compare the number of variables of the requests. How can we be sure that the linear scale they observe is not due to variables queried simply being dispatch to a single partition for each messages?\r\n\r\nAlso when comparing memory configurations, the weird latency for 4 partitions is not explained. Since there is no discussion around this, it's very suspicious.\r\n\r\n### Conclusion\r\n\r\nThis paper has been a lot of fun for me to read and understand. I really enjoyed the optimization part and understanding how linearizability is guaranteed. The great thing about the paper is that it goes from a general algorithm that works in any case and they open the door for a lot of optimization. Also they introduce a lot of related works that tackled the same problem with different perspectives.\r\n\r\n3 questions remains for me:\r\n\r\n1. Where could the algorithm serve in the industry? Most replication use a specialized algorithm, thing like geo-partionning. How could a general purpose algorithm compete against them?\r\n2. Is the latency worth the throughput?\r\n3. The author mention that the algorithm is write optimized but zookeeper is read optimized. Is there a place for such algorithm in the industry?\r\n\r\nI do not have sufficient knowledge in this area to answer these questions. I really enjoyed reading this paper and I really want to keep reading academic papers. They open my mind on difficult subject that I would not realize in my day to day engineering.\r\n\r\n---\r\n\r\nUpdate: Murat Demirbas wrote a [quick article on this paper](https://muratbuffalo.blogspot.com/2020/10/scalable-state-machine-replication.html). For him, there is no doubt: the algorithm have limited applications. It clears out things that were out of my knowledge. First, multiring paxos is used to respect the atomic multicast. Since it's already a difficult problem to solve on its own, you cannot use any regular SMR. Also this means that comparing to a single Zookeeper cluster is not enough. Secondly, the graphs are pretty bad case for this solution.\r\n\r\nIt answers my questions, and I think my intuitions were correct: the paper will remain a research subject and won't have industry applications.","language":"en","shareable":false,"publication_date":"2020-09-22T19:33:55.771739+00:00","current_slug":"reading-notes-scalable-state-machine-replication","previous_slugs":[]},{"post_id":"5618965d-f1e8-4cdb-88e6-e5f1fc85c642","version":18,"title":"When business rules become technical problems","markdown_content":"Sometimes business rules are easy to implement. Let's say a PM comes to me and asks \"make sure the price of a product never goes below zero\". Piece of cake:\r\n\r\n``` java\r\npublic void save(Product product) {\r\n  if (product.price < 0) {\r\n    throw new IllegalArgumentException(String.format(\r\n      \"tried to save product %s with negative price %d\",\r\n      product.id,\r\n      product.price\r\n    ));\r\n  }\r\n  myOrm.save(product);\r\n}\r\n```\r\n\r\nYou disagree on the exception being used as control flow? Replace it with your favorite way of dealing with conditions. Can one save a negative price product with this code? Is this code correct?\r\n\r\nIt is not as obvious as it seems. In a fully concurrent application, the reference to `product` could be shared by multiple threads. Another thread could change the price of the product after the check and before it is saved by the current thread leading to wrong behavior.\r\n\r\nWe do not consider this kind of scenario in DDD approaches or blog posts. To answer to an HTTP requests, threads do not share references to domain objects. They would rather share references to the database pool. Each request fetches the domain object from the database, applies changes and saves the result. Since each request creates a different object for the same Entity (uniquely identified domain concept), the code above solves the business need to refuse negative prices.\r\n\r\nHere's an example of an execution of two requests at the same time:\r\n\r\n<figure>\r\n<img src=\"https://sadraskol.s3.eu-central-1.amazonaws.com/multiple-save-sequence.png\" alt=\"sequence diagram of multiple user changing the price at the same time\"/>\r\n<figcaption>In purple the product at its current price, in green the product with price 14. </figcaption>\r\n</figure>\r\n\r\nIn any order of execution, user B will never be able to save the product at a negative price. As long as the database acts like a **regular** register (see my [notes on Concurrency](https://sadraskol.com/posts/reading-notes-concurrency-the-works-of-leslie-lamport) for a definition), the business rule is correctly solved.\r\n\r\nFor this kind of business needs, the architecture of systems makes our code safe. This technical detail provides a safe environment for our code. This environment sparks conversations around the best way to express our business rules with code. These conversations lead to DDD practices (it's a bit far fetched, bear with me for a moment).\r\n\r\n## Is domain purity possible?\r\n\r\nWhen all business rules are expressed in a single place in the code, some call that domain purity. In this [article](https://enterprisecraftsmanship.com/posts/domain-model-purity-completeness), the author insists on the distinction between completeness and purity. This is not what I'll discuss here. I want to focus on the example used in the article.\r\n\r\nI have a problem with this example. I tweeted about it:\r\n\r\n> If you consider isolation, all implementations fail to check uniqueness in a concurrent environment, even with the in-memory database...\r\n> This is a very good example of technical constraints influencing domain code.\r\n> Could you find a correct way to check uniqueness?\r\n> [@sadraskol - August 10, 2020](https://twitter.com/sadraskol/status/1292744962161946624)\r\n\r\nI think this tweet is too provocative to explain the kind of problem it points out. Since tweets are too short for an explanation, let's dig into it here.\r\n\r\n## Database isolation\r\n\r\nLet's consider Postgres. By default, when running a transaction, it's under *[Read Committed](https://www.postgresql.org/docs/current/transaction-iso.html)* isolation. At this level of isolation *\"a SELECT query sees a snapshot of the database as of the instant the query begins to run\"*. Note that the snapshot is before the *query*, not before the *transaction*.\r\n\r\nIt means that two concurrent transactions can run without hindering each other. Let's run the example in a *Read Committed* transaction in the worst case:\r\n\r\n- Database has no user\r\n- User A opens a transaction\r\n- User A checks for email \"a@a.com\"\r\n- User B opens a transaction\r\n- User B checks for email \"a@a.com\"\r\n- Database saves user A with email \"a@a.com\"\r\n- Database saves user B with email \"a@a.com\"\r\n\r\nThis behavior can be checked using a formal specification. In TLA+, this would look like that:\r\n\r\n``` tla\r\n\\* We consider 3 accounts that can choose from 3 distinct emails\r\nUsers == { \"tom\", \"nas\", \"hyp\" }\r\nEmails == { \"a\", \"b\", \"c\" }\r\nNil == \"Nil\"\r\n\r\nVARIABLE possibleEmails, chosenEmails, userRegistered, checkedEmails\r\nvars == << possibleEmails, chosenEmails, userRegistered, checkedEmails >>\r\n\r\n\\* At first no user registered\r\nInit == /\\ chosenEmails = << >>\r\n        /\\ userRegistered = << >>\r\n        /\\ possibleEmails = Emails\r\n        /\\ checkedEmails = [ u \\in Users |-> Nil ]\r\n\r\nUserRegisteredYet(user) == \\A u \\in DOMAIN userRegistered : userRegistered[u] /= user\r\n\r\nCheckEmailUniqueness(user, email) == /\\ email \\in possibleEmails\r\n                                     /\\ checkedEmails[user] = Nil\r\n                                     /\\ checkedEmails' = [ checkedEmails EXCEPT ![user] = email ]\r\n                                     /\\ UNCHANGED << possibleEmails, chosenEmails, userRegistered >>\r\n\r\nEmailChecked(user, email) == checkedEmails[user] = email\r\n\r\nChooseEmail(user, email) == /\\ UserRegisteredYet(user)\r\n                            /\\ EmailChecked(user, email)\r\n                            /\\ chosenEmails' = Append(chosenEmails, email)\r\n                            /\\ userRegistered' = Append(userRegistered, user)\r\n                            /\\ possibleEmails' = possibleEmails \\ { email }\r\n                            /\\ UNCHANGED << checkedEmails >>\r\n\r\nNoEmailToChoose == possibleEmails = {} /\\ UNCHANGED vars\r\n\r\nEmailChecking == \\E u \\in Users: /\\ \\E e \\in possibleEmails: CheckEmailUniqueness(u, e)\r\n\r\nRange(f) == { f[x]: x \\in DOMAIN f }\r\n\r\nUserRegistering == \\E u \\in Users: /\\ \\E e \\in Range(checkedEmails): ChooseEmail(u, e)\r\n\r\nNext == \\/ EmailChecking \\/ UserRegistering \\/ NoEmailToChoose\r\n\r\nSpec == /\\ Init\r\n        /\\ [][Next]_vars\r\n        /\\ WF_vars(UserRegistering)\r\n        /\\ WF_vars(EmailChecking)\r\n\r\n\\* Invariants\r\nEveryChosenEmailMustBeUnique ==\r\n        \\/ Len(userRegistered) = 0\r\n        \\/ \\A email \\in Emails:\r\n            Len(SelectSeq(chosenEmails, LAMBDA x: x = email)) <= 1\r\n\r\nEveryRegisteredEmailHasARegisteredAccount == Len(userRegistered) = Len(chosenEmails)\r\n\r\n\\* Property: here we check for liveness of our implementation,\r\n\\* that is that at least one email is chosen by account\r\nEventuallyAtLeastAnEmailIsChoosen == <>(Len(chosenEmails) >= 1)\r\n```\r\n\r\nThe model checker of TLA+, TLC, will find the same example as previously described:\r\n\r\n<figure>\r\n<img src=\"https://sadraskol.s3.eu-central-1.amazonaws.com/tlc-check-email-uniqueness.png\" alt=\"TLC finds a counter example for our specification\"/>\r\n<figcaption>TLC finds a counter example for our specification</figcaption>\r\n</figure>\r\n\r\nIf you think I wrote this article only to practice my TLA+ skills... You're right! But let's not stop there.\r\n\r\n## Finding an elegant solution\r\n\r\nThere are multiple solutions to that problem.\r\n\r\nThe first one would be to set the transaction level of your database to *Serializable*, the highest level of isolation. It guarantees that every transaction is serializable: you can find a linear execution of all transactions. It simulates transactions being run sequentially in a single thread. This has a lot of performance drawbacks, so my team was shy to try it. If you use this isolation in production, I'd be curious of your experience with it!\r\n\r\nAnother solution would be to set up a lock on the table for unicity. You can use `SELECT ... FOR UPDATE` to lock the rows of the table. It protects against concurrent conflict updates in the same row. Since it's a one liner, it's easy to implement in your current code.\r\n\r\nSerializable isolation and locks are good solutions but they can be quite expensive. If a transaction takes a long time, it slows down every request waiting for the lock. If misused, you can find yourself in deadlocks or having poor performances. There is a simpler solution: unique constraints. Constraints are checked within the database. Unique constraints are tailored for unicity check.\r\n\r\nUsing the database constraints to check unicity means moving some of the business needs outside your application code. This is not coherent to an approach that centralized all rules in one place. There's an easy mitigation to this problem. Since the repository interface is defined by the domain, we can add this case to the domain:\r\n\r\n``` java\r\ninterface UserRepository {\r\n  void save(User user) throws EmailAlreadyTakenException\r\n}\r\n```\r\n\r\nEvery caller will have to define a behavior in case the exception is thrown. Once again exception is not the best control flow ¯\\\\\\_(ツ)\\_/¯ Use the control flow that fits your code style.\r\n\r\n## End notes\r\n\r\nIt's always better to express code in pure domain code: checking rules in pure memory is much simpler than mixing Database calls with logic. But sometimes pure memory code will not cut it. Concurrent problems, unicity across systems, partial failures, time related tasks are difficult to check without battle tested technical solutions. I would recommend retrofitting technical constraints in the domain code. It's safer and would lead to less painful bugs rather than depending on an unadapted architecture.\r\n\r\n*ps: race condition, race condition is the missing word of this post. It took me a week to figure it out...*","language":"en","shareable":false,"publication_date":"2020-08-21T18:29:42.064838+00:00","current_slug":"when-business-rules-become-technical-problems","previous_slugs":[]},{"post_id":"2a33bd19-bce3-460b-be9a-4dc61e0c5cb3","version":8,"title":"Reading notes: eXtreme Modelling in Practice","markdown_content":"This is the first time I read a full paper. This is the [eXtreme Modelling in Practice](https://arxiv.org/pdf/2006.00915.pdf) paper written by a team of engineer at MongoDB. The paper's insight on eXtreme modelling is really interesting and I was not disappointed reading the paper. Here are my notes:\r\n\r\nMongoDB already used TLA+ to check some high level specifications. TLA+ is already used in the industry by Amazon, Microsoft, Intel, etc. It successfully helped teams identify bugs. But the authors note a reluctancy in using TLA+ in fear of the \"transcription bug\": when the implementation and the model do not match.\r\n\r\neXtreme Modelling was introduced by this [paper](https://arxiv.org/pdf/1111.2826.pdf), and explored the possibility of implementing and modelling at the same time. The specification would evolve with the implementation and the system is tested directly with the model. Two techniques are presented:\r\n\r\n- Model-based trace-checking (MBTC): it consists of running the system, capturing traces then checking them with the model\r\n- Model-based test-case generation (MBTCG): we run the model, capture the states and implement the corresponding tests in the implementation language.\r\n\r\nThere are alternatives to these two methods (specifications and implementation in the same language, generating code from specs, refinement, direct check on existing implementation, etc.) but they are not applicable to MongoDB's use cases. The author has doubts in refinement: it implies maintaining mutliple models and their implementation. It is costly and conflicts with the eXtreme Modelling that suggests to maintain a single model.\r\n\r\nThey tested two systems that already run randomized testing: MongoDB and Mongo Realm Sync.\r\n\r\n## MBTC applied to MongoDB\r\n\r\nMBTCG is hard to apply to MongoDB because it requires to introduce hooks in the code to stop processes. It is expensive and could change the system's behavior. Note: The last claim is not proved or explained a lot. Once you know all the issues they had, maybe this approach could have worked.\r\n\r\nThe database has 423 hand-written integration tests and 23 randomized tests. First they implemented a `MongoRaft.tla` specification to match high level specs of MongoDB consensus protocol. They changed the implementation from the original Raft protocol, since MongoDB has some implementation differences.\r\n\r\nThe specification had 3 nodes having their own state (4 variables) and 7 labelled operations (It is weird because they list 9 operations but the paper states only 7 throughout, I don't where the discrepancy comes from). This leads to a state space of around 371k states.\r\n\r\nThe author then describes the protocol used to analyse traces within the system. They basically introduced logs after each operation.\r\n\r\n<figure><img src=\"https://sadraskol.s3.eu-central-1.amazonaws.com/mbtc-pipeline.png\" alt=\"each Node logs to files, then a python script turns them into TLA+ which is then checked\"/></figure>\r\n\r\n### Analysis\r\n\r\nThe analysis on this case is really insightful, I would say it's the most interesting part of the paper.\r\n\r\nThey invested 10 weeks of work to validate one specification. Due to discrepancies between the code and the model, there was a lot of effort to fix the model and the lack of tooling did not help. The problems they faced:\r\n\r\n- The traces need to be written before the action of a node is visible to other nodes, otherwise the traces are wrongly ordered. They had to lock the code when writing the traces which is quite expensive\r\n- Each nodes of MongoDB are multi-threaded. Each thread shares locking mechanisms, latches, use futures, etc. All of this makes snapshoting the state of each node very difficult\r\n\r\nNote: I'm surprised the author did not anticipate this problem. Lamport is known for consensus algorithm, but he planned their usage for both distributed systems and multi-threaded environments. I think they secretly hoped not to encounter such issues.\r\n\r\n- The specification did not model arbiters in the protocol (oversimplification)\r\n- Initial synchronisation of nodes needed extra work\r\n- MongoDB can have 2 leaders for a short amount of time (!!!)\r\n- Copying the oplog did not work has specified\r\n\r\nAll these problems could be solved by changing the specification, but the authors feared it would implode the state space. The spec had already a runtime of 15 minutes, finer specification would mean a lot more time to wait for results.\r\n\r\nThe final cost for the MBTC method is really high and the authors dropped this experimentation when they see the amount of work to put in it.\r\n\r\n## MBTCG applied to Mongo Realm Sync\r\n\r\nThe system is under migration from the C++ implementation to a Golang implementation. The authors used MBTCG to check both implementations. They checked 6 operations that represented 21 rules of merge implemented in approximately 1000 lines of C++.\r\n\r\nThey used the C++ implementation directly and slowly converted it into TLA+ in 40 hours. They met 2 challenges: C++ relied heavily on the mutation of arguments of methods which is not possible in TLA+. Operation are unordered in and could lead to a state space explosion.\r\n\r\nTo constrain the state space, instead of modelling a lot of state transitions, they used only one operation applied to a lot of initial states.\r\n\r\nTLC (TLA+ main checker) helped finding a non terminating bug in the translation that was also present in the C++ implementation but not catched by the existing tests. They decided to deprecate the operation and to focus on the tests.\r\n\r\nThe pipeline in this case is simpler: TLC generated a graphiz DOT file for every states. They translated theses files into C++ code corresponding to the implementation. It results in 4913 tests.\r\n\r\nThe existing hand-written tests had a 21% branch coverage. The fuzzy tests had a 92% branch coverage. The MBTCG tests had a wooping 100% branch coverage. The author are therefore very confident the specification matches the implementation and that MBTCG proved itself useful. The overall process was 4 weeks long.\r\n\r\n## Personal notes\r\n\r\nThis paper is really interesting. I feel like eXtreme Modelling has a lot to offer. The comparison in the paper seems unfair: MBTC failed because of the complexity of the system they were testing. If they had applied MBTC to the second case, would they have failed the same? I am seduced by the MBTCG approach, but the paper is not sufficient to decide.\r\n\r\nI think that both approaches require tools to more accessible to most software engineers. But I'm sure that there is a place for this kind of approaches in a lot of cases. I hope you enjoyed reading me as I enjoyed reading the paper.","language":"en","shareable":false,"publication_date":"2020-06-04T22:17:48.208637+00:00","current_slug":"reading-notes-extreme-modelling-in-practice","previous_slugs":[]},{"post_id":"95ef6aa1-36d7-4c90-88fd-2efb21c2d778","version":16,"title":"Reading notes: Concurrency, the works of Leslie Lamport","markdown_content":"*Concurrency, the works of Leslie Lamport* edited by Dahlia Malkhi, is published by ACM and [freely available on their site](https://dl.acm.org/doi/epub/10.1145/3335772). The collection is targetted to large audience to better know the work of ACM Turing award recipients. As the title implies, this book explains the work of Leslie Lamport on concurrency, and tries to convince you this award was deserved.\r\n\r\nThe book dives quickly into the first major contribution of Leslie Lamport: the mutual exclusion solution of the Bakery algorithm. It mimics the queue of clients waiting at a bakery. Each process has a ticket and only the lowest ticket is given access to the critical part of the code. Lamport proved that the algorithm works for atomic registers, but also for regular registers (more on that later). This algorithm is already a challenge for the mind to understand how difficult it is to find and prove correct concurrent algorithms.\r\n\r\nLamport also provided a definition of what safe, regular and atomic registers meant. When you deal with memory, two operations can be performed: **read** and **write**. As explained in [this stackoverflow answer](https://stackoverflow.com/a/8872960), reads and writes can happen at the same time.\r\n\r\n```\r\nProcess1 -----wwwww--------------wwwwww------- (w1, w2)\r\nProcess2 -------rrrrr----------------rrrr----- (r21, r22)\r\nProcess3 -------------rrrrrr---rrrr----------- (r31, r32)\r\n```\r\n\r\nLet's say that the register is reading 0 before any writes, w2 writes 10 and w3 writes 100. The range of this virtual register is 0-255. The possible values returned would be:\r\n\r\n|Read|Atomic|Regular|Safe|\r\n|---|---|---|---|\r\n|r21|0,10|0,10|0-255|\r\n|r31|10|10|10|\r\n|r32|10,100|10,100|0-255|\r\n|r22|if r32 = 100, 100 else 10,100|10,100|0-255|\r\n\r\nNote that every none overlapping read returns the latest write, the behavior changes for overlapping reads. For safe registers, overlapping reads can return any value in the range of the register. Regular register will only allow current value or previous value to be returned, without constraints on the order of read. Successive overlapping reads can return incoherent values between one another but not random values. Atomic read are the strongest registers, concurrent reads must respect **sequential consistency**.\r\n\r\n## Causal time\r\n\r\nArguably the biggest contribution to computer science by Leslie Lamport is the notion of causal time. At a time when it was not proved that any algorithm could be performed in distributed systems, and the reliance on clocks to synchronize algorithms, the paper \"Time, Clocks, and the Ordering of Events in a Distributed System\" marked a turning point.\r\n\r\nThe idea is the following: multiple processes send messages to other processes and perform actions. Each process has his own causal clock, a number increasing for each operation. When sending a message to other processes, the process also send his clock. The receipient will then choose: either his clock is greater, and it keeps on going, or it chooses the clock of the sender and increases it. If every step of an algorithm is performed between messages, we are able to trace which step have followed other steps.\r\n\r\n```\r\nProcess1 0--1---------4------------5-------\r\n                     /              \\\r\nProcess2 0------2---3----------------6-----\r\n               /                      \\\r\nProcess3 0----1------------2-----------7---\r\n```\r\n\r\nThis little graph represent the clock of each process. They all start at 0. When a step of the algorithm is performed, the local clock increases by 1. Every line in between processes represents a message being sent to another process. In this case the local clock is also re-evaluated. If every clock increase is performed by a message, we can trace the origin of every steps. We are not interested in steps between message sending. The main focus is not the real time, but the **logic time** that links every steps of the algorithm.\r\n\r\nThis appearing simple concept allows to prove that any algorithm, every state machine can be distributed (given no faults in network/process) and opens the door for future work on distributed state machines.\r\n\r\nFor instance, you can perform a *snapshot* of the distributed system, that doesn't really snapshot the state of every processes at a given time (\"real\" time), but a causal view of the system. Although not precise, this kind of snapshot allow to verify properties of the running system: if the snapshot is in a deadlock, the system is in a deadlock, etc.\r\n\r\nLeslie Lamport also defined the Byzantine failure, but I didn't really got this part so i'll skip to the next.\r\n\r\n## Replication problem\r\n\r\nLeslie Lamport provided with one of the most influencial algorithm: the Paxos algorithm. It runs Apache Cassandra, Google Spanner and Bigtable, it influenced a whole family of consensus algorithm, [Raft](https://en.wikipedia.org/wiki/Raft_(computer_science)) being the latest newborn.\r\n\r\nBut first let's do some history:\r\n\r\n- in 1975, the RFC 677 described the first protocol for database replication. Lamport was highly inspired by this paper. It mentioned that the protocol could have the probability of strange behaviors...\r\n- in 1976, the first primary-backup protocol was described\r\n- in 1977, Xerox PARC used petri nets to replicate data between servers\r\n- in 1978, Lamport published the first state machine replication (SMR) proposal based on causal time\r\n\r\nHis paper was groundbraking since if no failure happened, strong consistency and replication could be proved possible!\r\n\r\nAfter some definition of *Agreement*, *Completion*, *Asynchrony*, *Partial Synchrony*, *Synchrony*, *Crash Failure*, *Fail stop*, *Total Ordering Protocols* and *Consensus Protocols*, the book dives into some properties of the systems (I'll let you read the book to understand all those terms). One thing to note is that for `f` failures, consensus can be found for `2f + 1` participants.\r\n\r\nThe first early consensus protocol was published in 1983 by Micheal Ben-Or. It is described as such in the book:\r\n\r\n> 0. For every N processes p set an estimate e(p) to Red or Blue randomly, they also set their round r(p) = 0\r\n> \r\n> Phase 1:\r\n> \r\n> - every process broadcasts a message of type (Phase1, r(p), e(p))\r\n> - wait to receive N/2 phase 1 messages of round r(p)\r\n> - if every message has the same estimate e, choose v(p) = e\r\n> - else v(p) = `_|_` (bottom or null for instance)\r\n> \r\n> Phase 2:\r\n> \r\n> - every process broadcasts a message of type (Phase2, r(p), v(p))\r\n> - wait to receive N/2 phase 2 messages of round r(p)\r\n> - if every message has the same value v (!= `_|_`), **decide** e(p) = v\r\n> - else if a message has a non bottom value v, e(p) = v\r\n> - else choose a random Red or Blue estimate e(p) = Red | Blue\r\n\r\nThe two phase algorithm allows to reduce the number of processes, as the single phase variant protocol would require `3f + 1` processes to guarantee the same properties. This algorithm is C-valid, C-agreement and completes with a probability 1 (like the probability of getting head when tossing a coin for an infinite amount of times).\r\n\r\nAlthough this is a theoretical only algorithm, it can be extended to other consensus algorithms.\r\n\r\nIn 1984, the Dwork, Lynch & Stockmeyer (DLS) introduces the notion of leader to simplify the complexity of communication. The alternative presented in the book is called the Franken algorithm. It only works for *Partial Synchrony*, while Ben-Or worked for *Asynchrony* systems.\r\n\r\n- There is a timeout T(p), doubled at the end of each round\r\n- In phase 1, a leader broadcasts his estimate. If a process waits more than T(p) for the leader's estimate, it chooses its own\r\n- In phase 2 if process p receives multiple estimates, it chooses its own instead of a received value.\r\n\r\nDLS is still a theoretical algorithm, but it is an improvement over Ben-Or since any value can be used as estimates.\r\n\r\nFinally in 1989, Lamport published the first paper on the first Paxos consensus algorithm. Instead of using O(N²) messages by rounds, it would only use O(N) messages, making it the first possibly interesting algorithm for the industry. It uses a leader and is also aimed at *Partial Synchrony* systems.\r\n\r\n> 0. set e(p) = `_|_`, r(p) = 1 and T(p) > 0\r\n> \r\n> Phase 1a.\r\n> \r\n> - if p is leader of r(p) broadcast (Phase1a, r(p))\r\n> - wait for message of type Phase1a, with r >= r(p), then set r(p) = r\r\n> \r\n> Phase 1b.\r\n> \r\n> - send (Phase1b, r(p), e(p)) to leader of r(p)\r\n> - if p leader of r(p):\r\n> - wait for N/2 messages of Phase1b with E = set of estimates received,\r\n> - if there is an non bottom estimate in E, v(p) = max(E) else use the initial estimate of p\r\n> \r\n> Phase 2a.\r\n> \r\n> - if p is leader of r(p) broadcast (Phase2a, r(p), e = (v(p), r(p)))\r\n> - wait for message of type Phase2a, and accept e(p) = e\r\n> \r\n> Phase 2b.\r\n> \r\n> - send (Phase2b, r(p)) to leader of r(p)\r\n> - if p is leader of r(p):\r\n> - wait for N/2 messages from Phase2b, then **decide** the proposal e(p) and broadcast to all replicas\r\n> \r\n> Optional Phase 3\r\n> \r\n> - if a p is not leader of r(p) then upon timeout T(p) of not receiving from the leader:\r\n> - increase r(p) for which p is leader\r\n> - double T(p) and go back to phase 1a.\r\n\r\nLeaders of rounds are choosen by a simple mecanism like p is leader of rounds `r mod N = p`. Although I had a pretty clear picture in my head of previous algorithms I am not sure I understand how Paxos could work and be complete. The tricky part to me is understanding when the leader does not respond, how the new leader is choosen.\r\n\r\nPaxos has opened a whole family of consensus algorithms that were successfully implemented in distributed systems thoughout the industry, but also inspired more recent Raft.\r\n\r\nThe weakness of Paxos algorithm is dynamic configuration. Changing the processes configuration have tricky corner-cases and need special care.\r\n\r\n## Formal verification\r\n\r\nLeslie Lamport has a mathematician background which influences his work in the sense that he does not focus on language specific syntax in elegant algorithms. He tries to study systems as a whole and properties that are common to every technology. This makes his work applicable to memory, multiprocesses or distributed systems alike.\r\n\r\nHe coined the terms \"Safety\" (nothing bad ever happen in a system) and \"Liveness\" (Something good eventually happens). These were later defined. \r\n\r\nIn the 70s there was work on temporal logic, in the 80s Lamport worked on temporal logic to try coming up with a formal method specific for distributed problems and finally in the early 90s he put the foundation of TLA (Temporal Logic Action). This is the subject of my next book so I didn't get into this part of the book.\r\n\r\nThe rest of the book consists of a collection of groundbraking papers proposed by Leslie Lamport. I didn't read that either.","language":"en","shareable":false,"publication_date":"2020-05-26T16:45:01.249518+00:00","current_slug":"reading-notes-concurrency-the-works-of-leslie-lamport","previous_slugs":[]},{"post_id":"1db7d82c-ea56-49cd-be0e-6282e82cfc5f","version":5,"title":"Press review #8","markdown_content":"I am currently working on a long articles on different models. Since I don't find the inspiration in those dire times, I forced myself into writing a press review.\r\n\r\n### [Retries in distributed systems: good and bad parts](https://shubheksha.com/posts/2020/05/retries-in-distributed-systems-good-and-bad-parts/)\r\n\r\nBefore reading this article, I was reluctant to add retries in a distributed system. Retry storm is a way of DDoS yourself. Plus, retries don't usually help solving the issue that the first request ran into.\r\n\r\nI might now consider retries with two conditions: exponential backoff and jittering.\r\n\r\n### [The hard parts about making it look easy](https://surfingcomplexity.blog/2020/05/05/the-hard-parts-about-making-it-look-easy/)\r\n\r\nThe **law of fluency** is really nice:\r\n\r\n> “Well”-adapted work occurs with a facility that belies the difficulty of the demands resolved and the dilemmas balanced.\r\n\r\nThis quote inspires me a myriad of unorganized thoughts, it would be egoistic to keep it for me. The facility of a presentation on story mapping during an hour belies the dozen of hours not meeting expectations with a reluctant client...\r\n\r\n### [Python tutor - Visualize your code](http://www.pythontutor.com/)\r\n\r\nThe more I think of models, the more I regret the lack of visual aids when designing software. Python tutor is nice for language that do not have a nice debugger. For Java I'll still use my IDE debugger.\r\n\r\nI am still in quest of an even more powerful tool to develop visually, but I can't find any that seem accessible.\r\n\r\n### [I hate configuring JSON serializers](https://einarwh.wordpress.com/2020/05/08/on-the-complexity-of-json-serialization/)\r\n\r\nI disagree with this article, but I think it's interesting to talk on this subject.\r\n\r\nFirstly, it does not mention the reason JSON is widespread in the first place: APIs are built for the most common device, the browser. Therefor you need to agree on a representation that is easy for Javascript. JSON is the easiest solution as browser provide a free mapping.\r\n\r\nSecondly, the fact that you decide to use a client-server architecture makes the communication between them an essential part of the system.\r\n\r\nFinally, if you put your server in charge of the core of your application, then I find natural to have a communication as a separate component. I agree with the conclusion of the article: you have to separate your API objects (to treat retro-compatibility, etc.) and your domain objects. The way it arrives there is not my favorite.","language":"en","shareable":false,"publication_date":"2020-05-11T13:26:51.873156+00:00","current_slug":"press-review-8","previous_slugs":[]},{"post_id":"bfb572a3-5635-48a2-8d94-08b4273dccfe","version":8,"title":"How to make the best out of Twitter","markdown_content":"Twitter can be a mess. I have a hard time managing my timeline to make it useful to me. Fortunately, Twitter has a lot of functionalities to get rid of the noise. Here is a list of tips I have found useful\r\n\r\n**100 follow:** If you follow more than 100 accounts, Twitter will stop promoting accounts to you. It's sad that you cannot simply ask Twitter to stop suggesting stuff... You can mitigate that by following 100 people randomly and mute them. You will have less pressure to follow people this way.\r\n\r\n**Unfollow:** When a timeline does not suit you, there are multiple strategies, but the one I always find myself doing is to unfollow noisy twittering people. People don't expect you to follow them, and it's part of a sane timeline to unfollow.\r\n\r\n**Like:** Like with your heart, use bookmarks for anything else. Likes appear on your profile and are suggested to your followers whereas bookmarks don't.\r\n\r\n**Mute:** Muting an account has wonderful effects. You won't see the tweets of the person but the person will be able to see yours.\r\n\r\n**Block:** Blocked account cannot see your tweets and Twitter will hide the person's tweets when popping on your timeline. You can force someone to unfollow you by: making your account private, blocking a person, going back to a public account. It can help with a follower annoying you in your notifications.\r\n\r\nNote: you can mute or block an advertiser if their ads annoy you, Twitter will respect your settings.\r\n\r\n**https://analytics.twitter.com** This is for the ones who have a large ego (like me)\r\n\r\n**Self retweet:** You can retweet your own tweets. This can be useful to move tweets up your timeline, also considered a bad practice if you do it too much.\r\n\r\n**Multiple Timelines:** If you want to follow someone for general knowledge, but don't want to follow them, you can create a list to save his timeline for later. I generally organize my lists by topics, but you can also have lists of one individual if you please.","language":"en","shareable":false,"publication_date":"2020-05-10T16:49:31.809265+00:00","current_slug":"how-to-make-the-best-out-of-twitter","previous_slugs":[]},{"post_id":"13590b8b-cc56-4bf3-a26b-e1a40560dded","version":19,"title":"Learning Alloy the hard way","markdown_content":"Reading [Software Abstractions](http://softwareabstractions.org/) was a blast. It is complete, very insightful in first order logic, and makes Alloy an intuitive tool. That was until page 171 and the chapter \"Leader Election In A Ring\". This chapter gave me a serious headache, and I needed to write about it here so I can clear my head out.\r\n\r\nThis article is not meant to be a tutorial on Alloy and I won't explain the logic or syntax of the language here. Sorry if you're not familiar to the language, this post won't be very easy on you. \r\n\r\n## How the book states the problem\r\n\r\nLet's imagine you have a ring of processes, the goal is to elect the leader of the group of processes. Each process will be given a unique identifier (say a MAC ID, or something) and the leader will be the process with the largest identifier. To achieve that, we'll use the [Chang and Roberts algorithm](https://en.wikipedia.org/wiki/Chang_and_Roberts_algorithm), a well known approach to solve the problem. The given Alloy code is explained first:\r\n\r\n``` alloy\r\nopen util/ordering[Time]\r\nopen util/ordering[Process]\r\n\r\nsig Time {}\r\nsig Process {\r\n  succ: Process,\r\n  toSend: Process -> Time,\r\n  elected: set Time\r\n}\r\n\r\nfact Ring { all p: Process | Process in p.^succ }\r\n```\r\n\r\nAs a complete stranger to this kind of algorithm, it took me quite some time to understand the ordering of the processes: it simulates the unique identifiers of processes.\r\n\r\nI have to point out something that bothers me at this point. The book reads \"[...] a **token** can be taken from the **pool** of one **process** and moved to the **pool** of its **successor** in the ring\" (I put emphasis on the words myself). Out of 4 concepts, two of them are completely dropped from the Alloy specification, **token** and **pool** does never appear, and it seems is replaced by **toSend**, which kind of feel an arbitrary name.\r\n\r\nThen the core of the algorithm is presented:\r\n\r\n``` alloy\r\npred step (t, t': Time, p: Process) {\r\n  let from = p.toSend, to = p.succ.toSend |\r\n    some id: from.t {\r\n      from.t' = from.t - id\r\n      to.t' = to.t + (id - p.succ.prevs)\r\n    }\r\n}\r\n\r\nfact DefineElected {\r\n  no elected.first\r\n  all t: Time - first |\r\n    elected.t = { p: Process | p in p.toSend.t - p.toSend.(t.prev) }\r\n}\r\n```\r\n\r\nAnd this is where I lost myself, not only are these steps explained in a paragraph or less, but there's no more explanation to relate the choices of writing this way compared to the original algorithm. Where are the pools, the tokens, and above all why toSend?!\r\n\r\nI was angry and I could not wrap my head around the problem. Plus it was the first time graphs presented by the examples did not help me. I did not understand the distance between the original algorithm and the solution in Alloy. I doubted Alloy for the first time.\r\n\r\n## Revamping the specifications\r\n\r\nMy hubris took place: I'm smarter than Daniel Jackson, am I not? I will revamp his example into a more faithful example. Let's look at the description of the algorithm in Wikipedia: \r\n\r\n> 1. Initially each process in the ring is marked as non-participant.\r\n>  2. A process that notices a lack of leader starts an election. It creates an election message containing its UID. It then sends this message clockwise to its neighbour.\r\n>  3. Every time a process sends or forwards an election message, the process also marks itself as a participant.\r\n>  4. When a process receives an election message it compares the UID in the message with its own UID.\r\n>       1. If the UID in the election message is larger, the process unconditionally forwards the election message in a clockwise direction.\r\n>       2. If the UID in the election message is smaller, and the process is not yet a participant, the process replaces the UID in the message with its own UID, sends the updated election message in a clockwise direction.\r\n>       3. If the UID in the election message is smaller, and the process is already a participant (i.e., the process has already sent out an election message with a UID at least as large as its own UID), the process discards the election message.\r\n>       4. If the UID in the incoming election message is the same as the UID of the process, that process starts acting as the leader.\r\n\r\nThis is the part the specification treats, the second phase of the algorithm is not modeled here.\r\n\r\nWhat do we read? Firstly, there is a notion of `participant` that is not in the specification of the book. Secondly, the message being carried out is not present in the original specification. So here is the new `Process` definition:\r\n\r\n``` alloy\r\nsig Time {}\r\nsig Process {\r\n  neighbor: Process,\r\n  token: Process -> Time,\r\n  inbox: Process -> Time,\r\n  participant: set Time,\r\n  elected: set Time\r\n}\r\n```\r\n\r\nOur goals are:\r\n\r\n- make the message passing more obvious, so we name an `inbox`\r\n- the `succ` being too close from `next`, we rename it `neighbor`\r\n- instead of having a `sendTo`, rename it `token` just as the description says\r\n- introduce the concept of `participant` that is in the description as well\r\n\r\nSince we renamed all of these concepts, I feel more confident in refactoring the `step` method:\r\n\r\n``` alloy\r\npred startsElection (t, t': Time, p: Process) {\r\n  p not in participant.t implies // (1)\r\n    p in participant.t' // (2)\r\n    and p.neighbor.inbox.t' = p.token.t // (3)\r\n    and messageReception [t', p.neighbor] // (4)\r\n}\r\n```\r\n\r\nWhenever a process `p` is not a participant (1), it becomes one (2) and sends a message in it's neighbor's inbox (3), and the neighbor will act the message reception as it should (4). The message reception logic follows the one from the description:\r\n\r\n``` alloy\r\npred messageReception (t: Time, p: Process) {\r\n  p.inbox.t = p implies p in elected.t and p not in participant.t // (4.4)\r\n  p.inbox.t in p.^next implies messageReception [t.next, p.neighbor] // (4.1)\r\n  p.inbox.t in p.^prev and p not in participant.t implies // (4.2)\r\n    p in participant.t.next\r\n    and p.neighbor.inbox.t.next = p.token.t\r\n    and messageReception [t.next, p.neighbor]\r\n}\r\n```\r\n\r\nFor each proposition, the comment links to the rule in the algorithm description above. Although this code is not perfect, I was confident it was an improvement compared to the example in the book.\r\n\r\nLet's run the code...\r\n\r\n<figure>\r\n  <img src=\"https://sadraskol.s3.eu-central-1.amazonaws.com/no-recursion-alloy.png\" alt=\"pred this/messageReception cannot call itself recursively!\"/>\r\n  <figcaption>This is what happens when you are not attentive enough</figcaption>\r\n</figure>\r\n\r\n## Hubris is not a good advisor\r\n\r\nAlright, this approach is uselessly aggressive and full of pride. I admit my anger blinded me and hubris brought me to think **I** could do better! First, I don't know a penny about concurrent algorithms (apart from distant lessons during my studies). Two, I am still a beginner in Alloy. I only used the language for its boosted graphs drawing capabilities and not for its formal logic powers. I forgot the one and only rule the author has being repeating again and again in the book: Alloy is a [first order logic](https://en.wikipedia.org/wiki/First-order_logic) langage. It means that recursions, variables bindings, etc. are not part of the tools available to express ideas.\r\n\r\nTherefore, Alloy is definitely not the intuitive approach to specifications like a typical language would be. One must bind their mind to the first order logic (pun intended).\r\n\r\n## What now?\r\n\r\nI want to try two things: first rename variables in the algorithm from the book to understand it better, then fix my own implementation to check my understanding of the approach and to formulate the limitations of the algorithm. Alright, so let's rename the variables and understand how an election can be generated by the algorithm:\r\n\r\n<figure>\r\n  <img src=\"https://sadraskol.s3.eu-central-1.amazonaws.com/ring-trace.png\" alt=\"traces of the original specification when renaming methods\"/>\r\n  <figcaption>Let's analyse the traces carefully</figcaption>\r\n</figure>\r\n\r\nWe'll try to understand this example of an election.\r\n\r\n0. At the initial state, no process is elected. We know Process2 should become elected, as it has the higher id. Each process has a token to itself. This is the initial state of every simulation\r\n1. Process0 has lost its token while others have their own token. This can be explained for a call of `step [Time0, Time1, Process0]`. Let's see how by replacing the terms in the predicate:\r\n\r\n``` alloy\r\nstep [Time0, Time1, Process0] iff {\r\n  let from = Process0.token, to = Process0.neighbor.token |\r\n    some id: from.Time0 {\r\n      from.Time1 = from.Time0 - id\r\n      to.Time1 = to.Time0 + (id - Process0.neighbor.prevs)\r\n    }\r\n}\r\n```\r\n\r\nThis substitution unravels the following predicate:\r\n\r\n``` alloy\r\nsome id: Process0.token.Time0 {\r\n  Process0.token.Time1 = Process0.token.Time0 - id\r\n  Process2.token.Time1 = Process2.token.Time0 + (id - Process2.prevs)\r\n}\r\n```\r\n\r\nSince we know that `Process0.token.Time0` is a scalar, `id` must be `Process0.token.Time0` and since we know `Process0.token.Time0 = Process0` and `Process2.token.Time0 = Process2` we can keep on reducing:\r\n\r\n``` alloy\r\nProcess0.token.Time1 = Process0 - Process0\r\nno Process0.token.Time1\r\nProcess2.token.Time1 = Process2 + (Process0 - Process2.prevs)\r\n```\r\n\r\nWe confirmed that the `Process0.token` is empty on the second step, but what about `Process2.token.Time1`? For that we need to explain `Process2.prevs`: it's all the processes with a smaller id than the current one. This term is the translation of the rule 4.3: the bigger process will discard messages of smaller ids. So:\r\n\r\n``` alloy\r\nProcess2.token.Time1 = Process2 + (Process0 - (Process1 + Process0))\r\nProcess2.token.Time1 = Process2\r\n```\r\n\r\nThat's it, the reduction is valid, we proved the predicate `step[Time0, Time1, Process0]`. Let's be a bit quicker for other steps\r\n\r\n2. Here token points from Process0 to Process1, that would happen if Process1 passed its token to Process0, this is `step[Time1, Time2, Process1]`:\r\n\r\n``` alloy\r\nlet from = Process1.token, to = Process1.neighbor.token |\r\n  some id: from.Time1 {\r\n    from.Time2 = from.Time1 - id\r\n    to.Time2 = to.Time1 + (id - Process1.neighbor.prevs)\r\n  }\r\n```\r\n\r\nAgain `Process1.token.Time1 = Process1`, therefor `id = Process1`, `Process1.neighbor = Process0` and `Process1.neighbor.prevs = {}` the empty set. We have our final reduction:\r\n\r\n``` alloy\r\nno Process1.token.Time2\r\nProcess0.token.Time2 = Process1\r\n```\r\n\r\n3. We can use the same proof: this time Process2 sent a message to Process1.\r\n4. This time, it seems that Process1 sent the message to Process0, since Process0 already had a token for Process1, it also has a token to Process2 now.\r\n5. Okay, we arrived at the crux of the algorithm, the two next step are the most important. This one is trickier, because so far, we only solved the `step` predicate with a single possible value for `id`. Since Process0 has two tokens now, there is a choice to make. We'll focus on the three options:\r\n\r\n``` alloy\r\n// id = Process1\r\nProcess0.token.Time6 = Process2\r\nProcess2.token.Time6 = Process1 - (Process0 + Process1)\r\nno Process.token.Time6\r\n\r\n// id = Process2\r\nProcess0.token.Time6 = Process1\r\nProcess2.token.Time6 = Process2\r\n\r\n// id = Process2 + Process1\r\nno Process0.token.Time6\r\nProcess2.token.Time6 = Process2\r\n```\r\n\r\nAlright, so we can see clearly that this time, it's the last option that is right. We'll keep the second option in our mind, since we can wonder if it can imply the election of Process2 in the next step.\r\n\r\n6. Finally last step, this time, we need to understand the election predicate:\r\n\r\n``` alloy\r\nfact DefineElected {\r\n  all t: Time - first |\r\n    elected.t = { p: Process | p in p.token.t - p.token.(t.prev) }\r\n}\r\n\r\n// t = Time6 and p = Process2\r\nelected.Time6 = Process2.token.Time6 - Process.token.Time5\r\n```\r\n\r\nIt means that the elected process will be the one having received his own token. The fact it just received it is garanteed by the fact that the system only evolves with the step predicate. The condition `- p.token.(t.prev)` also prevents processes that did not change to elect themselves. The process being elected is the process that has it's own token and received it from its left neighbor with the `step` predicate.\r\n\r\n## Conclusion\r\n\r\nNow that I've understood the version of the book, I'm confident that I won't be able to do better than renaming the variables. I understand now how Alloy can help in this kind of approach but I can't stop thinking that a temporal logic tool like TLA+ is a much better fit. As Hillel Wayne (yes him again!) puts it:\r\n\r\n> the more “timelike” the problem gets, the worse Alloy becomes at handling it\r\n>\r\n> [Hillel Wayne on HN](https://news.ycombinator.com/item?id=21226370)\r\n\r\nDon't be discouraged by this post to learn Alloy. I'm still convinced it is a very powerful tool to understand constraints in systems. I think that the first order logic means that you cannot use familiar techniques like recursion.\r\n\r\nAlso traces can be misleading, the first read might make you feel confident, but you need to decypher and fully understand the underlying specification. And I think this is what Daniel Jackson meant at the beginning of his book when he says Alloy focuses on the deep concepts behind your design and not intricacies of transient technology.","language":"en","shareable":false,"publication_date":"2020-04-15T10:30:07.262855+00:00","current_slug":"learning-alloy-the-hard-way","previous_slugs":[]},{"post_id":"ec706360-d93a-447a-98b6-6439fd5236a5","version":10,"title":"Le paradoxe de Picasso : pourquoi on ne peut pas faire confiance au langage naturel","markdown_content":"Au fondement de la logique, il y a les [syllogismes](https://fr.wikipedia.org/wiki/Syllogisme). \r\nAristote les formula en premier comme cela : 3 propositions s'enchaînent, 2 prémisses et une conclusion.\r\nLa conclusion est une idée nouvelle qui permet d'être déduit des 2 prémisses. Par exemple :\r\n\r\n1. Socrate est un Homme\r\n2. *Mais* Tous les Hommes sont mortels\r\n3. *Donc* Socrate est mortel\r\n\r\nLes propositions possibles dans ces syllogismes sont séparés en 4 catégories :\r\n\r\n- *A* Les affirmatives universelles : Tous les hommes sont mortels\r\n- *E* Les négations universelles : Aucun homme n'est mortel\r\n- *I* Les affirmations particulières : Au moins un homme est mortel\r\n- *O* Les négations particulières : Au moins un homme n'est pas mortel\r\n\r\nComme la sémantique est limitée, il n'y a qu'un nombre restreint de raisonnements qui font sens, tous présentés avec leur petit nom dans l'[article wikipedia](https://fr.wikipedia.org/wiki/Syllogisme#Les_modes_concluants). Avant d'aller plus loin, comprenons ce que \"valide\" veut dire en logique.\r\n\r\n## Validité et vérité\r\n\r\nOn distingue ces deux concepts dans la logique. La vérité est une valeur que l'on donne aux prémisses. On dit qu'une prémisse est soit juste, soit fausse. C'est au lecteur de décider de la vérité d'une prémisse, car s'il est facile d'admettre que \"Socrate est un Homme\" est une prémisses vraie, dire que la prémisse \"Le bonheur est bleu\" est vraie est totalement arbitraire. La logique n'est pas un outil qui permet de déterminer le vrai du faux, il s'applique à savoir si les raisonnements sont *valides*.\r\n\r\nLa validité est une propriété d'un syllogisme. Elle n'indique que si les prémisses et la conclusion sont cohérents. Grâce à un syllogisme valide, on peut dire : si les prémisses sont vraies, alors la conclusion est vraie. Ainsi La validité permet de transférer la vérité à des propriétés. La vérité serait de l'électricité, la validité serait la conductivité.\r\n\r\n## Le paradoxe de Picasso\r\n\r\nPrenons cet exemple de syllogisme :\r\n\r\n- Un Picasso bleu est rare\r\n- *Mais* tout ce qui est rare est cher\r\n- *Donc* un Picasso bleu est cher\r\n\r\nÀ priori le raisonnement est toujours valide. Ainsi on peut dire que si on utilise des adjectifs, les règles des syllogismes tiennent toujours. Pourtant, il est facile de trouver un contre-exemple à cela :\r\n\r\n- Un Picasso bon marché est rare\r\n- Mais tout ce qui est rare est cher\r\n- Donc un Picasso bon marché est cher\r\n\r\nEt c'est là que le langage naturel trouve ses limites. En utilisant un adjectif inoffensif on voit bien qu'on arrive à un raisonnement invalide. En effet, le langage naturel n'a pas pour objectif la validité de ses formulations mais d'être un équilibre entre le débit d'information et la vitesse d'assimilation.\r\n\r\n## Corriger le paradoxe\r\n\r\nPour comprendre ce qui ne colle pas, on va enlever la possibilité d'avoir des adjectifs :\r\n\r\n- Un Picasso bon marché : Il existe un Picasso bon marché (*I* affirmation particulière)\r\n- *Mais* Tout ce qui est rare est cher (*A* affirmation universelle)\r\n\r\nÇa ne suffit pas, il faut que l'enchaînement des propriétés colle. Donc on va renverser pour toujours traiter de l'ensemble de ce qui est bon marché. On peut utiliser pour cela la contraposée de l'affirmation universelle : tout P est Q est équivalent à tout \"non Q\" est \"non P\". Ce qui nous donne :\r\n\r\n- Un Picasso bon marché : Il existe un Picasso bon marché (*I* affirmation particulière)\r\n- *Mais* Tout ce qui est bon marché est commun (*A* affirmation universelle, contraposée)\r\n- *Donc* il existe un Picasso commun (*[Modus Dimatis](https://commons.wikimedia.org/wiki/File:Modus_Dimatis.svg?uselang=fr)*)\r\n\r\nUn joli _Modus Dimatis_ (je suis ravi d'apprendre ce nom en écrivant cet article), donc qui ne nous apprend pas grand chose, mais qui ne nous permet certainement pas de dire qu'un Picasso est bon marché et cher à la fois.\r\n\r\n## Langage naturel = danger\r\n\r\nLes langages naturels sont un danger pour la validité de nos raisonnements et sont souvent la raison de nos pensées magiques : l'impression d'avoir compris un problème pour découvrir plus tard que notre modèle mental est trompeuse.\r\n\r\nLa pensée magique a des antidotes, commencez par des [tableaux de vérité](https://sadraskol.com/post/methodes-formelles) pour vous soigner !","language":"fr","shareable":false,"publication_date":"2020-03-30T21:05:24.983119+00:00","current_slug":"le-paradoxe-de-picasso-pourquoi-on-ne-peut-pas-faire-confiance-au-langage-naturel","previous_slugs":[]},{"post_id":"5404dcb6-1b0c-4c18-80b3-5b2f9aeee355","version":6,"title":"Une compilation de quadrant","markdown_content":"Connaissez-vous le [quadrant](https://www.gartner.com/en/research/methodologies/magic-quadrants-research) de Gartner ? Cet indicateur est vendu par Gartner pour choisir le bon prestataire de service, comment situer l'acteur dans un marché difficile à lire. Ne nous détrompons pas : les entreprises paient des sommes suffisantes pour que Gartner fasse l'audit qui permettra de les inclure dans le quadrant, le quadrant est biaisé par défaut. Apparaître sur le quadrant devient un argument de vente pour les entreprises présentes dans le quadrant. Ce n'est pas ce qui nous intéresse ici.\r\n\r\nLe quadrant lui-même utilise deux variables pour placer les acteurs. La première est la \"completeness of vision\" et la seconde \"ability to execute\". Si l'on se place à la place d'un décideur, on veut certainement que le prestataire soit fort dans les deux variables. Pour éviter donc de diriger tout le monde vers le même prestataire (et donc perdre l'intérêt des concurrents de s'inscrire à ce quadrant), Gartner définit 4 zones pour faire que tout le monde soit content : \"Niche players\", \"Challengers\", \"Visionaries\" et les \"Leaders\".\r\n\r\nCette séparation en 2 dimensions et en séparation de l'espace permet de donner l'impression que chacun a ses forces et faiblesses et de s'introduire à une rationalisation des solutions possibles. Au-delà de l'usage superficiel qui peut être fait de cet outil, il reste à la base des études comparatives, crucial pour comparer avec hauteur et discernement.\r\n\r\n## Le quadrant de Kano\r\n\r\nLa [méthode de Kano](https://uxways.wordpress.com/2018/11/21/la-methode-kano/) permet d'évaluer la pertinence d'une fonctionnalité en répondant à deux questions : Quel est mon sentiment si la fonctionnalité est présente ? Quel est mon sentiment si la fonctionnalité est absente ?\r\n\r\nEncore une fois la catégorisation est capitale : une fonctionnalité est soit \"indispensable\", \"performante\", \"attractive\" ou \"répulsive\". La position relative de chaque fonctionnalité importe assez peu car c'est surtout la catégorie qui va aider à comprendre son utilité.\r\n\r\n## Les limites du quadrant\r\n\r\nJe fais une parenthèse dans cette énumération de quadrants, car il me semble capital de contextualiser les quadrants. Leur aspect magique de catégorisation n'est pas absolu car 1) l'arbitraire des deux variables utilisées rend facile l'attaque de l'étude et 2) rien ne dit que le quadrant sera pertinent dans le futur.\r\n\r\nPour le premier point, il ne faut pas oublier que le quadrant n'est pas une étude comparative et qu'il faut multiplier les points de vue sur un problème pour évaluer finement les possibilités. Si vous voulez un exemple d'étude plus fine, vous pouvez consulter cette étude comparative de 7 langages pour réimplémenter [0install](http://roscidus.com/blog/blog/2013/06/09/choosing-a-python-replacement-for-0install/).\r\n\r\nLe temps est le second traître des quadrants et des études comparatives en général. Ce n'est pas un hasard si Gartner dépublie leurs articles car les acteurs de 2014 ne sont plus ceux de 2020. Il en est de même de l'étude sur [0install](http://roscidus.com/blog/blog/2013/06/09/choosing-a-python-replacement-for-0install/) : les résultats sur rust ne serait certainement pas les mêmes aujourd'hui vu son évolution depuis 2013. Paradoxalement les quadrants sont tels la beauté des fleurs : aussi puissants qu'ils sont éphémères.\r\n\r\n## Se débarrasser des variables\r\n\r\nIl existe un quadrant qui ne s'embarrasse pas des variables et ne garde que les catégorisations. C'est le cas du framework [Cynefin](https://en.wikipedia.org/wiki/Cynefin_framework). Ce que le quadrant perd en finesse, il le gagne en assertivité. Je dois admettre ne pas comprendre ce genre de framework basé sur des théories assez fumeuses. Je laisse le lecteur juge des interprétations que formule ici.\r\n\r\nCe qui semble crucial dans ce genre de quadrant, c'est la capacité de la personne qui manipule le framework qui va donner l'illusion de son efficacité, non le framework lui-même. La catégorisation sera facilement compréhensible pour la personne qui lit le résultat, mais ne m'aidera pas à mieux comprendre un problème. Cela est dû à une difficulté à catégoriser les problèmes : un problème simple pour une entreprise sera complexe pour une autre et vice-versa. Les critères d'attribution deviennent tellement subjectifs que ce n'est pas le quadrant qui fait le travail mais son manipulateur.\r\n\r\nNéanmoins, Cynefin n'est pas un échec total du point de vue des quadrants, il existe bien pire.\r\n\r\n## Comment louper son quadrant\r\n\r\nSi le quadrant du Cynefin est douteux, il est aussi possible de totalement loupé un quadrant. C'est à mon avis le cas des études de Redmonk, en particulier le [classement des langages les plus populaires](https://redmonk.com/sogrady/files/2020/02/lang.rank_.120.wm_.png). Cette fois-ci il y a aussi deux variables : Le nombre de dépôt Github et la popularité sur StackOverflow. Par contre pas de catégorisation des langages. La majorité des langages étant proches du même axe, les langages sont finalement très homogènes. Or l'intérêt de la catégorisation est justement de discriminer intelligemment les choix sans les réduire à une variable arbitraire discutable.\r\n\r\n---\r\n\r\nLa force du quadrant est qu'il complexifie assez le problème pour éviter d'être dogmatique, et rend plus difficile d'attaquer les critères choisis. Il est clairement le plus utile quand il est utilisé pour répondre à une question simple : cette fonctionnalité est-elle nécessaire ? Cette tâche est-elle à faire ? etc. L'exemple de Kano est bon car il a permis de bien prioriser les fonctionnalités. J'aurais pu aussi présenter le [quadrant d'Eisenhower](https://en.wikipedia.org/wiki/Time_management#The_Eisenhower_Method) qui est aussi très discriminant et permet de répondre à un problème avec peu de variables.\r\n\r\nIl est utile cependant d'utiliser d'autres méthodes quand la décision est plus importante. Les études qualitatives (comme celle de [0install](http://roscidus.com/blog/blog/2013/06/09/choosing-a-python-replacement-for-0install/)) ou des méthodes impliquant plus de participants et de documentation sont à favoriser.\r\n\r\nMon quadrant favori n'est pourtant aucun de ceux nommés :\r\n\r\n<figure><img src=\"https://sadraskol.s3.eu-central-1.amazonaws.com/quadrant.jpeg\" alt=\"Economic-Left/Authoritarian: It's ___state, Economic-Right/Authoritarian: ________, Economic-Left/Libertarian It's Free ___, Economic-Right/Libertarian: It's ___ Real Estate, \"/><figcaption>Tim & Eric + Internet</figcaption></figure>\r\n\r\n---\r\n\r\nP.S. : alors que je relis mon article pour le publier, je remarque que je suis un piètre blogueur. Le vrai blogueur aurait fini l'article sur un quadrant de quadrants, rendant bien plus passionnant l'article. Je laisse l'exercice au lecteur motivé par des heures de recherches de quadrants plus ennuyants les uns que les autres !","language":"fr","shareable":false,"publication_date":"2020-03-16T12:54:16.271720+00:00","current_slug":"une-compilation-de-quadrant","previous_slugs":[]},{"post_id":"8ef6d940-a5a1-4a99-8936-14c5cbc3948a","version":27,"title":"Méthodes formelles","markdown_content":"Je cite souvent Hillel Wayne et il cite souvent les méthodes formelles. Pour expliquer ces concepts, j'ai décider d'apprendre à utiliser différentes méthodes légères pour modéliser un cas d'usage.\r\n\r\nDeux concepts sont au cœur des méthodes formelles :\r\n\r\n- La conception formelle : comment concevoir des fonctionnalités sans ambiguïté\r\n- La vérification formelle : comment vérifier que les fonctionnalités n'ont pas d’ambiguïté\r\n\r\nLes deux concepts sont très liés car on ne peut répondre qu'aux deux problèmes en même temps. Par contre, les deux fournissent des outils différents.\r\n\r\nPour illustrer les outils et leurs limitations, nous allons spécifier le cas d'usage suivant :\r\n\r\n- Pour utiliser le service X, il faut que l'utilisateur ait vérifié son email\r\n- Tout utilisateur peut changer son email\r\n- Pour vérifier son email, l'utilisateur doit appeler le lien unique contenu dans l'email envoyé lors de son inscription\r\n- Les emails venant du domaine `gmail.com` ne peuvent pas être vérifiés (disons que ce n'est pas la cible du service X)\r\n\r\nCette spécification est ambiguë car faite pour : [https://www.hillelwayne.com/post/feature-interaction/](https://www.hillelwayne.com/post/feature-interaction/)\r\n\r\n## La table de vérité\r\n\r\nOutil issu du domaine de la logique booléenne, la table de vérité est un outil très simple à appréhender les problèmes qui peuvent se réduire à des propositions logiques.\r\n\r\n| Lien envoyé | Email en `gmail.com` | Lien visité | Accès au service X |\r\n|---|---|---|---|\r\n| Non | Oui | X | Non |\r\n| Non | Non | X | Non |\r\n| Oui | Oui | Oui | Non |\r\n| Oui | Non | Oui | Oui |\r\n| Oui | Non | Non | Non |\r\n| Oui | Oui | Non | Non |\r\n\r\nC'est la seule table de vérité que j'ai réussi à faire pour lever l'ambiguïté. En entrée (les trois premières colonnes), on note si la proposition est vraie ou fausse, et on entre dans la dernière colonne si l'accès au service est permis ou pas. Je me suis permis de réduire le tableau dans le cas où on n'envoie pas de lien, car dans ce cas, il n'est pas possible pour l'utilisateur de visiter le lien qui n'existe pas.\r\n\r\nLes tables de vérité ont été popularisé par le philosophe et logicien [Ludwig Wittgenstein](https://en.wikipedia.org/wiki/Ludwig_Wittgenstein). Elles sont un premier pas pour vérifier les spécifications. Bien que formellement correcte, l'ambiguïté de la spécification n'est pas levé par la table elle-même : de quel email parlons-nous quand on dit que `gmail.com` est interdit ? L'erreur peut encore se glisser dans le manque de clarté dans la définition des termes.\r\n\r\n## Le diagramme de flux\r\n\r\nLe deuxième outil léger pour faire de la spécification formelle : les diagrammes de flux. Plutôt que de se concentrer sur un état fixe, on se concentre plutôt sur l'enchaînement des actions et des conditions. Les outils tels que [DRAKON](https://en.wikipedia.org/wiki/DRAKON) permettent ensuite de vérifier que de tels schémas sont cohérents, voire de générer du code à partir de ceux-ci. Attention DRAKON n'est pas un outil de graphes, mais bien de spécification. On peut valider le modèle contrairement aux outils de dessin qui permettent des graphes incorrects.\r\n\r\n<figure><img src=\"https://sadraskol.s3.eu-central-1.amazonaws.com/drakon.png\" alt=\"diagramme DRAKON de la spécification précédemment présentée\"/><figcaption>Spécification avec DRAKON</figcaption></figure>\r\n\r\nLes diagrammes ont une lisibilité et une facilité de compréhension sans pareil. Ils ont été conçus dans ce but et c'est une valeur sur pour explorer des processus métiers. On peut mieux saisir les contraintes temporelles, limiter les variables changeantes. Dans notre cas on peut lever facilement l'ambiguïté de la spécification en nommant un \"Email To Verify\" et un \"Secondary Email\".\r\n\r\nIl est intéressant de voir que l'on peut rapidement exploser la complexité tout en restant clair sur les cas qui amène aux mêmes finalités. Alors que les tables de vérité peuvent vite devenir incompréhensibles au fur et mesure de l'augmentation du nombre de cas, il est plus facile de suivre un diagramme de flux, car les trajectoires sont tout de suite reconnues par notre œil habitué à ces motifs. Pour vous en convaincre, réaliser le tableau de vérité qui correspond à la séquence \"User Inbox\" de notre diagramme : vous vous retrouverez avec 3 entrées, 2 sorties et 8 lignes pour explorer tous les cas.\r\n\r\n## Le langage de spécification\r\n\r\nPour l'instant, nous n'avons utilisé que des outils de spécifications qui pourrait être fait sur papier rapidement. Nous allons à présent utiliser un langage de modélisation. Dans les outils de spécification, le langage de spécification est le plus avancé car il permet de fournir des vérifications très avancées et automatiques. Par exemple TLA+ peut explorer rapidement des problématiques pour évaluer des problèmes de concurrence. Pour notre cas, nous allons utiliser Alloy pour vérifier la validation des emails. Le langage se veut similaire de l'orienté objet et permet de produire des exemples et des contre-exemples aux contraintes que l'on fournit.\r\n\r\n#### La logique de validation\r\n\r\nAlloy étant difficile à saisir rapidement, nous allons spécifier chaque partie de la fonctionnalité itérativement.\r\n\r\n``` alloy\r\nopen util/ordering[Service] // L'objet \"Service\" sera représenté par des états successifs\r\n\r\nsig Email {}  // On définit le set d'emails\r\nsig User {} // ainsi que les utilisateurs\r\n\r\n// Pour chaque état du service\r\nsig Service {\r\n\tlive: set User, // on a un set d'utilisateurs utilisant le service\r\n\tverified: set User, // Le service aura un set d'utilisateurs vérifiés\r\n\temail: User -> one Email, // Pour chaque utilisateur il y a un email\r\n} {\r\n\tverified in live // les utilisateurs vérifiés utilisent le service\r\n\tlive = User // on ne s'intéresse qu'aux utilisateurs qui utilise le service\r\n}\r\n\r\n// Les relations d'utilisateurs à Email ne changent pas : L'utilisateur ne peut changer son Email\r\nfact { all s, s': Service | s.email = s'.email }\r\n\r\n// Un utilisateur vérifié restera toujours vérifié\r\nfact { all s: Service, s': s.next | all u: s.live | u in s.verified => u in s'.verified }\r\n\r\n// Exemple avec aucun utilisateur vérifié au départ et tous les utilisateurs véfifiés dans le dernier état\r\nrun { no first.verified && last.verified = User }\r\n```\r\n\r\nLa commande `run` permet de demander à Alloy de générer des exemples de la spécification. L'aide visuelle est très pratique, on peut ainsi rapidement explorer les incohérences du modèle.\r\n\r\n\r\n<figure><img src=\"https://sadraskol.s3.eu-central-1.amazonaws.com/email.png\" alt=\"Exemple de la spécification présenté, avec un utilisateur vérifié\"/><figcaption>Exemple visuel de notre modèle</figcaption></figure>\r\n\r\n\r\n#### Exclusion des Emails en Gmail\r\n\r\nPour spécifier le fait que les emails peuvent être `@gmail.com`, on va étendre le set d'emails :\r\n\r\n``` alloy\r\nsig Gmail extends Email {}\r\n```\r\n\r\nEnsuite on introduit la notion de lien envoyé à l'utilisateur et qu'il ne sera validé que s'il n'est pas dans `Gmail` :\r\n\r\n``` alloy\r\nsig Service {\r\n\tlive: set User,\r\n\tverified: set User,\r\n\temail: User -> one Email,\r\n\tlink: User -> one Email\r\n}\r\n\r\n// ...\r\n\r\n// Les utilisateurs ne peuvent pas changer de lien d'inscription\r\nfact { all s, s': Service | s.link = s'.link }\r\n// Les utilisateurs ne peuvent pas changer d'Email\r\nfact { all s, s': Service | s.email = s'.email }\r\n// si l'utilisateur est vérifié, son email `u.(s.email)` dans le précédent état n'appartient pas à Gmail\r\nfact { all s: Service, s': s.next | all u: s'.verified | u.(s.email) in Email - Gmail }\r\n```\r\n\r\nEnfin on vérifie que notre modèle est correct :\r\n\r\n``` alloy\r\ncheck { all s: Service | all u: s.verified | u.(s.link) in Email - Gmail } for 3\r\n```\r\n\r\nIl est à noté qu'étant un vérificateur partiel, on ne peut faire des vérifications que pour un nombre limité de cas avec le mot clé `for x` (ici 3 instances de `Service`). On peut augmenter notre confiance dans le modèle en augmentant ce paramètre.\r\n\r\n\r\n#### Possibilité de changer les Emails\r\n\r\nEnfin, on peut rajouter à l'utilisateur la possibilité de changer d'email. On enlève la contrainte sur le modèle précédent et rajoutons la condition que l'utilisateur ne peut pas à la fois changer d'email et confirmer son email au même moment :\r\n\r\n``` alloy\r\nfact { all s: Service, s': s.next | all u: s'.verified | u in s.live - s.verified => u.(s.email) = u.(s'.email) }\r\n```\r\n\r\nOn peut faire tourner le modèle et là... patatra, un contre exemple est trouvé :\r\n\r\n<figure><img src=\"https://sadraskol.s3.eu-central-1.amazonaws.com/counter.png\" alt=\"Contre exemple à la spécification: l'utilisateur passe d'un email en gmail à un email autorisé pour se vérifier au service\"/><figcaption>Contre exemple !</figcaption></figure>\r\n\r\nComme vous le constatez, l'utilisateur change son email avant de cliquer sur le lien et cela lui permet de valider le mauvais email. La solution devient évidente : on doit vérifier l'email auquel le lien est envoyé et non à celui de l'utilisateur.\r\n\r\n``` alloy\r\nfact { all s: Service, s': s.next | all u: s'.verified | u.(s.link) in Email - Gmail }\r\n```\r\n\r\nEt voilà que Alloy valide qu'il ne trouve plus de contre exemple, même si on augmente le nombre d'occurrence !\r\n\r\n### Alloy\r\n\r\nC'est la première fois que j'utilise Alloy et j'ai évité de parler des problèmes que j'ai rencontré (toujours pas compris `not in`) et la documentation est assez peu bavarde. Par contre, il est assez simple de vérifier que le modèle est cohérent grâce à la visualisation des états. Bien que le cas choisi peut sembler assez évident, Alloy est le seul outil utilisé qui permet de valider le modèle sans lever l'ambiguïté par distinction de grammaire. Les autres outils avaient besoin de spécifier \"L'email à vérifier\" ou pirouette du genre pour cela, ce qui pourrait être de la triche. Il est donc normal que sa prise en main soit moins facile (j'ai pris une journée pour lire le [tutoriel](http://alloytools.org/tutorials/online/index.html) et réalisé le modèle tout en écrivant l'article).\r\n\r\nMalgré ses apparences trompeuses (Alloy se donne des airs de langage orienté objet, alors que c'est vraiment un jeu sur les sets), je suis surpris d'avoir si facilement pris en main l'outil et je vais passer mon temps à imaginer comment l'utiliser au boulot. D'autant que je n'ai pas exploré l'utilisation des modules ou des fonctions.\r\n\r\nJe suis fermement convaincu de l'utilité des outils de formalisation partielle. En apprenant à les utiliser, on apprend aussi à spécifier nos besoins avec moins d'ambiguïté. On peut plus facilement trouver la bonne représentation qui permet de faire comprendre à une personne sans connaissance sur un sujet complexe les problèmes que l'on peut rencontrer lors de son implémentation. Je ne suis néanmoins pas convaincu que les langages de formalisation comme Alloy trouveront grâce aux yeux de la majorité des développeurs vu les prérequis et la motivation nécessaire pour modéliser avec ces outils. Espérons que cet article vous aura convaincu à vous y pencher.","language":"fr","shareable":false,"publication_date":"2020-02-23T20:33:08.681927+00:00","current_slug":"8ef6d940-a5a1-4a99-8936-14c5cbc3948a","previous_slugs":[]},{"post_id":"52dad5e2-65f1-48f4-abb4-89acf897ab81","version":9,"title":"Divers : Foucault et intuition","markdown_content":"## Le savoir et la remise en cause de la morale\r\n\r\nAu micro de Jacques Chancel, Foucault tenait ces propos sur l'école :\r\n\r\n> \"Imaginez que les gens aient une frénésie de savoir comme ils ont une frénésie de faire l'amour. Vous imaginez le nombre de gens qui se bousculeraient à la porte des écoles ? Ce serait le désastre social total. Il faut bien, si l'on veut restreindre au maximum le nombre de gens qui ont accès au savoir, le présenter sous cette forme parfaitement rébarbative et ne contraindre les gens à savoir que par des gratifications annexes sociales qui sont précisément la concurrence ou les hauts salaires enfin en fin de course, etc.\"\r\n\r\nJ'aimerais tellement avoir la capacité de remettre en jeu les institutions et les opinions que je \"fais comme si j'y croyais\" comme dit Deleuze. Je cherche sans cesse à remettre en cause les savoirs institués, d'être méfiant des prêcheurs de la bonne parole et de la doxa. Il m'a profondément aidé à reconnaître dans le \"Clean Code\" une morale venant oppresser les développeurs avec des pratiques arbitraires. À voir dans certains combats contre les \"Silver Bullet\", un discours normalisateur et promouvant le statu quo avant tout autre critère de jugement.\r\n\r\nJ'ai lu \"Clean Code\" à une époque où tout mot m'était promission. Je n'avais pas le recul critique pour comprendre ce qui n'allait pas dans la séparation manichéenne du \"good code\" et du \"bad code\", expression littérale de l'introduction. Il me faut maintenant un effort monumental pour remettre en question ces \"conseils\" devenus si familiers pour moi. La familiarité est le moment du voyage où l'on ne sait plus revenir en arrière...\r\n\r\n## Réflexion sur la familiarité (inspiré de ce [blog](https://www.asktog.com/papers/raskinintuit.html))\r\n\r\nÀ l'école, j'avais une calculatrice HP en [notation polonaise inversée](https://fr.wikipedia.org/wiki/Notation_polonaise_inverse) que mon beau-père m'avait confié. Alors que j'étais d'abord attiré par la magie de faire des calculs à l'envers, je me suis vite rendu compte de l'incroyable facilité qu'elle offrait pour résoudre des calculs complexes et intriqués. Mes camarades de classe se sont moqués de moi lorsque je tentais d'expliquer le paradigme, qu'il ne fallait pas écrire l'équation de manière littérale, mais essayer de faire les opérations \"dans l'ordre\". La notation m'était devenue familière. J'avais emprunté un chemin et tel un petit poucet dont les bouts de pain sont mangé par les oiseaux, je ne pouvais retrouver le chemin de la calculatrice à notation infixée.\r\n\r\nL'intuition est mauvaise conseillère. Elle est conditionnée par un seul facteur : ce que l'on sait déjà des choses. Pour juger une nouvelle interface, on va suivre notre intuition et suivre l'avis qu'elle seule aura conçu. Pour juger équitablement un outil, il faut donc ne pas prendre en compte l'intuitivité de celui-ci.\r\n\r\n","language":"fr","shareable":false,"publication_date":"2020-01-19T01:28:59.019446+00:00","current_slug":"divers-foucault-et-intuition","previous_slugs":[]},{"post_id":"6f8603b9-0288-4fed-8138-08e9c4b8cd14","version":0,"title":"Press review #7: sleep, remote and verbs","markdown_content":"For this version I have a lot of article to talk about:\n\n- [This article](https://increment.com/teams/the-epistemology-of-software-quality/) on how stress and sleep are way more impactful than technology, processes and paradigms. It's not the first time Hillel shows up in my review, that is because his work on empirical research provide a lot of solid insights\n- [This article](https://usefyi.com/remote-work-best-practices/) on best practices for remote work. I've worked remotely for 3 years, for the best and the worst. You should not underestimate the effort to put in clear communication, self-care and time sharing\n- [This article](https://chris-martin.org/2017/interfaces-and-records) on how to implement the equivalent of interface from Java in Haskell. This article provides a good pattern and a right comparison between these very different languages\n- [This article and conference](https://argumatronic.com/posts/2018-09-02-effective-metaphor.html) is insightful at what makes abstractions so powerful. I have to steal this first slide!\n- [This answer](https://www.quora.com/Will-coding-be-a-minimum-wage-job-in-50-years/answer/Travis-Addair) on why we will still need coders in the future. \"The languages are easy, it’s the problems that are hard.\" is at the core of my values","language":"en","shareable":false,"publication_date":"2019-12-05T20:36:49+00:00","current_slug":"press-review-7-sleep-remote-and-verbs","previous_slugs":[]},{"post_id":"24e806b1-b4b6-4870-9353-04a21a0eb1e7","version":0,"title":"Press review #6","markdown_content":"2 years after my last [press review](https://sadraskol.com/posts/press-review-5), I'm rebooting the format. I feel my blog reading has not been great lately, I want to learn a bit better.\n\n- An [nice article](https://increment.com/testing/testing-the-boundaries-of-collaboration/) from Kent Beck explaining reasoning behind TCR (Test && Commit || Revert). I like how small changes are valued for their stability and simplicity. I admit, I doubt it can be scalable in most companies, but it can be really fun to try at a coding dojo.\n\n- Every software practice is an opinion, thoughts leaders are more opinion marketers. In his [talk](https://www.hillelwayne.com/talks/what-we-know-we-dont-know/) Hillel Wayne explains what can be saved thanks to empirical studies on engineering practices. 3 points : tests are just as useful as parachutes, code review are great, all sleep and no stress are the most effective ways to build software.\n\n- Also, there's a [new release](https://info.crunchydata.com/blog/just-upgrade-how-postgresql-12-can-improve-your-performance) of postgres and it looks pretty awesome, can't wait to try it !\n\n### Tweets !\n\n> \"Mistakes are expected, respected, inspected, and corrected.\"\n\n[This](https://twitter.com/bcantrill/status/1164725111171104768) is my mantra from now on, acceptance and redemption are not easy tasks and should be taken seriously. \n\n> programmers should learn the fundamentals of programming\n> - sending emails\n> - listening\n> - team work\n> - thinking about consequences\n>\n> *[source](https://twitter.com/tef_ebooks/status/1169652186370007040)*\n\nBy sending emails, I understand learn to communicate, apart from this detail, I can't agree less.\n\nFinally, there's been a lot going on in the Scala community lately on twitter. I want to point out this [tweet](https://twitter.com/argumatronic/status/1169725383844872192): when people say things or point out to facts, there's no smear campaign only recognition of what happen and how it affected them.","language":"en","shareable":false,"publication_date":"2019-09-06T19:20:06+00:00","current_slug":"press-review-6","previous_slugs":[]},{"post_id":"31dd4571-d71f-432b-be8e-0c283e4a9513","version":3,"title":"Lara Hogan's Resilient Management, reading notes","markdown_content":"I read Lara's book carefully taking a lot of notes compared to other books. It is filled with 101 management, wise and practical advises for everyday life as a manager. Even I, being a developer aspiring to management positions, could get some really good insight to what to expect from a manager. My notes consist of quotes mixed with my own comments. Writing the post allows me to fixate this knowledge somewhere for future reference.\r\n\r\n## My notes\r\n\r\nA manager works around 4 dimensions in a team:\r\n\r\n- __Resiliency__\r\n- __Human growth__\r\n- Delivery\r\n- Cross-functional strategy\r\n\r\nThe book focuses on the two firsts. As those two skills revolve around the team dynamics, Lara uses Bruce Tuckman's stages of group development. Those stages are necessary before having a performing team. If a stage is neglected, the team will be stuck and won't perform as expected, even if the individuals are brilliant. The 4 stages consists of:\r\n\r\n- Forming: people getting to know each other\r\n- Storming: frictions arise, people faces each others needs\r\n- Norming: when people agree on aligning their goals\r\n- Performing: the team is at max delivery capacity\r\n\r\nAs Lara points out, even if you are at the last stage, meaningful even will break the group dynamic and you're back at the forming stage. Like Sisyphus, you have to carry the rock up the mountain again. The job of the manager is to be like Albert Camus: imagine Sisyphus happy! His role is to make sure the performing stage is obtained soonest possible.\r\n\r\n### Meet your team\r\n\r\nThe forming stage is a \"question of balance, not perfection\". The first important step is to know yourself. What do you want from the team and what do you want to achieve? What do you value? In order to answer to this question, Lara suggests using the BICEPS values. I've done mine, so I can follow myself better:\r\n\r\n- <b>B</b>elonging: I need a couple of people to trust, I'm thrive when I can rely on a couple of people, no more\r\n- <b>I</b>mprovement/Progress: I need to see myself learning a lot. it's likely one of my core value. I want to learn from my colleagues and from meetups.\r\n- <b>C</b>hoice: My core value, I want to make the choices and not obey to one's will. I can do anything if I choose to do it, but impose me a task and I'll Bartleby your ass (\"I'd rather not\")\r\n- <b>E</b>quality/Fairness: I am not very demanding on fairness, but I'm not sure I understand this value well enough\r\n- <b>P</b>redictability: I like to understand the people I'm working with, I would be less confident exposing my opinions otherwise\r\n- <b>S</b>ignifiance: I welcome rewards when I deliver nice stuff\r\n\r\nOnce you know yourself, you can start asking others about themselves. You can ask for their BICEPS or guess them yourself. There's plenty of questions available out there to better understand your teammates. Lara points out something really important: accept the differences, you value something different from other people and it's okay! They can enjoy being put in the spotlight, or dislike it, it's all okay as long as you accept them as they are and not as you want them to be. Yoga has a word for this: Samtosha, accepting the world as it is.\r\n\r\nOne good question Lara asks is: what do you optimize for? Most of the time, frictions come from diverging directions. Understanding what people optimize for allow us to accept other's reaction and decisions.\r\n\r\n### Grow your teammates\r\n\r\nDo you know the difference between mentoring and coaching? Mentoring is saying what you would do at another person's place. Coaching on the other hand is helping the person grow by herself, a bit like a Socratic method, asking the right questions to show that the person has the resources to answer her own problems. As noted by Lara, mentoring is the go-to posture for most starting managers or leaders, but coaching is so much more efficient!\r\n\r\nIn order to be more in a coaching position, be less solution focused and do not judge the situation. Ask questions starting with \"What\" or \"Who\", like \"What's holding you back?\" or \"Who would you like to emulate on this problem?\". Act like a mirror in front the person by exploring more deeply her issue, leave her space to be listened to.\r\n\r\nOnce in a while you will have return feedback to a person, it can be a tricky situation, especially if the feedback is negative and can attack the person on her core values. Lara's solution lies in the feedback equation: __Observation__ + __Impact__ + __Request__ = __Good feedback__. The observation is a simple and cold factual report on a behavior *\"you left the meeting early without warning\"*. The impact is the effect on the team or yourself *\"we could not ask for help on this thing you worked on*. Finally the request is a coaching question that makes the feedback actionable *\"What format of meeting would you prefer to get you onboard?*. I'm not sure my example is good, but I guess I need to learn to do better feedbacks myself.\r\n\r\n### Set clear expectations\r\n\r\nFirst thing: inform on people's role & the responsabilities of those roles. Documented roles sets expectations for everyone. When roles are not clear on a project and there's confusion and miscommunication use a RACI. It informs on people's role in a project:\r\n\r\n- Responsible: will perform the task\r\n- Accountable: in charge of the good delivery of the task\r\n- Consulted: can provide his opinion during the process of the task\r\n- Informed: is informed of the advancement of the task, does not take part in the decisions taken\r\n\r\nAlthough I've already heard of this before, I never realised the simplicity and nice effect it can have on a stuttering project.\r\n\r\nAlso need to document the team's vision or mission statement. It allow to explain the priorities and better balance decisions. Also document the team's meeting and way to work so newcomers integrate easily. Retrospect on your team practices to adapt them with better insights.\r\n\r\nEtsy rules of communications are as follows: Reflect, Elevate, Assume good intentions, Listen. They ensure that everyone is on the same page, and that people interact effectively.\r\n\r\n### Communicate effectively\r\n\r\nPeople overestimate the ability of email recipients to understand an email out of context. They fill the gaps with stereotypes and false guesses. So no, a \"useless\" meeting could not have been replaced by an email. There's plenty of meetings that are useful, and foster motivations, communication and trust.\r\n\r\nRepeat information as much as you can, people don't accept new piece of information the first time its stated to them. It's okay because we all do that.\r\n\r\nThere are plenty of emotions and kind of energy to use to convey information, experiment and know to use them as emotions are a key part of a message being delivered, it plays a key role in the phatic function of language. Different mood can be:\r\n\r\n- Anger, frustration, urgency\r\n- Cautiousness, hesitation (it's my best one)\r\n- Lighthearted, effervescent\r\n- Compassionate\r\n- Calm, collected, steady\r\n- Creative\r\n- Ambiguous\r\n- Blunt, cut and dry\r\n\r\nAdapt your mood and listen to your team's priority to get the message through.\r\n\r\nFinally, being a manager can be exhausting. You will feel alone and lost some times. It's important to connect with other managers to share your difficulties, to change perspective and find help. Although I'm no manager, I definitely understand this step, as meeting other developers helped me to feel less lonely in the shitty job I started with.\r\n\r\n---\r\n\r\nMy notes are personal, I skipped a lot of what Lara covers in her very complete book. I can only recommend you get your own to dig subjects I covered very superficially.","language":"en","shareable":false,"publication_date":"2019-08-09T09:44:24+00:00","current_slug":"lara-hogan-s-resilient-management-reading-notes","previous_slugs":[]},{"post_id":"bdf59052-9f40-489c-bb51-c297a54fc215","version":0,"title":"Two busy weeks","markdown_content":"This is the story of two rich weeks I've just been through. I've attended to three events in a row, depleting all the energy I had, but also teaching me so much!\n\nIt all started Tuesday 14th with a conference day with the whole tech team of Malt. It was the first time all of us gathered and shared knowledge on our different specialties. We had the chance to listen to brilliant [Nickie Roudez](https://twitter.com/Nickie_rdz) explain CSS grids, [Aurélia Amalvict](https://www.linkedin.com/in/aurelia-amalvict/) showing the power of K-means to explore users topologies, [Nicolas Demengel](https://twitter.com/NicolasDemengel) explaining how hexagonal architecture works, etc. It was a perfect opportunity to discover all the team members I haven't met so far (we've more or less doubled in the last 6 months) and explore new challenges.\n\nI've [captured](https://twitter.com/sadraskol/status/1128246912652541953) the whole team during a session, aren't we beautiful?!\n\n### Newcrafts 2019, Paris\n\nThe next day, I was on my way to Paris to attend [Newcrafts](http://ncrafts.io/) and present my introduction to event source programming. I was quite stressed out since the training session went quite badly. I prepared a lot to mitigate all the problems I had encountered and defined the goals of each steps of the workshop. The conference started crazy with Clément Delafargue able of explaining hexagonal architecture in a [single slide](https://clementd-files.cellar-c2.services.clever-cloud.com/ncrafts-monad-stacks.html#11.0) and showing how monad transformers solved problems usually solved by dependency injection frameworks in OOP languages.\n\nI was delighted by how [Patrick Kua](https://twitter.com/patkua) explained the trident career development they implemented at N26. Although I'm not sure it can be extended to any organization, and I still prefer Camille Fournier's vision of technical management, He explained and captured the essence of the technical lead perfectly: multiplier of knowledge, unifier of technical practices and beholder of the long term vision.\n\n[Kevlin Hennley](https://twitter.com/KevlinHenney) spoke about his vision of software ethics and the balance between rationality, emotion and compassion. I'm not sure his talk will remain as important to me as the [passion gospel](http://www.virtuouscode.com/2014/02/10/the-passion-gospel/) article I've already mentioned, but he sure mentioned one of my favorite quote of twitter:\n\n> One of my most controversial software opinions is that your sleep quality and stress level matter far, far more than the languages you use or the practices you follow. Nothing else comes close: not type systems, not TDD, not formal methods, not ANYTHING. *[source](https://twitter.com/hillelogram/status/1119709859979714560)*\n\nI'm gonna stop enumerating conferences I attended one at a time, otherwise it'll take me a month to write everything I learned, but I want to speak about that one term I'm happy of finding during these events: the corridor conference. It consists of not going to the organized conferences and wander around the venue and speak with random people. I think it's the best conference you can attend. It allows you to discover wonderful individuals and speakers you didn't know of.\n\n### Mixit 2019, Lyon\n\nMixit is a community event focusing on diversity and openness. I finally had the chance of seeing Woody Zuill on stage. He presented how he and his team implemented the mob programming concept not for a workshop but for actually working all together. I admit I'm skeptical at the effects on the long run of such techniques, they look to me like real Panopticon (more on that by [Romeu Moura](http://videos.ncrafts.io/video/275530213)). It could really be a surveillance tool by the company (funny enough Woody showed surveillance camera movies to illustrate the efficiency of his method). The interesting part is that management did not interfere with the team decision on how they were working, or that they supported their decision depending on where you see it.\n\nIn the middle of other interesting conferences, I've attended an improv class, which is the best thing I taught myself in ages. It really reminded me of choir, except that you can hide yourself behind a character.\n\n### Close up\n\nI had the opportunity to learn, to share, to bound with colleagues, to have fun, to confront my world view and to do all of that in a kind and respectful environment. I consider myself lucky to thrive in such a positive environment. I consumed a lot of my energy but it was really worth it. You can expect some other blog posts coming soon on thoughts that have been running in my head and I'm now ready to write down.\n\nCheers!","language":"en","shareable":false,"publication_date":"2019-05-31T21:20:23+00:00","current_slug":"two-busy-weeks","previous_slugs":[]},{"post_id":"72339715-55f4-4c1a-9ead-0d99359fc275","version":0,"title":"Speaker's notes : discover event-driven programming","markdown_content":"General advice:\n\n* Make sure to have a bottle of water nearby\n* Open `xrandr` options before it starts\n* Open [pursuit](https://pursuit.purescript.org/) before it starts\n* Changing the police is `CTRL + 6` and `CTRL + =` on alacritty\n* Find a high contrast theme for alacritty (no light green or yellow)\n* Prepare some slides to tell the audience what they have to do\n* One screen, one window\n* Purescript ain't rocket science but make sure to explain basic syntax when introducing it (pattern matching, function signatures, records, hof, etc.)\n* We're using purescript, but it can obviously be done in any language\n\nNext up, how should I present each steps:\n\n## Event storming\n\n* Quick intro to event storming\n* Separate in groups if too many attendees\n* Focus on naming events and their fields\n* Leave the `type` step at the end\n* Explain the problem, let participants decide how to tackle the issue\n\n## Implementing the view\n\n* Remind attendees they are the brain, I write their implementation\n* Repeat every suggestions and clear out any misunderstanding\n* Let people disagree\n* Start with a simple unit test (remember using Eq/Show)\n\n## Follow up\n\nOnce the two first step are completed, it's time to let the audience decide on what to tackle next. Some steps that can be seen:\n\n* How to implement a time machine?\n* How to emit the events in the first place?\n* ?\n\nTake 5 minutes in the end to gather audience feedbacks and questions.","language":"en","shareable":false,"publication_date":"2019-05-02T20:47:04+00:00","current_slug":"speaker-s-notes-discover-event-driven-programming","previous_slugs":[]},{"post_id":"b7be05c7-366a-44a0-996f-1b85fcc06e7a","version":0,"title":"Quick Recap on The Manager's Path","markdown_content":"The Manager's Path is the reference book if you want to learn about engineer management, that is anything ranging from a mentor position to being CTO. The book emphasizes on the obvious state of becoming a manager as a technical engineer: you will code less, you will have more responsibilities and your capacity to lead others will be key to your success. Here's what I learned by reading it.\n\n### Mentoring\n\nThe first step to enter in a manager's position is to mentor an intern or a junior dev entering the company. If you are assigned to the task, don't discard the importance of taking care of her. Take time and attention to:\n\n- Provide clear goals: how do you expect your mentee to perform\n- Provide guidance and reassurance: entering a new company can be disturbing and stressful. Your action can make a change\n- Assess your mentee progression with regular 1-to-1s\n\n### Why doing 1-to-1s\n\nPrecious tool to assess your mentee or your team members. It allows providing a regular feedback, to spot problems early, and to update everyone on the situation of the team in the larger context of the company. Tackle most important and difficult issue during those 1-to-1s, before these poison your team efficiency and well being.\n\n### Tech Lead\n\nA Tech Lead is the position you start managing a whole team by yourself. You provide technical guidance and help a small team achieve their goal. One big part of the job is explaining the goals set for the team and decide by which means those will be achieved.\n\n### The importance of feedback\n\nFeedback and communication is a great part of a manager's role. Other roles have tasks to achieve with the constraint they understood. If their actions or their misunderstanding hurts the company you are in the front line to tell them and solve the situation. You can issue positive or negative feedbacks but they need to be shared in different settings.\n\nWhen you are happy with the work of a collaborator or with her behavior, you can congratulate her directly in a team meeting. Positive feedbacks make the team feel better and improve their mindset.\nIn case you need to provide a negative feedback, see directly with the person. She doesn't have to be humiliated in front of everyone for something that can also be a mistake/misunderstanding.\nIn any case, don't provide shallow feedback. It has to be actionable.\n\n### Tech Manager\n\nThe tech manager guides multiple teams. He has delegated most of his past work, including developing. Her main role is to help other people grow to their full potential.\n\n### Conclusion\n\nWhat I learned by reading this book is:\n\n- The more you know your collaborator, the better (What do they aspire at?)\n- Fix problems the soonest possible\n- Tackle touchy issues instead of fleeing away\n- Listen and watch for signs of discomfort","language":"en","shareable":false,"publication_date":"2019-03-22T23:46:58+00:00","current_slug":"quick-recap-on-the-manager-s-path","previous_slugs":["reading-the-manager-s-path"]},{"post_id":"4d697e12-1f4f-41ad-b394-4b54a3328751","version":0,"title":"Luttons contre les pouvoirs réactionnaires et autoritaires","markdown_content":"Nous caricaturons nos adversaires politiques par facilité et pour éviter les ambiguïtés sur des réseaux prompts à l'interprétation facile. Pourtant connaissez-vous bien le discours et la rhétorique de vos adversaires politiques ? Quand j'ai suggéré que les propos défendus par Thomas Pierrain, aka υѕe caѕe drιven, dans son article [les dangers du politiquement correct](https://medium.com/@tpierrain/les-dangers-du-politiquement-correct-2bc438611226) étaient proches de ceux tenus par Alain Finkielkraut, il s'est insurgé. Quoi de plus naturel quand on est comparé à l'intellectuel souvent présenté comme Parangon de l'intelligentzia réactionnaire ?! L'objectif de cet article est d'étayer ma réponse pour éviter les raccourcis, malentendus et comprendre pourquoi ce rapprochement m'a semblé naturel.\n\nPour commencer, je tiens à préciser que je ne vais pas traiter de l'histoire que l'article relate. Ce qui m'intéresse c'est l'interprétation de υѕe caѕe drιven du discours qui lui a été opposé. Cette interprétation renferme une vision du monde proche des courants réactionnaires, dont Alain Finkielkraut est pour moi le théoricien le plus explicite.\n\n## La pensée d'Alain Finkielkraut\n\nL'Archipel du Goulag par Alexandre Soljenitsyne est publié en 1974 en France. Ce livre va pousser beaucoup d'intellectuels communistes, dont Alain Finkielkraut, membre actif de l'Union des jeunesses communistes marxistes-léninistes, à rejeter en bloc l'union soviétique. Ce rejet sera le fondement d'un nouveau courant français : les \"nouveaux philosophes\". Ils sont jeunes, antisoviétiques, ne refusent aucune participation aux plateaux de télé et n'hésitent pas à dénoncer la pensée de leurs aînées (Michel Foucault, Gilles Deleuze, Félix Guattari, Jacques Derrida, etc.) trop sympathiques à l'URSS à leurs yeux.\n\nC'est donc 10 plus tard qu'il écrit \"la défaite de la pensée\", un essai qui va décrire sa vision de la société. Dans celui-ci, il commence par reconnaître l'erreur de considérer l'homme hors de tout contexte social, économique et culturel. Il existe des femmes, des hommes, des riches, des pauvres, des arabes, des blancs, des noirs, etc. Le rôle des États est d'élever les individus au-delà de leur origine et de former des \"citoyens\". Cette vision, qu'il appelle la République, implique deux choses. D'une part, l'éducation doit permettre la diffusion d'une culture républicaine commune qui permet aux individus de s'élever au-delà de leurs différences. D'autre part, la place publique n'est pas le lieu de l'expression d'un culture personnelle, ce qui met en péril l'unité républicaine.\n\nCette vision de la République, il l'oppose au multiculturalisme, mal de notre société, qui promeut une société où la multitude de cultures est fièrement affichée et défendue, voire cultivée dès l'école. Ces deux visions qui se confrontent sont au cœur du discours d'Alain Finkielkraut, qu'il s'agisse d'interdire le port du voile, de la supériorité de la musique classique sur le rock ou de la culture gay dont il disait en 1996 qu'il \"faut qu'ils sachent que la discrétion est nécessaire à tout art de vivre\".\n\n## Dévoilement du réactionnaire : le politiquement correct\n\nAvec le temps, cette dénonciation du multiculturalisme glissera vers ce qu'il appelle le politiquement correct. Il en donne une [définition claire](https://www.lepoint.fr/societe/finkielkraut-la-bien-pensance-ne-resoudra-pas-les-problemes-20-09-2012-1695142_23.php) : le politiquement correct est \"tout ce qu'on n'a pas le droit de savoir\". On s'en sert pour dissimuler la réalité, pour gommer les problématiques que les bien-pensants ne veulent pas reconnaître. Une définition qui n'est pas très loin de ce que propose υѕe caѕe drιven dans son article :\n\n> Le politiquement correct nous empêche de nommer les choses sous prétexte que cela pourrait gêner ou embarrasser quelqu’un\n\nCette rhétorique a un double effet. D'abord, il discrédite les opinions de l'interlocuteur sans confronter son raisonnement : étant politiquement correct, le raisonnement est incomplet par essence. On peut alors le compléter avec nos propres interprétations et le rendre absurde. La deuxième mécanique (la préférée des réactionnaires) c'est que cela fait de l'interlocuteur le porte-parole d'une opinion majoritaire, discréditant alors ses intentions de défendre une minorité : \"Puis-ce que votre opinion est majoritaire, comment osez vous dire défendre les opprimés et les victimes ? Les vraies victimes, c'est nous !\".\n\n## Quelle République dans une société sexiste ?\n\nLe cas qui m'a fortement mis la puce à l'oreille dans l'article est l'ensemble des arguments utilisé à l'encontre des \"safe space\". La rhétorique conservatrice se déploie au point d'aller plus loin que la position d'Alain Finkielkraut. Voici ce qui en est dit dans l'article :\n\n> Vous savez, ces endroits interdits aux Hommes, aux Blancs, aux Personnes de grandes tailles (remplacez-les par « Juifs », « Noirs » ou « Arabes » et ça fait tout de suite froid dans le dos)\n\n\"Vous savez ?\" Mais savez-vous réellement ce que sont les fameux safe spaces ? [Martha P. Johnson](https://en.wikipedia.org/wiki/Marsha_P._Johnson) et Sylvia Rivera sont à l'origine de cette pratique. Après plusieurs années à la rue, obligées de se prostituer, arrêtées par la police régulièrement, elles connaissent la détresse commune aux transgenres des années 70. Elles décident alors de créer une organisation (la Street Transvestite Action Revolutionaries ou STAR) et ouvrent une \"maison\" dans le but d'accueillir les jeunes trans qui se retrouvent à la rue. Cette maison devient un symbole des luttes LGBTQ+. Elle permet à des populations victimes de violences, de se retrouver, de partager leurs expériences et de se supporter.\n\nAujourd'hui, cette pratique s'étend à d'autres usages, toujours dans l'objectif de défendre et de protéger des populations victimes d'agressions. Or il faut bien être clair : les \"safe spaces\" sont des lieux où les \"Blancs\" ou les \"Juifs\" sont accueillis. C'est même expliqué dans cette [émission](https://www.franceculture.fr/emissions/repliques/la-question-du-politiquement-correct) animé par Alain Finkielkraut ! Ce qu'il reproche à ces lieux (surtout à ceux dans les universités, lieu de l'éducation par excellence), ce n'est pas leur constitution ethnique, mais simplement que ce ne sont pas des lieux de débats et de confrontation. Ils ne correspondent pas au modèle Républicain selon lequel, tout lieu public se doit d'être le lieu d'expression de \"citoyens\" qui ont fait le deuil \"d'où ils parlent\".\n\n## Pour une empathie et un armement des opprimé-e-s\n\nPour reprendre les propos de Didier Eribon : \"toutes les luttes contre les dominations sont légitimes, vouloir les disqualifier est l'oeuvre des pouvoirs réactionnaires et autoritaires\". Je continuerai à dire que les propos soutenus dans cet article sont réactionnaires et proches d'Alain Finkielkraut, car il suffit d'écouter l'avis de ce dernier sur les sujets évoqués (racisme, féminisme, etc.) pour y entendre la même rhétorique à l'œuvre.\n\nJ'ai souvent été fasciné par les discours de l’extrême droite, leur apparente cohérence nous renvoie vers les défauts et les limites de nos propres discours. Pourtant le cas d'Alain Finkielkraut est bien plus ambigu. Il s'est toujours désolidarisé des discours haineux de l'extrême droite (il s'oppose toujours fortement au front national) tout en garantissant une place pour sa rhétorique réactionnaire sur la scène médiatique (il n'hésite pas à inviter Éric Zemmour quand l'actualité lui en donne l'occasion).\n\nCette infiltration des discours réactionnaires dans le débat public est une catastrophe pour la vitalité de notre société. C'est un danger qui nourrit les peurs, les violences, la haine et le rejet. Pour soutenir une société en paix, il faut travailler avec les opprimé-e-s des différents systèmes d'exclusions sur des mots qui permettent de parler de leur réalité. Pourquoi parler de \"migrants\", alors qu'ils vivent une réalité de réfugiés ? Pourquoi des \"travailleurs illégaux\", quand ils sont sans papiers ?\n\nUtiliser les bons mots, la bonne rhétorique n'est pas une question de morale, c'est un outil d'accompagnement des luttes et de défense des faibles. J'ai la chance d'être né sous une bonne étoile, je ne céderai pas à la facilité d'un discours qui reproduit les violences et les inégalités de notre société.\n\nSources :\n\n- [L'article à l'origine de cette réponse](https://medium.com/@tpierrain/les-dangers-du-politiquement-correct-2bc438611226)\n- [Sur la nouvelle philosophie](https://www.youtube.com/watch?v=-pGTU-t_Duw)\n- [Didier Eribon contre le discours homophobe d'Alain Finkielkraut](https://www.ina.fr/video/I12243837/didier-eribon-a-propos-de-la-communaute-gay-et-du-livre-de-frederic-martel-le-rose-et-le-noir-video.html)\n- [Construction de la blanchité](https://www.franceculture.fr/emissions/les-nouvelles-vagues/le-blanc-25-le-concept-de-blanchite)\n- [Avis d'Alain Finkielkraut sur la bien pensance](https://www.lepoint.fr/societe/finkielkraut-la-bien-pensance-ne-resoudra-pas-les-problemes-20-09-2012-1695142_23.php)\n- [L'émission \"répliques\" sur le politiquement correct venu des États-Unis](https://www.franceculture.fr/emissions/repliques/la-question-du-politiquement-correct)\n- [Le racisme selon Colette Guillaumin](https://blogs.mediapart.fr/eric-soriano/blog/210111/le-racisme-selon-guillaumin)\n- [Une critique sur la rhétorique de l'anti-politiquement correct](http://lmsi.net/Critique-de-l-anti-politiquement)\n- [Blog de Didier Eribon](http://didiereribon.blogspot.com/)\n- [Jonathan McIntosh démontant les représentations de la masculinité dans les médias](https://www.youtube.com/watch?v=mOV7_U3bBVw)\n- [Qu'est-ce qu'un migrant ?](https://www.amnesty.fr/focus/migrant)\n\n---\n\nps: je me permets une seule attaque en dessous de la ceinture, mais qui m'a titillé pendant la lecture de l'article. Le terme \"racisé\" est moqué pour être le \"néologisme favori\" de l'auteur. Mais sait-il d'où il vient ? Des travaux de Colette Guillaumin sur les discours essentialistes qui légitiment les discriminations. Elle note que certains individus sont systématiquement renvoyés à leur appartenance à une communauté : ils sont donc racisés, comme triés par leur race. Pourquoi je fais remarquer cela ? L'auteur utilise dans son article l'expression \"les causes racines\", qui n'est rien d'autre qu'une traduction faite avec le cul de l'anglais \"root cause\". Faut croire que l'on utilise les néologismes que l'on mérite...","language":"en","shareable":false,"publication_date":"2019-01-24T13:35:42+00:00","current_slug":"luttons-contre-les-pouvoirs-reactionnaires-et-autoritaires","previous_slugs":["4d697e12-1f4f-41ad-b394-4b54a3328751"]},{"post_id":"04cf5b2f-362e-4a9e-9cea-d5ee6ea95a2a","version":0,"title":"Hors sujet : impératif catégorique de Kant et masculinité toxique","markdown_content":"Je regarde de temps en temps des vidéos essais sur youtube mais rarement celle-ci provoque en moi l'effet que ces deux vidéos que je vous présente. La première m'a fait réaliser que l'impératif catégorique de Kant n'est pas l'idiotie que l'on m'a toujours été expliqué. La seconde est une chaîne dédiée aux représentations de la masculinité toxique dans la culture populaire.\n\n## De l'impératif catégorique\n\n> Agis seulement d'après la maxime grâce à laquelle tu peux vouloir en même temps qu'elle devienne une loi universelle\n\nCette phrase, ainsi que d'[autres](https://fr.wikipedia.org/wiki/Imp%C3%A9ratif_cat%C3%A9gorique), sont les termes utilisés pour décrire formellement l'impératif catégorique. Pour vulgariser ce concept, on préfère les exemples simplistes du style :\n\n> Il ne faut pas voler (*la maxime*) car si tout le monde volait (*une loi universelle*) plus personne n'aurait de propriété. (*paradoxe*)\n\nKant serait donc, disent ces philosophes de basse facture, un moraliste qui demande de suivre que les maximes qui seraient universelles. Or cette présentation est quelque peu caricaturale. En effet, il est facile d'imaginer des situations où cette position serait indéfendable. Que ce passerait-il si vous étiez sur le point de mourir de soif et que le seul puits accessible est détenu par un propriétaire qui vous en refuse l'accès. En respectant cet impératif vous n'auriez pas le choix de vous laisser mourir.\n\nPendant longtemps, je trouvais peu d'intérêt à la philosophie de Kant du fait de cette piètre explication. C'est alors que j'ai rencontré le chemin de la vidéo qui explique la [thèse de Dana Dragunoiu](https://www.jstor.org/stable/44030393?read-now=1&loggedin=true&seq=1#page_scan_tab_contents) selon laquelle le héros de la trilogie de The Matrix respecte scrupuleusement l'impératif catégorique d'une morale qu'il veut universelle.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/ZvyCyyFRpfE?rel=0\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>\n\nPour résumer, Neo décide systématiquement de suivre le devoir moral qu'il a choisi, et de se sacrifier pour la cause de la résistance (même si cela met en péril son amour pour Trinity).\n\nAinsi la morale qu'il a choisi n'est pas celle de l'amour, mais de la défense inconditionnelle de la liberté des individus contre tous les systèmes d'oppression et le pouvoir détenu par les robots. Cette thèse est d'autant plus intéressante qu'elle permet de comprendre les prises de position en faveur de la défense des minorités et des dominés par les Wachowskis à plusieurs [occasions](https://www.hollywoodreporter.com/news/lana-wachowski-reveals-suicide-plan-382169).\n\nPour reprendre l'exemple du début, ce n'est pas le vol qu'il faut considérer comme un impératif catégorique. C'est l'idéal que l'on défend. Le problème n'est pas de voler dans l'absolu, c'est de voler lorsque l'on en a pas besoin de le faire ou dans des conditions qui nous semblent incompatibles avec les conditions d'exercice du droit à la propriété (dans un acte de désobéissance civique par exemple).\n\nL'impératif catégorique se révèle donc un outil politique puissant. Kant demande de nous questionner sur notre morale et nos choix, puis de les défendre dans chacune de nos actions tout en les exigeant d'autrui.\n\n## La masculinité toxique\n\nLa seconde vidéo est issue de la chaîne \"Pop Culture Detective\", qui réalise une série d'essais analysant les tropes et archétypes de masculinité dans les films et les séries. Le constat est assez sombre : la majorité des films utilisent des héros masculins qui [traquent](https://www.youtube.com/watch?v=wWoP8VpbpYI) et [capturent](https://www.youtube.com/watch?v=t8xL7w1POZ0) des femmes qui sont réduites au rôle d'objectif romantique. Ces hommes sont récompensés par les scénarios pour de tels actes alors qu'ils sont explicitement présentés comme immorale lorsque perpétrés par des méchants. Son exemple le plus frappant est son essai sur la misogynie constante de la sitcom [The Big Bang Theory](https://www.youtube.com/watch?v=X3-hOigoxHs).\n\nPourtant, l'espoir n'est pas perdu et la chaîne présente également de multiple exemples de films qui font la part belle à des sentiments peu représentés chez les héros masculins. Son hommage aux \"Animaux Fantastiques\" d'après l'univers de J.R. Rowling est le plus touchant. Comme beaucoup j'ai évité ce film suites aux critiques mitigés. Une partie des reproches ont été à l'intention du personnage principal, interprété par Eddie Redmayne, il aurait été pas assez charismatique. C'est comme si on ne pouvait avoir de héros humble :\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/C4kuR1gyOeQ?rel=0\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>\n\nLa morale de ces essais est extrêmement juste. Elle enjoint les hommes à ne pas s'ingérer dans le combat féministe, mais de participer à l'égalité des sexes en mettant en question nos valeurs et celles que l'on attent de notre culture. Voulons-nous faire l'apologie de valeurs portées par la lie de l'[humanité](https://www.youtube.com/watch?v=1r3FkR5rziY) ? Ou accepter de défendre une masculinité fragile, humble et empathique ? Pour paraphraser la philosophe [Chantal Jaquet](https://twitter.com/franceculture/status/1046979974287302656) :\n\n> L'homme héroïque est sans honte ni orgueil\n\nIl n'y a pas de honte à être fragile et pas d'orgueil à être un homme simple.","language":"fr","shareable":false,"publication_date":"2018-10-17T21:18:23.678361+00:00","current_slug":"hors-sujet-imperatif-categorique-de-kant-et-masculinite-toxique","previous_slugs":[]},{"post_id":"c66193a1-954e-4f0c-8a4f-46229068172a","version":0,"title":"Moving the blog to Purerl, the journey into type safety land","markdown_content":"I started implementing my own blog more than a year and a half ago. Since I was working with Ruby on Rails at the time, I wanted to experiment [Phoenix](https://phoenixframework.org/). It was an introduction to functional programming and I really enjoyed it. I wrote a [small guide for beginners](https://sadraskol.com/posts/the-survival-kit-for-functional-language-beginner) and later learned [Purescript](http://www.purescript.org/). I consider myself as an intermediate haskeller (my understanding goes as far as `ReaderT`). I used to enjoy dynamically typed languages, but my experience with [sum types](https://sadraskol.com/posts/les-types-algbriques-pour-les-langages-orients-objet) really changed my perspective. I cheer on the static side now!\n\nI implemented my blog with a full event driven approach. It allowed me to fix issues more safely than ever. At least that was what I thought. A year after the first lines, it had become very difficult to fix bugs. The problem is really about refactoring the code. Not declaring types had become a pain. In the following code, focus on the `publication.publication_date` variable:\n\n``` elixir\ndef execute({state, new_events}, %PublishDraft{} = publication) do\n  cond do\n    state == nil ->\t{state, {:error, \"Does not exist yet\"}}\n    draft_should_not_be_published?(state) -> {state, {:error, \"Draft non conform to publication\"}}\n    true ->\n      {state, new_events}\n      |> apply_event(%PostPublished{\n        aggregate_id: publication.aggregate_id,\n        publication_date: publication.publication_date,\n        slug: slugify(state.title)\n      })\n  end\nend\n```\n\nWhat is its type? Is it type that my database driver expects, `NaiveDateTime`? Or is it a string that I need to format? What does the `apply_event` function expect as an argument, a string or a `NaiveDateTime`? If I want to answer those questions, I need to dig in two directions in my code and I might not even find a satisfying answer, since some library might hide the details of implementation. I really enjoy Elixir as a language, but refactoring can be really problematic, especially when you don't actively maintain the code base.\n\n## Purerl: the miracle solution\n\n[Purerl](https://github.com/purerl) is a fork of Purescript. The core language is the same, but it compiles to Erlang instead of Javascript. Do you see it coming? Yes, the blog still runs with Elixir, but it also uses Purerl to compile to Erlang and run alongside with the Elixir components. How did I do it? First, a Makefile that fetches Purerl dependencies, and compile the sources to Erlang.\n\n```\nall:\n\tpsc-package install\n\tpsc-package sources | xargs purerl compile 'purerl/**/*.purs'\n```\n\nThen in my `mix.exs` configuration for Elixir, I specify the path where my Erlang sources are:\n\n``` elixir\ndef project do\n  [app: :sadraskol,\n  # ... other confs\n  erlc_paths: [\"output\"], # Path where purerl will generate the erlang\n  # rest as usual\n  ]\nend\n```\n\nAnd *voilà*! The code is ready to use the Purerl within Elixir.\n\n## Switching to a statically typed language\n\nThe first major difference from Elixir, was that I was able to define types much more expressively and to gather them together. For instance, every domain event had a file for itself, with only the keys defined:\n\n``` elixir\ndefmodule Sadraskol.Blog.Events.LegacyPostImported do\n  defstruct [:title, :pub_date, :html_content, :slug, :status, :description, :language]\nend\n```\n\nThe equivalent in Purerl was much easier to read, see for yourself:\n\n``` haskell\ntype Title = String\ndata Status = Published | Draft\ndata PostEvent\n  = DraftEdited Title HtmlContent Language Description (Maybe MarkdownContent)\n  | PostPublished PublicationDate\n  | LegacyPostImported Title HtmlContent Status Description Language Slug PublicationDate\n  | DraftDeleted\n  | PostEdited EditDate HtmlContent Language Description (Maybe MarkdownContent)\n  | PostTitleChanged Title\n```\n\nHere every value is either a type synonym or has its proper data type. It gives me a lot of flexibility when it comes to replacing changing them with more complex logic. My decision aggregate is also much more specific:\n\n``` haskell\ndata BlogPost\n  = Draft Title HtmlContent Language Description (Maybe MarkdownContent)\n  | Published Title HtmlContent Language Description (Maybe MarkdownContent)\n  | Deleted\n  | NoPost\n```\n\nWhen implementing a method, the compiler will complain if a case was not taken into account. It makes my refactoring much easier and painless.\n\n## Cheating for foreign communication\n\nPurerl does not provide the [purescript-foreign](https://github.com/purescript/purescript-foreign) library which allow to safely use foreign bindings. Most bugs I ran into during the implementation were caused by using badly the Erlang data in the Purerl code. So such a library would have been of a wonderful help.\n\nThe real problem is passing data back to Elixir code: since there's no real easy way of asserting the data representation, I limited myself to using very simple data structure, mostly maps with `Atoms` as keys.\n\nTalking of `Atoms`, They were in the heart of the reason I couldn't unit test my code (I tired of fighting against myself and libraries). I'm using [Ecto](https://github.com/elixir-ecto/ecto) to save the events. It takes maps with strings as keys, but returns structured maps with atoms. The way I binded the Purerl and Ecto was a complete failure in that regard, and I already regret it.\n\n## Introducing a new aggregate\n\nFor a long time I didn't let myself change titles on my blog, The code just didn't implement the logic behind it. You would think changing a blog post title is a benign operation, but it's not. One thing that needs to be kept is the slug of the post. The [slug](https://en.wikipedia.org/wiki/Clean_URL#Slug) is the human readable section of an url. When I publish an article, a slug is automatically generated from the title of the article. But since my article can be referenced from Twitter or other media, the old slugs should redirect to the updated slug.\n\nThis refactoring with a type safe language allowed me to implement this feature without the fear of breaking anything. I admit I also felt the pleasure of doing something that would not be allowed in an industrial environment! Using less maintained languages are a real pleasure! And pain! But just as Marcel Proust would say:\n\n> *J’en conclus plus tard qu’il y a une chose aussi bruyante que la souffrance, c’est le plaisir.*\n>\n> I concluded later that there is something as noisy as suffering, it is pleasure.\n>\n> *Marcel Proust, [Sodome et Gomorrhe](https://marcelproustrecherche.wordpress.com/2015/05/04/chez-proust-il-ny-a-pas-de-bien-sans-que-lon-sente-le-souffle-du-mal/)*\n\n## You should introduce Purerl in your Erlang code?\n\nOnly if you don't fear diving deep into weird problems, having to support basing utilities for yourself, building your own `package-set.json` file, and have fun! I guess Javaist can use [eta](https://eta-lang.org/), javascripters Purescript and Csharper [F#](https://fsharp.org/). Since most of those languages have tricks to be easily integrated, test them for simple modules, so you can easily come back from them.\n\n\n*A special thanks to [Nicolas Wolverson](https://twitter.com/nwolverson) who did an awesome job at implementing Purerl!*","language":"en","shareable":false,"publication_date":"2018-07-27T00:05:02.379743+00:00","current_slug":"moving-the-blog-to-purerl-the-journey-into-type-safety-land","previous_slugs":[]},{"post_id":"5e5c0234-2229-4433-a311-aa778ee310c8","version":3,"title":"Unexpected values in Java","markdown_content":"You read the documentation of Java and you find the method you were looking for. What are the possible scenarios when running this method?\r\n\r\n``` java\r\npublic static LocalDate parse(CharSequence text);\r\n```\r\n\r\n## Documented execution results\r\n\r\nThe [documentation](https://docs.oracle.com/javase/8/docs/api/java/time/LocalDate.html#parse-java.lang.CharSequence-) gives 2 explicit answers and an implicit one :\r\n\r\n* The `CharSequence` represent an actual date, and it returns a non null `LocalDate`.\r\n* The `CharSequence` do not represent a date, the method throws a `DateTimeParseException`\r\n* The `CharSequence` is null. The documentation implicitly says that it would throw a `NullPointerException`\r\n\r\nTo be sure to workout all those case, you would have to write something like this:\r\n\r\n``` java\r\npublic void hell(CharSequence str) {\r\n  if (str != null) {\r\n    try {\r\n      LocalDate result = parse(str);\r\n    } catch (DateTimeParseException e) {\r\n      // Exception management\r\n    }\r\n  } else {\r\n    LocalDate result = // ..?\r\n  }\r\n}\r\n```\r\n\r\nDid you find them all ? If not, it's probably that you don't know Java as much as you think. We provided yet the answer if the documentation was trustworthy. But we all know that documentation can be wrong ! What else could the method do ?\r\n\r\nIt could throw a runtime exception that is not documented. This case is not that problematic, because this unexpected behavior would stop your thread execution. Hopefully you already implement a mecanism to cope with runtime exception in your program.\r\n\r\nThe documentation says that the method would *never* return a `null`. But who believes in documentation. You could very well have to deal with a `NullPointerException`:\r\n\r\n``` java\r\nLocalDate date = parse(\"String That Is Parsed As null\");\r\n// some other code\r\ndate.isBefore(otherDate.plusDays(3)); // throws a Null Pointer Exception\r\n```\r\n\r\nThe issue is double here. Firstly, the stack trace will indicate the line of the `NullPointerException` but not the expression it evaluated. You cannot determine if `date` or `otherDate` is the cause of the exception without debugging. The other issue is that the date can be propagated to other methods and create a time bomb in your code. The further the value is propagated the more difficult the root cause analysis.\r\n\r\nMitigating code would be something like:\r\n\r\n``` java\r\npublic void hell(CharSequence str) {\r\n  if (str != null) {\r\n    try {\r\n      LocalDate result = parse(str);\r\n      if (result == null) {\r\n        result = // ..?\r\n      }\r\n    } catch (DateTimeParseException e) {\r\n      // Exception management\r\n    }\r\n  } else {\r\n    LocalDate result = // ..?\r\n  }\r\n}\r\n```\r\n\r\nThere are no real long term solution to this. When developing in Java, any expression can be null. You can use tools to analyze your code, but if your program depends on reflection, you will never be sure. You need to accept this, and prepare for long and difficult analysis.\r\n\r\nThe last unexpected value is not a value: what if the method does never return? This case doesn't have a name in Java, so I'll use the Haskell vocabulary: the Bottom or *_|_*. What can we do against that? Nothing, definitely nothing. You would usually mitigate such problems by limiting the time tasks can take in your program.\r\n\r\nThere's no escape for software hell. Other more strict languages might help you by getting rid of worst cases, but in the end, only one thing count: how clearly you've expressed your needs through the code.","language":"en","shareable":false,"publication_date":"2018-06-21T15:55:53.831251+00:00","current_slug":"unexpected-values-in-java","previous_slugs":[]},{"post_id":"a9953492-1eb4-45fe-842c-79a924aba945","version":0,"title":"Revue de presse : spécial parcoursup","markdown_content":"Les motivations pour changer de système de sélection sont diverse. L'ancien système APB, pour admission post bac, n'était pas sans reproche mais avait derrière lui la solidité reconnue de l'algorithme qu'il utilisait : le fameux Gale-Shapley. La solidité n'était pas seulement liée à ses propriétés mathématiques, il a été utilisé dans l'attribution des élèves à la sortie des classes préparatoires aux grandes écoles (CPGE).\n\nPlus d'information sur le fonctionnement de l'algorithme ici : [https://www.youtube.com/watch?v=oHYcOXi06uY](https://www.youtube.com/watch?v=oHYcOXi06uY)\n\nEn septembre 2017, la CNIL émet une [mise en demeure](https://www.cnil.fr/fr/admission-post-bac-apb-cloture-de-la-mise-en-demeure) à l'encontre du ministère de l'éducation nationale pour manquement à la loi Informatique et Libertés pour l'APB. En cause : différents manquements à la loi concernant l'information des étudiants sur les finalités de traitement de leur données. L'algorithme utilisé est lui aussi remis en cause. L'utilisation de l'aléatoire lorsque candidats et candidates ne peuvent être descriminés par ailleurs.\n\nDeux mathématiciens sont alors diligentés pour trouver un algorithme qui puisse convenir aux requètes de la CNIL, tout en ayant les mêmes performances que l'APB. Ils ont expliqué leur travail dans cet [article](https://www.sciencesetavenir.fr/high-tech/informatique/bac-2018-l-algorithme-de-parcoursup-explique-par-les-deux-chercheurs-qui-l-ont-concu_124407). Pourtant ce ne sont souvent pas les algorithmes qui sont problématiques, comme le faisait remarquer Hubert Guillaud sur twitter :\n\n<blockquote>\n  <p dir=\"ltr\">A sa leçon inaugurale au Collège de France, Claire Mathieu concluait : &quot;Les algorithmes ne sont pas responsables des dysfonctionnements&quot; :(  <a href=\"https://t.co/2VDXBrRxZA\">https://t.co/2VDXBrRxZA</a> - Elle est l&#39;une des conceptrice de <a href=\"https://twitter.com/hashtag/parcoursup?src=hash&amp;ref_src=twsrc%5Etfw\">#parcoursup</a> : <a href=\"https://t.co/K4ljrKh7km\">https://t.co/K4ljrKh7km</a>\n  </p>\n  &mdash; hubert guillaud (@hubertguillaud) <a href=\"https://twitter.com/hubertguillaud/status/1002581707474788352?ref_src=twsrc%5Etfw\">1 juin 2018</a>\n</blockquote>\n\nPour le coup, Parcousup est loin d'être parfait. Au coeur des critiques, la reproduction sociale serait largement favorisée par la sélection des candidats décidée par les institutions formatrices. Comme le raconte [Le Monde](https://www.lemonde.fr/societe/article/2018/06/02/les-lyceens-de-banlieue-et-les-embuches-de-parcoursup_5308639_3224.html) ou comme le montre cette [carte](https://swaggcocos.wordpress.com/2018/05/27/cartographie-lexclusion-avec-parcoursup/), les étudiants peuvent payer cher leur implentation territoriale ou leur choix de filiaire.\n\nLa critique la plus documentée vient du magazine du Collège de France : [Le Parcoursup des filles](http://www.laviedesidees.fr/Le-Parcoursup-des-filles.html). Les deux sociologues montrent comment le dispositif va exclure encore plus les filles des milieux populaires particulièrement. L'algorithme de sélection n'est pas le seul en cause, l'[amendement du sénateur Jacques Grosperrin](http://www.senat.fr/amendements/commissions/2017-2018/193/Amdt_COM-37.html) aura un effet pervers. Il poussera les filles à ne pas poursuivre dans l'enseignement supérieur.\n\n## Synthèse\n\nComme on l'a vu, l'algorithme de sélection n'était pas facile à mettre en place, surtout dans des délais aussi cours. Le résultat n'est pas une catastrophe par rapport à APB. Pourtant les majeures différences et les directions choisies par les législateurs sont à l'origine des frustrations et des problèmes que nous avons évoqués. On peut alors se demander ce qu'entend Jean-Michel Blanquer lorsqu'il affirme à l'[Ouest France](https://www.ouest-france.fr/education/entretien-blanquer-parcoursup-c-est-une-amelioration-5792452) que le système est \"plus rationnel\". S'il parle du rationnel, il semble que c'est la raison au profit du plus fort.","language":"fr","shareable":false,"publication_date":"2018-06-03T00:55:35.051918+00:00","current_slug":"revue-de-presse-spcial-parcoursup","previous_slugs":["revue-de-presse-spcial-parcousup"]},{"post_id":"df1ad54e-7528-4d79-a4f0-fcd23fb17244","version":0,"title":"Simple take on monadic types : the List","markdown_content":"Monads are often introduced as an abstract mathematical concept or as an abstract design pattern. In this series, humbly called \"Simple take on monadic types\", we're going to manipulate the objects which have monadic instances. We'll extrapolate their properties and gradually discover their power. If the concept of monads is not familiar to you, you only need some knowledge of Java or Javascript and some attention. For the first article of the series, let's play with the type `List<T>` or `List a`.\n\nThe goal of our program is to harvest trees (🌳) to get apples (🍎) and bake them into pies (🥧)! In order to store them, we'll use the abstract (but familiar) concept of `List`, everything is much easier when stored in a list.\n\n## Bake the piece of pie\n\nLet's consider this function:\n\n``` haskell\nbake :: 🍎 -> 🥧\nbake apple = -- details the recipe\n```\n\nIt takes an apple, a value of type 🍎, and returns a piece of pie, a value of type 🥧. Emojis represent types, which are a set of value. All the apples, that my computer can deal with, are values of type 🍎. The function signature reads as simply as : I take one apple and I give one piece of pie.\n\nAn apple tree does not grow an apple at a time. It provides you with a large quantity of apples, you can organize them in a list, a `List 🍎`. If the tree does not give any apple, then it's an empty list, so you're all covered. An efficient way of providing pies to your customers would be to deliver a bunch of pies at the same time. You would provide a `List 🥧`. Snap! You only have a `bake` routine which does not deal with `List`. With Java, you would normally mitigate this by implementing `bakeAll`:\n\n``` java\nList<🥧> bakeAll(List<🍎> apples) {\n  List<🥧> result = new ArrayList<>();\n  while (iterator.hasNext()) {\n    result.add(cook(iterator.get()));\n  }\n  return result;\n}\n```\n\nThat's cool but wouldn't there be a more comfortable way of writing this? After all, it's all boiler plate to extend the capability of `bake` from the signature `🍎 -> 🥧` to the list equivalent `bakeAll` of signature `List 🍎 -> List 🥧`. There could be a boilerplate-free method of signature `(🍎 -> 🥧) -> (List 🍎 -> List 🥧)`, that would take `bake` function and return the `bakeAll` equivalent. Could you write it in your language of preference? You may have already used it, it's the `map` method. It is implemented in [most languages](https://en.wikipedia.org/wiki/Map_(higher-order_function)) for lists or arrays. In Haskell, you would write it as follows:\n\n``` haskell\nbakeAll :: List 🍎 -> List 🥧\nbakeAll apples = map bake apples\n```\n\nIt's not idiomatic Haskell yet (more to come later), but it reads nicely:\n\n> _To_ Bake all apples, _apply_ bake _to every_ apple.\n\nNow that, we baked all apples, we need to deal with the upstream providing apples. In other words, let's harvest apple trees!\n\n## Harvesting a tree\n\nLet's consider the following function:\n\n``` haskell\nharvest :: 🌳 -> List 🍎\nharvest tree = -- details the harvesting\n```\n\nHarvesting takes a single tree (🌳) and returns a lot of apples (🍎). One tree can produce up to 1000 apples, which can be baked into a 1000s of pies. We can directly have the list of pies as a result, some signature that resemble `🌳 -> List 🥧`. We have both functions `harvest :: 🌳 -> List 🍎` and `bakeAll :: List 🍎 -> List 🥧`, how hard could it be to compose them?! The output of `harvest` can be the input of `bakeAll`. We can \"plug\" them to create the equivalent: `harvestAndBake :: 🌳 -> List 🥧`. Let's use Haskell again:\n\n``` haskell\nharvestAndBake :: 🌳 -> List 🥧\nharvestAndBake tree = bakeAll (harvest tree)\n```\n\nSubstituting `bakeAll` by its implementation, we can get rid of the `bakeAll` intermediary step:\n\n``` haskell\nharvestAndBake :: 🌳 -> List 🥧\nharvestAndBake tree = map bake (harvest tree)\n```\n\n## Harvesting a field of trees\n\nWe do not own just a single tree, but hundreds of apple trees blooming happily in our field. Let's call that a `List 🌳`. Since we already know of the `map`, we could use it to compose a `harvestAndBakeAll` for our field:\n\n``` haskell\nharvestAndBakeAll :: List 🌳 -> List (List 🥧)\nharvestAndBakeAll trees = map harvestAndBake trees\n```\n\nThe problem comes with the type `List (List 🥧)`. It's not a convenient type to deal with for our consumers. It's like nested packages, a wasteful way of wrapping goods. Fortunately, there's an easy way of unwrapping `List (List 🥧)` into `List 🥧`: `join`. Let's look at its signature: `join :: List (List 🥧) -> List 🥧`. It removes a layer of `List`, returning a less intricate  Can you implement this method in your favorite language? Let's use it to simplify `harvestAndBakeAll`:\n\n``` haskell\nharvestAndBakeAll :: List 🌳 -> List 🥧\nharvestAndBakeAll trees = join (map harvestAndBake trees)\n```\n\n## Assembling into simple bricks\n\nLet's assemble every small pieces we've covered until now:\n\n``` haskell\n-- given\nharvest :: 🌳 -> List 🍎\nbake    :: 🍎 -> 🥧\n\n-- we compose\nharvestAndBakeAll :: List 🌳 -> List 🥧\nharvestAndBakeAll trees = join (map (\\tree -> map bake (harvest tree)) trees)\n```\n\nWe are here inlining the previous `harvestAndBake` function into the `\\tree -> map bake (harvest tree)` anonymous function, or lambda. This is the way of writing anonymous functions in Haskell. The two expression are equivalent.\n\nThere's a problem of readability with this one liner `harvestAndBakeAll` function, right? We are using composition glue functions, like `join`, `map` and the lambda. It would be elegant to make the expression less noisy, since the core functions are `harvest` and `bake`, our domain functions.\n\n## Reduce the noise of composition\n\nIn order to reduce noisy functions, we will use the union of `map` and `join`: `bind`, sometimes called `flatMap`. Let's first look at the signature of it: `bind :: List 🌳 -> (🌳 -> List 🍎) -> List 🍎`. Read the signature out loud to help yourself understand it: it takes a list of trees, takes a function which can harvest a tree into a list of apples and returns a list of apples. Could you implement this method using `map` and `join`? Signatures are helping a lot to answer this problem.\n\nNow that we have the `bind`, we can reduce the `harvestAndBakeAll` method a little:\n\n``` haskell\nharvestAndBakeAll :: List 🌳 -> List 🥧\nharvestAndBakeAll trees = bind trees (\\tree -> map bake (harvest tree))\n```\n\nWe didn't do anything fancy here, but notice that we didn't use the `bind` with the same signature and it works the same. Can you spot the difference from what we saw before and explain how we didn't change the behavior of `bind`?\n\n## Introducing Haskell operators\n\nThose operations (`bind`, `map`) are so common in Haskell that they have dedicated operators which reduce the amount of noise. First there is the map operator: `<$>`. Then there is the bind operator: `>>=`. They are written with arguments the same way the `+` applies to numbers in place of the `add` function:\n\n``` haskell\n           add 1 2 == 1 + 2\n   map bake apples == bake <$> apples\nbind trees harvest == trees >>= harvest\n```\n\nSome might say that it makes the code less readable with obscure symbols, but haskellers would tell you that it's only a glue operation, it does not carry any meaningful value. If we were to write `harvestAndBakeAll` again, it would become:\n\n``` haskell\nharvestAndBakeAll :: List 🌳 -> List 🥧\nharvestAndBakeAll trees = trees >>= (\\tree -> bake <$> (harvest tree))\n```\n\nTry to focus on the above expression and try to understand how each symbol works. A haskeller would not find this the best writing. arguably, the optimal way of writing it would be something like `harvestAndBakeAll trees = bake <$> harvest <.> trees`, but we'll cover this is later articles. \n\n## Monadic operations\n\nLet's recap the three monadic operations we've seen so far:\n\n* `map :: (🍎 -> 🥧) -> (List 🍎 -> List 🥧)` or `<$>`: it takes a function of simple types and returns a function of list of types\n* `join :: List (List 🥧) -> List 🥧`: it takes a nested list and returns a flat list\n* `bind :: List 🌳 -> (🌳 -> List 🍎) -> List 🍎`: it takes a list of stuff, a function of a single element returning a list and returns a flat list. It's the composition of the two last functions\n\nThere's two important things to note: monadic functions always return a monad, here `List a`. Once you are dealing with a list, monadic function won't allow you to get an element of the list. You could have an element of a list with a function like `get`, or `pop`, or something else, but those are not monadic anymore.\n\nThe second thing to note is that monadic functions compose well because they keep the integrity of the data and functions they apply on. The `map` is only a nice commodity to avoid boilerplate code. To be so, map keeps all the properties of the function `(🍎 -> 🥧)` in the \"realm\" of lists. You can easily check that by replacing emojis by any other type you want to work with: `String`, `Date`, `Int`, etc. `map` and `bind` only translate functions to be used with a type `List`.\n\nThat's all for `List` and `Monad` for now. There are many more properties that we haven't covered here. In my next article, I'll use the `Maybe` monad, and we'll verify the laws a monad abide to.","language":"en","shareable":false,"publication_date":"2018-04-03T22:59:58.572690+00:00","current_slug":"simple-take-on-monadic-types-the-list","previous_slugs":[]},{"post_id":"f92a4586-c9b1-413c-8f06-54dd8ab6ed35","version":0,"title":"Les types algébriques pour les langages orientés objet","markdown_content":"On pourrait renommer les languages fonctionnels (à l'exception d'Erlang, mais c'est une autre histoire) des languages algébriques à tel point que les structures algébriques sont leur outil de base. Nous allons essayer de montrer les analogies que ces structures ont avec les outils qui nous sont offerts dans les languages orientés objets et comment la réflexion en types algébriques permet de simplifier la modélisation de nos problèmes.\n\n## Les types sommes\n\nVous connaissez certainement déjà les types sommes : c'est le nom savant des énumerations. Vous savez ce qu'on utilise en Java pour désigner les méthodes Http ?\n\n``` java\npublic enum HttpMethod {\n\tDELETE, GET, HEAD, OPTIONS, PATCH, POST, PUT, TRACE\n}\n```\n\nCette structure est assez simple, alors pourquoi la nommer avec une opération algébrique comme la somme ? Qu'est-ce qu'on somme ici ? On parle de somme car on ajoute les possibilités. Ici le type `HttpMethod` est la somme de ses valeurs possibles (`DELETE`, `HEAD`, etc.) : 8. On parle de Cardinalité pour exprimer ce nombre. On dit que le Cardinal de l'ensemble `HttpMethod` est 8. On reviendra sur ce concept plus tard.\n\nLes énumérations ne sont pourtant pas beaucoup utilisées en Java et malgré leurs propriétés intéressantes (pas de garbage collection, pas de problème d'instantiation ou utilisation dans les switch, etc.) elles ne sont pas importantes dans les patrons de conceptions. Alors comment ce type pourrait-il être central dans un autre language ? Voyons ce qu'est un type produit avant de répondre à cette question.\n\n## Les types produits\n\nUn type produit est aussi très familier. Il correspond à la réunion de deux types. Si une personne est défini par son nom et son âge, on dira qu'il est le produit de ces deux types :\n\n``` java\npublic class Person {\n  private final String name;\n  private final int age;\n}\n```\n\nOn parle de produit dans ce cas, car on peut avoir autant d'instance de `Person` qu'il y a de noms multiplié par le nombre d'ages possibles. Dans ce cas, il s'agit d'une multiplication d'infini. Vu ce cardinal, il est impossible de prévoir tous les cas. C'est pourtant le type que le language nous engage le plus à utiliser. C'est que ce type permet d'englober toutes les possibilités dans une seule structure.\n\nEst-il possible de restreindre le nombre de valeurs possibles tout en profitant de la modélisation de domaine complexe que permet les types produits ?\n\n## Les types algébriques\n\nLes beaucoup de [languages](https://en.wikipedia.org/wiki/Algebraic_data_type#Programming_languages_with_algebraic_data_types) permettent d'utiliser une composition des types sommes et produits pour combiner les avantages des deux. Construisons un type qui modélise un cas concret, \n\n``` haskell\ndata Maybe a = Nothing | Just a\n\ngetHttpHeader = Just Get -- Maybe HttpMethod\nnoHttpHeader = Nothing -- Not available\n```\n\nSi l'on tente de calculer le cardinal de ce type algébrique, on voit que les valeurs possibles pour ce type sont : `1 + 1 * C(a)`, `C(a)` étant le cardinal du type `a`. La notion de somme et de produit transparait directement dans le calcul du cardinal. Dans le cas où `a` est un `HttpMethod`, `C(Maybe HttpMethod) == 8`. Ce qui est intéressant dans cette approche, c'est l'exhaustivité des types représentés. Par exemple, il est possible de représenter le score d'un point au tennis avec le type suivant :\n\n``` haskell\ndata Point = Zero | Fifteen | Thirty\n\ndata Player = Player1 | Player2\n\ndata GameScore\n  = Score Point Point\n  | GamePoint Player Point\n  | Deuce\n  | Advantage Player\n  | Game Player\n```\n\nOn pourrai montrer que le type `GameScore` implémente l'ensemble des scores possible pour un point de tennis. On peut même trivialement calculer l'ensemble des valeurs possibles :\n\n```\nC(GameScore) == C(Point) * C(Point) + C(Player) * C(Point) + 1 + C(Player) + C(Player)\nC(GameScore) == 3 * 3 + 2 * 3 + 1 + 2 + 2\nC(GameScore) == 20\n```\n\nIl y a exactement 20 valeurs possibles (le code qui implémente le comportement est à la charge du lecteur 💪). Être capable de modéliser nos problèmes avec des types algébriques a l'énorme avantage de demander à ne résoudre que des valeurs possibles. Pas besoin de soucier des cas où il y aurait un score de `34 - 70` ou un score négatif. Si Haskell, et d'autres languages, permettent de simplement d'exprimer ces cas, comment utiliser ces outils dans un language comme Java ? Voyons cela ensemble.\n\n## Les types algébriques en Java\n\nIl y a plusieurs alternatives pour implémenter correctement des types algébriques. Java n'offre pas d'outils de base pour les représenter, mais on peut utiliser un type purement produits avec une seule classe comme ceci :\n\n``` java\nclass GameScore {\n  private final int scorePlayer1;\n  private final int scorePlayer2;\n  private final GameStage stage;\n\n  enum GameStage {\n    Score, GamePoint, Deuce, Advantage, Game\n  }\n}\n```\n\nLe gros désavantage de ce genre d'approche (j'ai un peu exaggéré l'exemple, on aurait pu utiliser des classes plus fines) est facilement repérable à partir d'un calcul de cardinal : `C(GameScore) = C(int) * C(int) * 5`. Dans ce cas, `C(GameScore)` est largement supérieur au cas nominatif. De plus, il est de la responsabilité des méthodes manipulant ce type de ne pas se retrouver avec une valeur `(Score, 40, 40)` alors que c'est une valeur `Deuce` qui est attendue. Et puis que faire si on se retrouver dans la valeur `(Advantage, 15, 15)`, bref la complexité de cette implémentation est, à minima, dangereuse.\n\n### Restreindre les valeurs possibles\n\nPour résoudre cela, nous allons limiter les valeurs possibles. Dans un premier temps, on peut implémenter les énumérations simples que l'on a présentées en Haskell :\n\n``` java\nenum Player { PLAYER_1, PLAYER_2 }\nenum Score { Zero, Fifteen, Thirty }\n```\n\nIl nous reste quand même le cas de l'implémentation du score à résoudre. Pour cela, on va utiliser l'outil de base des languages orientés objets : le polymorphisme ! Une implémentation d'interface pour chaque constructeur de valeur :\n\n``` java\npublic class Score implements GameScore {\n  private final Score scorePlayer1;\n  private final Score scorePlayer2;\n}\npublic class GamePoint implements GameScore {\n  private final Player gamePointPlayer;\n  private final Score otherPlayerScore;\n}\npublic class Deuce implements GameScore {}\npublic class Advantage implements GameScore {\n  public final Player forPlayer;\n}\npublic class Game implements GameScore {\n  public final Player forPlayer;\n}\n```\n\nCette implémentation se rapproche très proche de l'implémentation en Haskell. On pourrait penser que son cardinal est la même. On a utilisé les mêmes constructeur avec les mêmes valeurs ! Or ce n'est pas le cas, car Java a une valeur qui est difficile à éviter lors de l'implémentation d'une classe : la valeur `null`. Si l'on explicite cette implémentation en Haskell, elle ressemblerait plutôt à ça :\n\n``` haskell\ndata Player = Player1 | Player2 | NullPlayer\ndata GameScore\n  = Score Point Point\n  | GamePoint Player Point\n  | Deuce\n  | Advantage Player\n  | Game Player\n  | NullGameScore\n-- etc.\n```\n\nAu lieu d'un cardinal du type algébrique `GameScore` : `C(GameScore) = 20`, on se retrouve avec `C(GameScore | Java) = 36`. Il y a 16 valeurs limites pour lesquels il va falloir se prémunir. Il existe des stratégies pour mitiger ce problème : on peut ignorer ces cas et risquer des `NullPointerException`, les prévenir avec des `checkNotNull`, etc. Aucune solution n'est meilleure qu'une autre et il faut faire avec, car c'est le language lui-même (et pas notre implémentation) qui produit des valeurs limites de nos types algébriques.\n\n## Conclusion\n\nLes types algébriques sont un outil très efficace pour limiter les valeurs pour un type et donc alléger la charge mentale lors du développement d'une fonctionnalité. Les languages sont un auxiliaire à l'habilité du développeur et c'est de notre devoir de leur demander de coller au plus proche de ce que l'on souhaite exprimer.","language":"fr","shareable":false,"publication_date":"2018-02-02T18:09:50.414671+00:00","current_slug":"les-types-algbriques-pour-les-langages-orients-objet","previous_slugs":["les-types-algbriques-pour-les-languages-orients-objets"]},{"post_id":"8879cf5a-6c55-4c76-949f-d4a823b2f7d1","version":0,"title":"Happy new year of code","markdown_content":"## What happened in 2017\n\n2017 has been a rich year for me! All of those good things happened to me this year:\n\n* I have found a job at [malt](https://www.malt.fr). It's the best working environment i've experienced so far: a growing team of fantastic individuals, a motivated and welcoming team spirit. I'm super happy to contribute to the adventure!\n\n* I'm a new member of the [Lyon Tech Hub](http://www.lyontechhub.org/#!/) and the [Cara Lyon](http://lyon.clubagilerhonealpes.org), mostly organizing the Coding dojos and DDD events. Our biggest feat has been the return of the Code Retreat.\n\n* I wrote a blog post every month at least on this very blog. I didn't write compuslively, and I tried to search for my articles. Most of them are short but most likely asked a lot of research.\n\n* I have abandonned the redaction of an unusually long article on processes and threads in different languages. I worked many hours on it, and it will certainly never be published but I learned a lot on concurrency models a low level.\n\n* I have learned Purescript/Haskell basics while working on side projects. It took a lot of effort to get to a poor level, but it teached me a lot about other languages and gives me a higher point of view (and reasons to dislike javascript)\n\n## What is planned for 2018\n\nI'm writing down my resolutions here so that people can blame me next year. Pardon if I've been slacky, there must be a good reason!\n\n* I will focus on the languages I already know, this year I'll learn no other language. It's really time consuming and enriching my knowledge of Java, Ruby, Elixir, Erlang, Haskell, Purescript or Javascript is already quite some work!\n\n* I will keep on organizing and coordinating the software crafters of Lyon. We'll be more active on twitter and already prepared a good program for next year!\n\n* I will provide a new podcast for the LyonTechHub, the project is still in its infancy, but it will happen at some point!\n\n* I will write French articles on my blog. Writing English is sometimes necessary to have feedback ([my article on purescript](https://sadraskol.com/posts/my-experience-with-purescript-so-far) is a good example), but I could very well write my blog in French.\n\n* I won't stop experimenting on my blog. Some cleaning is still necessary for my old blog posts written in HTML. But I will relentlessly try new things here.\n\nHope you have the best 2018!","language":"en","shareable":false,"publication_date":"2018-01-05T16:15:51.817609+00:00","current_slug":"happy-new-year-of-code","previous_slugs":[]},{"post_id":"9e978334-374d-4ea8-bda3-fc6d0e049ee3","version":0,"title":"Response to Vjeux article on Ocaml","markdown_content":"[Vjeux](https://twitter.com/Vjeux) works on React at Facebook. He published a [small list](https://gist.github.com/vjeux/cc2c4f83a6b60d69b79057b6ef651b56) of things that he feels are bad patterns in Ocaml language. I can't have an opinion on Ocaml itself, since I don't know the language, but I disagree strongly on some point he makes about functional programming.\n\n## Naming is the most difficult thing in computer science\n\nThis famous quote by [Phil Karlton](https://skeptics.stackexchange.com/questions/19836/has-phil-karlton-ever-said-there-are-only-two-hard-things-in-computer-science) captures a lot of our job: naming things is hard, because it's the only way we have to carry meaning and intentions. Here's the example vjeux uses to critisize a bad style of writing code:\n\n```\narray.map(fn)\narray.map(x => fn(x))\n```\n\nI'm gonna stop a moment to make fun of the author: he said some lines before this snippet that:\n\n> This means that you end up with a bunch of places with inconsistent names for attributes or even worse, one letter names\n\nThe snippet of code is the worst example you could give, in vjeux's own judgement! All names in here are ambiguous, unclear, and completely obscure the argument being made:\n\n- `array`: array of...? what is in this array we'll never know\n- `fn`: a function? Does it take arguments and return a result?\n- `x`: is it unknown? why not y or z?\n\nThe issue is that the poor name does not allow to discuss the main point: passing arguments is more explicit than passing functions. How can `x => fn(x)` be more explicit than `fn`? I could say that `meanTimesToFinish.map(addToStats)` is more readeable than `array.map(x => fn(x))`, but the poor choice of example does not allow to judge.\n\nPlease name things correctly in your examples and we might discuss it in details.\n\n## Partial evaluation\n\nWhen declaring a function with multiple arguments in a functional language, what you really do is declaring a chain of functions. The equivalent in javascript is currying:\n\n```\nlet add = (left) => (right) => left + right;\n// equivalent to add(left, right) {...}\n```\n\nThis is pretty practical when you need to contextualize an operation. For instance:\n\n``` haskell\naddInDatabase database left right = in database do left + right\n-- somewhere else\nlet add = addInDatabase database\n-- use 'add' without bothering with the database anymore\n```\n\nAlthough it might be counter intuitive when the only language you know are C like, but partial application (or evaluation) is quite useful when you want to compose functions together. And that's pretty useful when composition is at the core of functional languages.\n\n## Of the lack of early return\n\nYou can use Maybe, more generally monads to stop computation when it's not needed. For instance, such a construct `heavyComputation = doALotOn Nothing`, will be compiled as a no operation, skipping the heavy computation.\n\nI'm not sure early return is needed in functional computing, once again the lack of concrete and thorough example does not allow to discuss the idea in depth.\n\n## My opinion\n\nEveryone has an opinion, and I'm not blaming Vjeux to give his. I regret that he does not provide any in depth argument and examples to illustrate his points. Sharing ideas is much more interesting when they give room to other people to discuss and eventually respond in a positive way. I feel like he didn't go far in his usage of functional languages. Here, the lack of culture makes the opinions pointless.\n\nIt might feel stupid but I feel like this lack of culture and proper documentation is the reason documents like the \"[google memo](https://en.wikipedia.org/wiki/Google%27s_Ideological_Echo_Chamber)\" do exist, a combinaison of seclusion and a false idea of sharing idea. For ideas to spread, you need to have an opinion, but not any kind of opinion, a documented one. Otherwise you will not spread ideas, but preconception, biases and false information.","language":"en","shareable":false,"publication_date":"2017-12-25T21:38:44.496623+00:00","current_slug":"response-to-vjeux-article-on-ocaml","previous_slugs":[]},{"post_id":"ee06347a-b8cb-46b2-8058-9f359f51d712","version":0,"title":"My experience with Purescript so far","markdown_content":"Purescript is a pure functional language. It is highly inspired by Haskell and compiles to javascript. I learned it on a side project (not a very serious one) and to write scripts to query our mongodb instances at [malt](https://www.malt.com). I will simply present my point of vue on the current state of the language.\n\n## Environment tools\n\nFirst off, the install and setup of the environment is straight forward. [Pulp](https://github.com/purescript-contrib/pulp) works like a charm! It is intuitive and it never went in my way. The incremental build is super fast on my machine so you can have a quick feedback on your test while you code with a simple `pulp --watch test`.\n\nThe second thing purescript excels at is documentation browsing. If you look for the documentation of the `map` function, just look up on [pursuit](https://pursuit.purescript.org/search?q=map). It's a shame that the results are weidly ordered. I would have preferred to have the `Data.Functor (map)` at the top, since it's the most common. But this is only a detail, I'm sure maintainers are aware of these sort of things and are working towards a better browsing experience.\n\nAnother nice surprise is the [Atom Ide](https://atom.io/packages/ide-purescript). If you use Atom, it offers a nice ide that take care of autocomplete or source browsing. I need to restart the plugin from time to time to synchronise it with the current state of the build. Even with this minor problem, it's impressive that such a young language has such a nice completion features. static types FTW!\n\n## Language features\n\nSpeaking of type system, Purescript is so pure that it won't allow you to use partial functions without special treatments. This pushes you to a [type driven development](http://blog.ploeh.dk/2015/08/10/type-driven-development/), which allowed me to learn a lot about the problems I was trying to solve.\n\nPurescript does not come \"batteries included\", you need to import every dependencies, even the `+` operator! I don't know why, since the static typing system allows to prune useless code easily, and tree shaking is done by default when packaging the javascript. Anyways it's a surprising feature, that isn't clearly indicated. You will have weird error messages when not importing  Prelude. Which brings us to the core pain point of Purescript: its user experience.\n\n## Purescript user experience\n\nLet's say you mistype the function `traverse` to `traversee`. In Elixir, the compiler will warn you that there's a more natural option: it will suggest methods in the context that look like your mistyping using the [jaro distance](https://hexdocs.pm/elixir/String.html#jaro_distance/2). It's a shame that the Purescript compiler does not do such things, even more because the type system would allow to suggest some very smart and elegant choices. No such explanation is given by purescript compiler.\n\nAs I mentioned earlier, forgetting to import Prelude at the start will award you some very weird messages like `(+) does not exist`. I feel like it's a pain for nothing for many reasons:\n\t\n* I don't see a case where a program won't need to use operations like `(+)`, `(<>)`, etc.\n* Even if they did not use `Prelude`, the tree shaking would make sure their package is not impacted\n* Finally, even if there would be a good reason not to import `Prelude`, why not creating specific messages to help newcomers to follow steps to understand it.\n\nPurescript leaves you alone in the jungle of its methods and functional gibberish. If you don't know what a `Monoid`, a `Foldable` or a `<$>` is, you better learn the language with tutorial first! It feels like the language wasn't build for programmers first, but for Haskell programmers with strong theorical background. Could you easily guess what's the difference between a `Semi-groupoid` and a `Monoid`?\n\nThe most representative to me is the `purescript-assert` library, when the assertion work, everything is fine. But once you get an error, here's the result:\n\n<figure>\n  <img src=\"https://s3.eu-central-1.amazonaws.com/sadraskol/purescsript-asser-error.png\"/>\n  <figcaption><i>What happened?!</i></figcaption>\n</figure>\n\nAs you can see, there's no comprehensible error message, not even the line of the error in the `.purs` test file. If you have more than one assertion in your tests, which is quite the norm, you can't know which assertion fails. Fortunately, other libraries allow to perform testing with better output. I deeply regret that basic libraries don't go in a spirit of helping the programmers. As this [tweet](https://twitter.com/chrisamaphone/status/936966525810028546) says:\n\n> Programming languages should help programmers becoming better\n\nPurescript only provides half the tools for the statement to be true.\n\n## Purescript could change\n\nPurescript is not in its stable stage yet, and most of the work is still to be provided. I have great hopes in Purescript. It offers a super nice way of doing Javascript in a safe and productive way. It's a shame it is not designed for newcomers or in an [ethic of care](https://en.wikipedia.org/wiki/Ethics_of_care).","language":"en","shareable":false,"publication_date":"2017-12-12T00:08:50+00:00","current_slug":"my-experience-with-purescript-so-far","previous_slugs":[]},{"post_id":"438e974c-981d-4886-b1ac-47d806ea6cd4","version":0,"title":"Digging in the depth of Fibonacci","markdown_content":"Not so long ago, I read an [article](http://www.drincruz.com/blog/2017/08/19/what-does-fibonacci-look-like-in-elixir) on fibonacci. I suggested a more elegant solution to my eyes, but the problem kept bogging me. Let's get into it!\n\n## The naïve recursive approach\n\nThe first implementation, which reads like the mathematical formula, looks like this:\n\n``` elixir\ndef fib(0), do: 1\ndef fib(1), do: 1\ndef fib(n), do: fib(n-1) + fib(n-2)\n```\n\nThe main issue with this implementation is that the bigger the index you calculate, the exponentially bigger is number of operation needed. To show how, let's look at the following graph of calls of the `fib(5)`:\n\n<figure>\n\t<img src=\"https://s3.eu-central-1.amazonaws.com/sadraskol/fib-recursive-bomb.png\" alt=\"Recursive Fibonacci implementation function call graph\">\n  <figcaption><i>Fig 1: Recursive Fibonacci implementation function call graph</i></figcaption>\n</figure>\n\nAs you can see `fib(2)` is calculated 3 times, which is a inefficient. The number of recursive calls of `fib` will grow exponentially as we advance in the sequence. My computer start having big problems when attempting to calculate `fib(35)`. You could even get the result before you computer, which is a pretty bad sign! Let's find another way to remove most of that calculation.\n\n## Enters memoization\n\nMemoization is an optimisation technique that speeds up algorithm by saving intermediate function calls which are used multiple times. In our case, if we calculate `fib(n)`, we'll save every `fib(i)` with `i &lt; n`.\n\nElixir is not designed to tackle this kind of optimisation, but you can find a javascript implementation [here](https://medium.com/developers-writing/fibonacci-sequence-algorithm-in-javascript-b253dc7e320e)\n\nAlthough this technique will yield much better results at a benchmark, it is not yet an optimized version of the algorithm.\n\n## Dynamic programming\n\nThe last algorithm optimization available is called dynamic programming. It seems like a complex word, and it covers a lot of techniques but in the case of Fibonacci, the algorithm is elegant and intuitive.\n\nThe first thing you have to ask yourself is: \"How would I calculate `fib(5)`?\" Let's try to make it step by step:\n\n```\nfib(2) = fib(1) + fib(0) = 1 + 1 = 2\nfib(3) = fib(2) + fib(1) = 2 + 1 = 3\nfib(4) = fib(3) + fib(2) = 3 + 2 = 5\nfib(5) = fib(4) + fib(3) = 5 + 3 = 8\n```\n\nFor each step you only used 3 explicit variables, `i`, `fib(i)`, `fib(i - 1)`, `fib(i - 2)` and an implicite one, the sequence number we calculate `n` (5 in this case). It's pretty simple to implement a function which will replicate this behavior:\n\n``` elixir\ndef fib(0), do: 1\ndef fib(1), do: 1\ndef fib(n), do: dyna_fib(1, 1, n)\n\ndef fib_step(result, _, 1), do: result\ndef fib_step(fib_i_minus_one, fib_i_minus_two, i) do\n\tfib_step(fib_i_minus_one + fib_i_minus_two, last, i - 1)\nend\n```\n\nIt's a very fast implementation, it's complexity drops to `O(n)`. This version calculates very easily the millionth element of the Fibonacci sequence!\n\n## Using Maths at our advantage\n\nAs you might know, the Fibonacci sequence is a mathematical object. Maybe maths have some interesting formulas, you can find the most interesting formula in the end of [this chapter](https://en.wikipedia.org/wiki/Fibonacci_number#Matrix_form)\n\n> Fib(2n - 1) = F(n)² + F(n - 1)²\n>\n> Fib(2n) = (2 * F(n - 1) + F(n)) * F(n)\n\nThose formulas are a huge improvement! They would allow to jump indices of the sequence by a factor of 2! This will allow to reduce the complexity to `O(log(n))`, which is quite impressive. The implementation is straight forward:\n\n``` elixir\ndef log_fib(0), do: 0\ndef log_fib(1), do: 1\ndef log_fib(2), do: 1\ndef log_fib(n) when rem(n, 2) == 1 do\n  # Fib(2n - 1) = F(n)² + F(n - 1)²\n  i = div((n + 1), 2)\n  first = log_fib(i)\n  second = log_fib(i - 1)\n  first * first + second * second\nend\ndef log_fib(n) when rem(n, 2) == 0 do\n  # Fib(2n) = (2 * F(n - 1) + F(n)) * F(n)\n  i = div(n, 2)\n  first = log_fib(i)\n  (2 * log_fib(i - 1) + first) * first\nend\n```\n\n## Using a library\n\nInstead of getting all the problems with implementing an optimized version, you should use a library that does the job for you. [Gnu MP](https://gmplib.org/manual/Number-Theoretic-Functions.html#index-mpz_005ffib_005fui) is, as far as I know, the most optimized version of Fibonacci and uses a memoized version of the `O(log(n))` recursive algorithm.\n\nI didn't think I would get so deep when starting the article. I wanted to show off with dynamic programming, but in this case it's not even the optimized version. The lesson of this article should be: always doubt on an opinion you have on a subject you don't know well. We tend to take our opinions for truth, but if we confront them to a methodological and rigorous research process, they always prove to be, at best, misleading.","language":"en","shareable":false,"publication_date":"2017-10-24T22:12:14+00:00","current_slug":"digging-in-the-depth-of-fibonacci","previous_slugs":[]},{"post_id":"54776c46-1fad-4a4b-be44-0318affec5f1","version":0,"title":"Common pattern for bash auto complete","markdown_content":"After reading [my last article](https://sadraskol.com/posts/how-to-create-a-bash-auto-complete), I was disappointed. I could have shown you how to deal with the point 1:\n\n> \\[You can\\] Suggest based on subcommands and options available to the user. This means you need to create a tree of possibilities: goat push supports --force option but goat pull does not, etc.\n\nThe first thing to discuss is the `COMP_WORDS` variable. `COMP_WORDS[0]` is always the name of the command, `goat` in our case. Also the current word to be completed `${COMP_WORDS[COMP_CWORD]}` represent at least an empty string. You can be sure that you have at least 2 string in your `COMP_WORDS` array. We'll use that at our avantage and use a `case` to complete subcommands:\n\n``` bash\n_goat() {\n  prev=${COMP_WORDS[COMP_CWORD - 1]}\n  cur=${COMP_WORDS[COMP_CWORD]}\n\n  COMPREPLY=()\n  case \"$prev\" in\n  \tgoat)\n    \tCOMPREPLY=( $( compgen -W \"log commit push pull clone add\" -- ${cur} ) )\n      return\n      ;;\n    commit)\n      case \"$cur\" in\n        -*)\n          COMPREPLY=( $( compgen -W \"--author= --edit --no-edit --amend --include --only --allow-empty\" -- ${cur} ) )\n          return\n          ;;\n      esac\n      break\n      ;;\n  esac\n  COMPREPLY=( $( compgen -f \"${cur}\" ) )\n}\n\ncomplete -F _goat goat\n```\n\nWe declared `$prev` and we are sure it equals either `goat`, a subcommand or some other string. Note that we use `compgen -f` to suggest files in current directory, like the default behavior of bash auto complete. This code would grow in complexity pretty fast if we were to add some more subcommands. Let's first gather each behavior in a function:\n\n``` bash\n__goat_commit() {\n  case \"$cur\" in\n    -*)\n      COMPREPLY=( $( compgen -W \"--author= --edit --no-edit --amend --include --only --allow-empty\" -- ${cur} ) )\n      return\n      ;;\n  esac\n  COMPREPLY=( $( compgen -f \"${cur}\" ) )\n}\n\n# Somewhere in _goat()\ncase \"$prev\" in\n  # ...\n  commit)\n  \t__goat_commit\n    return\n    ;;\nesac\n```\n\nNow the main function consist only of a giant `case`, and could be pretty good as such. But after reading the `git` usage of Bash, i've crossed a pretty smart way to make the code less brittled by the verbosity of `case` statement, the trick is a simple two-liner:\n\n``` bash\n# declaring _goat() with $prev and $cur globals\nlocal completion_func=\"__goat_${prev}\"\ndeclare -f $completion_func >/dev/null 2>/dev/null && $completion_func && return\n# default completion here\n```\n\nThe first line allow to declare the name of the function the code is going to execute. We use the same pattern that we presented in the last example: `__goat_commit`, etc. The second line can be explained in steps:\n\n1. `declare -f $completion_fun` will display the content of function `$completion_fun`\n\t* if the function exists, we forward the standard and error output in `/dev/null`\n  * otherwise, it interrupts the evaluation of the line (more info on [declare](https://www.gnu.org/software/bash/manual/html_node/Bash-Builtins.html))\n\n2. the function is evaluated\n3. we exit from the current function\n\nAlthough the technique seems like a hack, it's really nice because it allows you to add a new subcommand without modifying the main or dealing with a very verbose `case`. You have to make sure that people contributing know the convention, because it's not obvious for people not proficient in Bash.\n","language":"en","shareable":false,"publication_date":"2017-08-24T14:34:55+00:00","current_slug":"common-pattern-for-bash-auto-complete","previous_slugs":[]},{"post_id":"cd1b9e7e-a112-4bb7-8e91-167e7631ba43","version":0,"title":"How to create a bash auto complete","markdown_content":"Bash auto-complete seems pretty magic. People who use bash extensively (I'm part of them) tend to have a certain love for the `[TAB]` key! It looked mysterious to me until I implemented one for myself. I'm not proficient at Bash, but basic knowledge of [arrays](http://www.linuxjournal.com/content/bash-arrays) and `compgen` will make you king of autocomplete.\n\n## The `compgen` magic\n\nThis Bash builtin is the base of auto-completion. It takes two arguments: a list of terms, a dictionary, and an input to compare it with. It will return the list of terms in the dictionary which could match with the input. You can use it like this:\n\n```\n$ compgen -W 'init list new compile install lint' -- li\nlist lint\n$ compgen -W 'init list new compile' -- compile\ncompile\n$ compgen -W 'init list new compile' -- lists\n\n```\n\nThe options `-W` stands for words. You can find the documentation of this builtin and in `man bash` or [here](https://tiswww.case.edu/php/chet/bash/bashref.html#Programmable-Completion-Builtins).\n\n## Working on a simple example\n\nLet's say we decide to create an auto-complete functionality for `goat`, your homemade version of `git`. We would like to complete subcommands like `goat log` or `goat commit`. Firstly you'd need to create a script to let Bash know how to perform the completion. You'd write this script in `/etc/bash_completion.d/goat`.\n\nThe content would look like this:\n\n``` bash\n_goat() \n{\n    local cur opts\n    cur=\"${COMP_WORDS[COMP_CWORD]}\"\n    opts=\"log commit push pull clone add\"\n    COMPREPLY=( $(compgen -W \"${opts}\" -- ${cur}) )\n}\ncomplete -F _goat goat\n```\n\n`COMP_WORDS`, `COMP_CWORD` are variables provided by Bash respectively containing an array of each terms in the command line and the index of the word being completed (more documentation on bash internal linked with completion [here](https://devmanual.gentoo.org/tasks-reference/completion/index.html)). The selection of words suggested to the user will be taken from the `COMPREPLY` variable. Calling the `complete` builtin will allow Bash to perfom the actual completion. Here's the result:\n\n```\n$ goat [TAB]\nlog commit push pull clone add\n$ goat com[TAB]\n$ goat commit\n$ goat pu[TAB]\npush pull\n$ goat ad[TAB] some_file\n$ goat add some_file\n$ goat log [TAB]\nlog commit push pull clone add\n```\n\nAs you can see in the last attempt to complete the sentence, there is no consideration of the place in the command line you are which would do a pretty bad autocompletion feature. Plus there is no completion of options or sub commands.\n\n## Where to go from here\n\nIf you want a smarter completion feature, you'll have to:\n\n1. Suggest based on subcommands and options available to the user. This means you need to create a tree of possibilities: `goat push` supports `--force` option but `goat pull` does not, etc.\n\n2. Suggest based on the type of argument expected. For instance Git auto completion will suggest branches and remote repository when using `git push [TAB]`.\n\n3. You can even suggest files based on their types, size, content, etc.\n\nThose tasks might feel simple to achieve, but remember that you also have to deal with Bash language which is not the most elegant one. To give you an idea, `docker` has a 3k lines script to perform completion.\n\nI hope this post helped you!","language":"en","shareable":false,"publication_date":"2017-08-07T22:35:27+00:00","current_slug":"how-to-create-a-bash-auto-complete","previous_slugs":[]},{"post_id":"78f5458f-7d2d-4d7e-85e0-29f4c463b1fd","version":0,"title":"Press review #5","markdown_content":"It's been a long time i haven't written a blog post, even a press review. This is fixed now and the rate of publishing should accelerate next weeks. I gave myself some holidays, and it gave me even more ideas on things to learn. Anyway, enough with boring news on the blog, let me share my best reading lately!\n\n[100 days of algorithm](https://medium.com/100-days-of-algorithms): I've got lately into algorithm. It's an interesting field of software I have forgotten for too much time, the more I read about it, the more fascinating it is. The small subset I had time to read are really mind blowing, I hope it does help!\n\n[Project package organization](http://dolszewski.com/architecture/project-package-organization/): This article is about package organization in Java. I'm a fan of organizing package by features (as presented in the article). Even if you don't use [hexagonal architecture](http://alistair.cockburn.us/Hexagonal+architecture) or CQRS, it forces you to think within your knowledge of the domain.\n\n[Deploy Elixir app to a vps](https://www.amberbit.com/blog/2017/7/17/deploy-elixir-app-to-a-vps/): Most tutorial on deploying an Elixir application are unclear or too specific, this one is perfect. It covers the basics of the tools without sacrificing the productivity they offer.\n\n[Splitting APIs, servers, and implementations in Elixir](https://pragdave.me/blog/2017/07/13/decoupling-interface-and-implementation-in-elixir.html): This article was a revelation to me. It describes what I've been trying to put my finger on for a long time. It shows how to decouple the immutable logic of the code and the mutable code in GenServers elegantly. It's nothing super extraordinary but a really nice pattern.\n\n[Node.JS production best practices](http://goldbergyoni.com/checklist-best-practice-of-node-js-in-production/): This list is really complete and does not apply only to NodeJS. It's interesting to see the ecosystem of NodeJS growing to maturity. Security, monitoring, error management, asset management, correlation identifiers or zero downtime deployments are all subjects to consider when deploying an application, whatever technology it uses!","language":"en","shareable":false,"publication_date":"2017-07-22T09:45:32+00:00","current_slug":"press-review-5","previous_slugs":[]},{"post_id":"fb6ea073-8af2-47c4-bad8-cfb60a56c833","version":0,"title":"The survival kit for functional language beginner","markdown_content":"Functional languages like [Haskell](https://www.haskell.org), OCaml or Erlang based [Elixir](https://elixir-lang.org) are difficult to learn when you come from an imperative or object oriented languages. Concepts like immutability, high order functions or monads are very difficult to implement in classical languages (let's call them that way). Thankfully, those functional languages share a lot in common and i'll try to introduce to the most important concepts behind them.\n\nThis kit is not a learning guide, and knowing those patterns will not teach you the specifics of each langugages. The road to mastering functional languages remains a hard path to take!\n\n## Pattern Matching\n\nLet's start with the most important syntax helper from functional programming: pattern matching. Did the ruby syntax of `a b = b a` mixed your head up? Prepare some aspirin because... no, I'm joking! Pattern matching is very straight forward if you start practicing it. It allows to assign variable similarly to arithmetic equations. For instance: *(Note: example are written in Elixir or Haskell)*\n\n``` elixir\n\"hello \" <> x = \"hello world\" # x == \"world\" !!!\n```\n\n*Simple pattern matching on a string in Elixir. `<>` is the string concatenation operator*\n\nThe compiler solves the equation for you! Beware though, the comparison with maths falls short if you start writing simple \"equations\" like:\n\n``` elixir\nx + 1 = 34 # oups!\n** (CompileError) iex:3: illegal pattern\n```\n\nBut then, you might ask why is it so powerful if it cannot solve such simple equations. Patience, you'll learn how pattern matching can reveal itself very powerful along the way. The reason is that it matches the representation of the variable, it doesn't \"solve\" anything. Let's talk about the simplest pattern matching construct: `case` (`match` in some languages). It allows you to return a value based on pattern matching. Look how simple it reads:\n\n``` haskell\ncase age of\n  12  -> \"Hey! that's young!\"\n  118 -> \"No kidding?!\"\n  21  -> \"You can vote in the UK!\"\n  _   -> \"Hmm that's boring\"\n```\n\nNotice the `_` underscore notation which matches any value, you're going to see it a lot if you start learning functional languages.\n\nBut it's not over, you can also use pattern matching when declaring function arguments. As the following example:\n\n``` haskell\nstupidRemark :: Int -> String\nstupidRemark 12  = \"Hey! that's young!\"\nstupidRemark 118 = \"No kidding?!\"\nstupidRemark 21  = \"You can vote in the UK!\"\nstupidRemark _   = \"Hmm that's boring\"\n\n--later\nstupidRemark 12 -- returns \"Hey! that's sweet\"\n```\n\nThis bit of code is the exact equivalent of the following:\n\n``` haskell\nstupidRemark :: Int -> String\nstupidRemark age = case age of\n  12  -> \"Hey! that's young!\"\n  118 -> \"No kidding?!\"\n  21  -> \"You can vote in the UK!\"\n  _   -> \"Hmm that's boring\"\n```\n\nYou will see pattern matching everywhere in functional programming. It's a simple way of writing how you want to manipulate the data, but we'll come back to it later.\n\n## Guards\n\nLet's say we want to go further on those stupid remarks. We could group the remarks by age. You would have to compare the age with arbritary thresholds. Guards are the utility to do that:\n\n``` haskell\nstupidRemark :: Int -> String\nstupidRemark age\n  | age < 13            = \"Hey! that's young!\"\n  | age < 117           = \"No kidding?!\"\n  | age > 20 && odd age = \"You can vote in the UK!\"\n  | otherwise           = \"Hmm that's boring\"\n\n--later\nstupidRemark 110 -- \"Hmm that's boring\"\nstupidRemark 119 -- \"No kidding?!\"\nstupidRemark 71  -- \"You can vote in the UK!\"\n```\n\nAs you can see, guards allow to create much more complex conditions without a lot of boilerplate code. Beware though as they allow a limited number of operations, especially in Elixir. The reason you won't see guards as often as pattern matching is that they do not assign variables, they are very practical as `if` replacement.\n\n## Lists\n\nLists are a very perticular construct in functional languages. They are the opening gates to high order functions, the introduction to recursion and so on. They are very simple objects though: an ordered list of elements. We would write for instance: `[1, 2, 3, 4]`. Lists support two operations:\n\n- `head` (`hd` in Elixir) returns the first element of a non empty list, `1` in our case\n- `tail` (`tl` in Elixir) returns a list of all elements except for the first one, `[2, 3, 4]` in our case\n\nAs mentioned in their description, `head` and `tail` do not work on empty list. Why would you do that then? As such those methods are not much used. They will allow you to understand something much more useful: pattern matching on lists. A list can be constructed from its `head` (a single element) and its `tail` (the rest of the elements). In Haskell you write it:\n\n``` haskell\n(head:tail)\n```\n\nIn Elixir:\n\n``` elixir\n[head|tail]\n```\n\nAnd guess what?! You can pattern match with this syntax on lists!\n\n``` elixir\n[head|tail] = [1, 2, 3, 4]\nhead == 1\ntail == [2, 3, 4]\n```\n\nHow can we iterate on a list from what we know as far? Let's try to upper case a list of names:\n\n``` elixir\ndef uppercaseAll [], do: []\ndef uppercaseAll [head|tail], do: [String.uppercase(head) | uppercaseAll(tail)]\n\n# Here we shortcut \"String.uppercase\" to \"up\" for readability issue\nuppercaseAll [\"Fanny\", \"Eric\", \"Maïté\", \"Charles\"]\n#<=> [up(\"Fanny\") | uppercaseAll([\"Eric\", \"Maïté\", \"Charles\"])]\n#<=> [up(\"Fanny\") | [up(\"Eric\") | uppercaseAll([\"Maïté\", \"Charles\"])]]\n#<=> [up(\"Fanny\") | [up(\"Eric\") | [up(\"Maïté\") | uppercaseAll([\"Charles\"])]]]\n#<=> [up(\"Fanny\") | [up(\"Eric\") | [up(\"Maïté\") | [up(\"Charles\") | uppercaseAll([])]]]]\n#<=> [up(\"Fanny\"), up(\"Eric\"), up(\"Maïté\"), up(\"Charles\")]\n```\n\nAs you can see, we can use the `head`/`tail` to match non empty lists and an empty list for the special case. This type of coding, recursingly call the function until you have the right result is a very common pattern in functional languages. Let's see another one. This time we'll generate the length of the list:\n\n``` elixir\ndef lengthAcc(acc, []), do: acc\ndef lengthAcc(acc, [head:tail]), do: lengthAcc (acc + 1) tail\ndef length list, do: lengthAcc 0 list\n```\n\nI hope you understand better recursion in functional languages. Those pattern are so common they have utilities to write them quickly. It's out of the scope of this article, but you'll cross them when you'll learn one of those language (you might even already know `map` or `reduce` as they are now available in other languages).\n\n## Side note on immutability\n\n*This chapter is pretty low level, you don't need to read it if you trust functional languages.*\n\nI often hear that immutability will plummet performances, that it means copy on change. The reality is more complex. Immutability in the language does not mean unoptimized code: it let the compiler optimize the code. lets consider this \"mutable\" code\n\n``` elixir\nx = 127\n# somewhere in memory: (x = 127 | ...)\nx += 7 # mutate x\n# in memory (x = 134 | ...)\n```\n\nThe equivalent \"immutable\" code:\n``` elixir\nx = 127\n# (x = 127 | ...)\ny = x + 7\n# (x = 127 | y = 134 | ...) OR (y = 134 | ...) the compiler decides\n```\n\nThis is not a very representative example of course, but it introduces to the type of optimisations the compiler can perform on an immutable language. Virtually, you could even optimise concurrent computation with a full immutable and pure language (apart from obscure concurrent languages like [ANI](https://code.google.com/archive/p/anic/wikis/Tutorial.wiki)). If you thought immutability would hit your performances, it's not the case. Ocaml has very similar performance benchmark to Java in the [CLBG](http://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=ocaml&lang2=java).\n\n## Conclusion\n\nI write this article while I'm learning Haskell, and I gather here every similarities and concepts I was happy to have discovered in Elixir first. Like you i've started on introduction pages of functional languages and felt lost, like this one:\n\n<figure>\n  <img alt=\"screen shot of introduction code on ocaml website\" src=\"https://s3.eu-central-1.amazonaws.com/sadraskol/really-not-simple-ocaml.png\" />\n  <figcaption><i>Really OCaml? It's the simplest example you could pull out?!</i></figcaption>\n</figure>\n\nConcepts in functional languages are very weird and different from object oriented languages. But they should not be fear you out! I hope that with this kit you'll get yourself up and learning some functional niceties!","language":"en","shareable":false,"publication_date":"2017-07-04T20:40:19+00:00","current_slug":"the-survival-kit-for-functional-language-beginner","previous_slugs":[]},{"post_id":"d779699a-efe9-403e-8dca-c9c516cb8fea","version":0,"title":"Press review #4","markdown_content":"This week's review is so diverse! From SQL `WITH` syntax to a list of good books, you'll find everything, even a critic of \"Corporate Agile\"\n\n[arpinum/awesome](https://github.com/arpinum/awesome/wiki/Books): I think it's important to share shortlists of books and this one seem pretty good!\n\n[#NoTDD - by Eric Gunnerson](https://blogs.msdn.microsoft.com/ericgu/2017/06/22/notdd): many problems with TDD comes from the lack of design being done. This article tells how design needs to be emphasize when testing first.\n\n[Literate SQL](http://modern-sql.com/use-case/literate-sql): although I do not practice SQL daily, I find this syntax very interesting! Tell me if you use it in your requests.\n\n[Hacker News readers as Progressive Web Apps](https://hnpwa.com): This site gathers multiple version of progressive web apps. It's really an interesting starting point if you want to implement it for your own.\n\n[Why “Agile” and especially Scrum are terrible](https://michaelochurch.wordpress.com/2015/06/06/why-agile-and-especially-scrum-are-terrible): the author tends to mix up Agile and its implementation in some companies. The article is worth for it's demonstration lacking of technical excellence hurts software companies.","language":"en","shareable":false,"publication_date":"2017-06-29T13:47:31+00:00","current_slug":"press-review-4","previous_slugs":[]},{"post_id":"5b538187-58a2-47ce-a078-a8916756700d","version":0,"title":"Why null leads to bad implementations","markdown_content":"Bergson once said:\n\n> Le néant, c'est la traduction des données de notre perception dans le language de nos attentes. [source](http://sites.arte.tv/philosophie/fr/video/imaginez-le-neant)\n>\n> *The void is the translation of the data of our perception in the language of our expectations.*\n\nExpectations are wicked things to represent in a program, they are implicit, changing, immaterial and conceptual. We should instead talk about things that exist, that represent reality, and its continuous realm of possibilities.\n\nOne could say that this issue has been solved in computing systems through the implementation of types. Types characterize systems without leaving any expectation implicit. This vision, however, fails to take into consideration the infamous `null` present in nearly [every language](https://www.lucidchart.com/techblog/2015/08/31/the-worst-mistake-of-computer-science).\n\nWhat is the problem of `null` references? Let's say you implement a virtual bag of sweets. You choose to implement it in this way:\n\n``` java\nclass Bag {\n  private Sweets sweets = null;\n}\n```\n\nThis code runs the risk of throwing a `NullPointerException` somewhere. And even with a perfect test coverage and no bugs induced in some production system, this code would still be problematic.\n\nTo understand why, we need to get back to Bergson.\n\nImagine you are offered a bag of sweets, let's say some Werther's, but the bag reveals to be empty! \"There are no candies in this bag!\" you mutter. Are you really pointing out the absence of candies in the bag? Strictly speaking, you could equally point out the absence of sweets everywhere: \"There are no candies in this cup of tea!\", \"There are no candies in this Shakespeare play!\", \"There are no candies on this table!\"... No, what you are expressing is merely a disappointed expectation.\n\nTranslated in your \"expectation language\", this would read:\n\n``` java\nclass Bag {\n  private Sweets sweets = null;\n}\n```\n\nBut your perceptions did receive:\n\n``` java\nclass EmptyBag extends Bag {}\n```\n\nPolymorphism, in the form of the [special case pattern](https://martinfowler.com/eaaCatalog/specialCase.html), is a stronger choice here. It allows to avoid any `NullPointerException` or undetected behavior, and also to leverage the power of the language's compilator. It is, arguably, the best solution.\n\nWhen Tony Hoare implemented object oriented language in 1965, he argued in its favour for one reason above all, that is:\n\n> The great thing about record handling is that you don't need to have a subscript error, because you cannot construct a pointer that points to something that doesn't exist, and a whole set of errors cannot occur and do not need to be [checked at run-time](https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare).\n\nNote how he mentions the fact that objects forbids to construct something that *does not exist*. Most languages provide a easy way to do so: `null`. This is indeed a shame because it inevitably leads to bad design! Let's be affirmative in our way of describing the world as it is, and not representing our expectations of it.\n\nLet's not use `null` and assume reality.\n\n*ps: thanks to Irene for the proofreading and suggestions.*","language":"en","shareable":false,"publication_date":"2017-05-04T14:00:19+00:00","current_slug":"why-null-leads-to-bad-implementations","previous_slugs":[]},{"post_id":"62aeb6c6-0db9-480b-808d-1a35a3936f9b","version":0,"title":"Press review #3","markdown_content":"Today's press review is about mostly Linux and system toolkit. It's a rather short and technical review, so without further a do, let's go into it.\n\n[Shell scripts matter](https://dev.to/thiht/shell-scripts-matter): Bash is almost always unconsidered, this blog post learns you how to create better ones. I've been working with git hooks lately and this guide has been a great help!\n\n[ssh_config](http://man.openbsd.org/ssh_config): This one is not really a press review, it's more a discovery i made while searching the way to bookmark ssh connection. For long I used the `CTRL + R` history functionnality of the terminal, but this time is over!\n\n[Manually Throttle the Bandwidth of a Linux Network Interface](http://mark.koli.ch/slowdown-throttle-bandwidth-linux-network-interface), [Slow down your internet with tc](https://jvns.ca/blog/2017/04/01/slow-down-your-internet-with-tc), [tc: Adding simulated network latency to your Linux server](http://bencane.com/2012/07/16/tc-adding-simulated-network-latency-to-your-linux-server): not one, not two, but three article at once! They all cover the same subject: the utility `tc` for linux.\n\n[Elixir and IO Lists, Part 2: IO Lists in Phoenix](https://www.bignerdranch.com/blog/elixir-and-io-lists-part-2-io-lists-in-phoenix): A very nice explanation of why Elixir is way faster than ruby with template rendering. You might want to read the part 1 if you don't know what IO lists are in Elixir.","language":"en","shareable":false,"publication_date":"2017-04-18T21:34:09+00:00","current_slug":"press-review-3","previous_slugs":[]},{"post_id":"d38711cd-f277-4101-982f-1a5cdc948d23","version":0,"title":"Press review #2","markdown_content":"I liked writing the first press review, so i was impatient to write another one! Here it is. It revolves around user experience and more, I hope you'll like it!\n\n[Sideways dictionary](https://sidewaysdictionary.com): As they put it: \"it's like a dictionary, but using analogies instead of definitions.\" A dictonary for technology principle. It's a very well designed website, cool concept and user's suggestion can be funny. I'll let you explore it!\n\n[Improving mobile web conversions just by optimizing web forms](https://medium.com/dev-channel/improving-mobile-web-conversions-just-by-optimizing-web-forms-1d846bed42f): This one is easy to summarize: use `autocomplete` to your forms as much as you can. As promoted, it will reduce the pain for users, especially for mobile users. I'm pretty confused, because as [this tweet](https://twitter.com/anttiviljami/status/816585860661518336) showed, the autocomplete could be used to steal user's private data.\n\n[How to launch software changes without pissing people off](https://m.signalvnoise.com/how-to-launch-software-changes-without-pissing-people-off-cf79dce64630): This article seems very important to me. We tend to consider users as passive, ready for every changes. We are not. We are pissed when our habits get crambles. I don't advocate for them not to happen, rather to accompany them for a smooth transition. As Proust said:\n\n> Nous n'arrivons pas à changer les choses suivant notre désir, mais peu à peu notre désir change. **« Albertine disparue », _in_ À la recherche du temps perdu**\n\n[Blogging principles I use](http://jvns.ca/blog/2017/03/20/blogging-principles): Prolific and awesome Julia Evans produces a little and helpful zine on what to think when you blog. It's smart and honest like all her blog posts, so I highly recommend to explore more articles from her!\n\n[Créer une startup dans l’IoT : est-ce que ce monde est sérieux ?](https://www.kissmyfrogs.com/startup-iot-difficile) Once again another French article. It's all about IoT startups. Basically, it's not as easy as launching a full web startup. Having a decent hardware comes at a price which many startups and investors failed to identify when they launched. Think of it, it does not mean you are bound to fail, rather it's gonna be tougher than you think!\n\nI've created a comment section (that redirect you to my twitter or my mail) on the blog. If you like those reviews, have critics to express, i'll welcome them with pleasure!","language":"en","shareable":false,"publication_date":"2017-03-26T17:04:17+00:00","current_slug":"press-review-2","previous_slugs":[]},{"post_id":"db376f14-bd48-45f2-9a4c-424c2c96143f","version":3,"title":"The alien erlang syntax choices","markdown_content":"Some developers still argue about which punctuation is the best. Some would support the C syntax with semicolon `;` at the end of each line, something that would look like:\r\n\r\n```\r\nint main() {\r\n  int a = 6;\r\n  int b = 3;\r\n  if (a > b) // notice this line has no punctuation\r\n    printf(\"a is greater than b \\n\");\r\n  return 0;\r\n}\r\n```\r\n\r\nOthers will say the best syntax is a ruby/python-like with no punctuation. You can write in elixir (very close to ruby):\r\n\r\n```\r\ndef print_file do\r\n  # notice the punctuation in the method\r\n  File.stream!(\"scratch.txt\")\r\n  |> Enum.each(&IO.puts/1)\r\nend\r\n```\r\n\r\nAs you can notice, both school still compromise with or without punctuation when they need to. So the answer is not as simple as a yes or no. There is even a language for which learning the punctuation is rather difficult when coming from other languages: Erlang.\r\n\r\n## Punctuation in Erlang\r\n\r\nRead [this snippet taken from stackoverflow](http://stackoverflow.com/a/1112630) and try to focus on the punctuation at the end of the lines.\r\n\r\n``` erlang\r\nfoo(X) when X > 0; X > 7 ->\r\n    Y = X * 2,\r\n    case Y of\r\n        12 -> bar;\r\n        _  -> ook\r\n    end;\r\nfoo(0) -> zero.\r\n```\r\n\r\nThe answer is much clearer than me, but if you don't want to open the link, here's the explaination. There are 4 possibilities to end the lines:\r\n\r\n- The period `.` indicates the end a statement or function declaration. In the Erlang Repl, your would write `A = 1.` to execute the assignement\r\n- The comma `,` indicates an intermediary statement, like in a sentence, the statement is not the last one\r\n- The semicolon `;` indicates that the current context is close but there is another related choice available. It is used both for multiple function declarations and conditionnal statements\r\n- Finally, only for conditional statement, you can finish last statements without no punctuation at all. I find that very confusing\r\n    \r\nI think punctuation is always here in some way and there is no right or wrong in it. Erlang syntax is easier to read once you get used to it, but it's also more error prone. It's a matter of balance and personal preference here. I hope you won't blame Java and C to have constraining syntaxes anymore!","language":"en","shareable":false,"publication_date":"2017-03-21T15:11:58+00:00","current_slug":"the-alien-erlang-syntax-choices","previous_slugs":[]},{"post_id":"54949624-65ae-4dcd-b32c-1638cdb34130","version":0,"title":"Press review #1","markdown_content":"Since I have a lot of time to spend and to read various articles, I thought it would be a nice exercise to review the nice articles i find here.\n\n[Want to blog? Read this](http://pablojuan.com/want-to-blog-read-this): i'll start with the article that inspired me to write down this article. It might also inspire you if you plan on writing in your blog but don't have any idea.\n\n[Architecting Continuously Testable Systems](http://blog.mccormack.net.au/architecting-testable-systems): Managing large systems is not the most common task for developpers, but delivery management reminds us with the complexity that goes on outside of code. This article goes deep down in the architecture of one system with an emphasis on testability.\n\n[Names that Make Computers Go Crazy](https://agiletestingdays.com/blog/exclusive-excerpt-from-gojko-adzics-new-book-computer-says-no-names-that-make-computers-go-crazy): how did you configure your database for names? `varchar(255)`? This article explains how this setup is a nightmare for people like James Dr No From Russia with Love Goldfinger Thunderball You Only Live Twice On Her Majesty's Secret Service Diamonds Are Forever Live and Let Die The Man with the Golden Gun The Spy Who Loved Me Moonraker For Your Eyes Only Octopussy A View to a Kill The Living Daylights Licence to Kill Golden Eye Tomorrow Never Dies The World Is Not Enough Die Another Day Casino Royale Bond, a UK citizen!\n\n[Virtual machine escape fetches $105,000 at Pwn2Own hacking contest](https://arstechnica.com/security/2017/03/hack-that-escapes-vm-by-exploiting-edge-browser-fetches-105000-at-pwn2own): This is a sweet reminder that VM can also be hacked from the web. Security will always be harder than we think.\n\n[La performance, une norme qui ne vous veut pas que du bien](http://www.internetactu.net/2017/03/13/la-performance-une-norme-qui-ne-vous-veut-pas-que-du-bien): a last article in French (sorry english people) that covers the ideology of self performance and calls for allowing ourself to be shitty sometimes.\n\nI hope you will enjoy those readings, Talk to you later!","language":"en","shareable":false,"publication_date":"2017-03-19T20:45:27+00:00","current_slug":"press-review-1","previous_slugs":[]},{"post_id":"65b3e9fd-0c6e-4555-88d6-877543e1667b","version":0,"title":"Quick introduction to macro in Elixir","markdown_content":"When i first ran into `macro` in Elixir, i felt it was too much for me to learn on the first round. The concept seemed too stepped to digest for the moment. Immutability, pattern matching and Erlang processes are already pretty difficult to grasp when you come from utterly different environment (Java & Javascript in my case).\n\nWhat a regret i have now! Even if macros are a powerful and complex tool, you can use them to make code much more readable without having to enter the hard bits. That's what i'll try to prove you with some simple examples.\n\n## What is a macro\n\nElixir is a compiled language based on Erlang. Compilation time can be annoying, but it provides more powerful tools such as code generation through their preprocessors. This feature is called a `macro` in Elixir. When I learned C I felt this was a useless feat, but now that I've grown aware to readability and reusability in programming, thanks to Software Craftsmanship mentality, I see `macro` a very different way.\n\n`Macro` allow you to use Elixir code to generate code, which can help you design complex APIs and sleek [domain specific languages](https://en.wikipedia.org/wiki/Domain-specific_language). But with great power comes great responsabilities, and there could be some issues:\n\n- It hides information that developer might want to access to\n- It is not as easy to debug as plain code\n- Complex `macro` can inflate compilation time by a lot\n\nWe won't cover those as they are specific issues that could be very dependent on the context or subjective perception.\n\n## Our first macro\n\nLet's say I want to spell numbers literally, write `two` instead of `2` for instance. Nothing more simple:\n\n``` elixir\ndefmodule Integers.Macro do\n  defmacro two, do: 2\nend\ndefmodule Integers do\n  import Integers.Macro\n  \n  def addTwo(addend), do: two + addend\nend\n```\n\nThis example is straight forward, the final result is exactly the same as if we'd use a function. The only difference is that the expression `two` is not evaluated at runtime but at compilation.\n\nThe process of generating code is call macro expand, and the above code generates the very expected:\n\n``` elixir\ndef addTwo(addend), do: 2 + addend\n```\n\nSo far so good, as the expanded version is arguably more readable then its macro version. Let's dig in a more useful example.\n\n## A more realistic use case\n\nWhen i started this blog, I wanted to sanitize the content of my articles. Remove traces of classes, and eventually protect users from my mistakes by removing any hazardous inline scripts. The excellent [html_sanitize_ex](https://github.com/rrrene/html_sanitize_ex) provides such functionality.\n\nUnfortunately, the basic sanitizer was sanitizing more than i would like. I will cut down the part of me reading the code, it's pretty straight forward (like any Elixir code base to be honest). I ended up on the [module](https://github.com/rrrene/html_sanitize_ex/blob/v1.0.1/lib/html_sanitize_ex/scrubber/basic_html.ex) which scrubs every unwanted html tags. It has a very elegant usage of `macro`. The scubber looks like:\n\n``` elixir\n# ...\nMeta.allow_tag_with_these_attributes \"hr\", []\nMeta.allow_tag_with_these_attributes \"i\", []\n\nMeta.allow_tag_with_uri_attributes   \"img\", [\"src\"], [\"http\", \"https\"]\nMeta.allow_tag_with_these_attributes \"img\", [\"width\", \"height\", \"title\", \"alt\"]\n\nMeta.allow_tag_with_these_attributes \"li\", []\nMeta.allow_tag_with_these_attributes \"ol\", []\nMeta.allow_tag_with_these_attributes \"p\", []\n# ...\n```\n\nWhat is really nice with this way of writing is that you understand almost immediately what the code is doing. If i were to ask you to add the `iframe` to the list of allowed tag, you would probably come up with:\n\n``` elixir\nMeta.allow_tag_with_uri_attributes \"iframe\", [\"src\"], [\"http\", \"https\"]\n```\n\nMoving forward a few minutes later, I had a complete scrubber that was complying with my needs. As you already suspect it, the above snippet uses `macro` too. But before getting into how the code works, i need to explain what quote and unquoted code is in Elixir.\n\n## Quote and unquote code\n\nIf the term scare you a little, don't worry it's the only concept of the article and it's easy to grasp.\n\nLet's go back to the first snippet. Let's say that instead of generating a literal, i generate a method declaration. The following code wouldn't compile:\n\n``` elixir\ndefmodule Sadraskol.Integers.Macro do\n  defmacro def_two do\n    def two, do: 2\n  end\nend\n```\n\nInstead, you have to `quote` the method declaration. It tells the preprocessor to treat the quoted code like a a representation of the Elixir code, not a expression to compile directly. You don't understand what I've just said, me neither. The [official docs](http://elixir-lang.org/getting-started/meta/quote-and-unquote.html) explains it better than i do. The final code you want is as follows: (the code generation equivalence is inlined each time):\n\n``` elixir\ndefmodule Integers.Macro do\n  defmacro def_two do\n    quote do\n      def two, do: 2\n    end\n  end\nend\n# ...\nIntegers.Macro.def_two\n# Generates\ndef two, do: 2\n```\n\nLet's try to generalize the `add_two` with any number. The `def_add_N` `macro` would take the `base_addend` as argument and generate the according method declaration. With the information i provided you so far, you could think that the above implementation works:\n\n``` elixir\ndefmodule Integers.Macro do\n  defmacro def_add_N(base_addend) do\n    quote do\n      def add_N(addend), do: base_addend + addend\n    end\n  end\nend\n#...\nIntegers.Macro.def_add_N(2)\n# Generates\ndef add_N(addend), do: base_addend + addend\n```\n\nUnfortunately, this code generates a compilation error, `base_addend` is undefined. This is where unquoting comes into play. It will take the value of an variable outside the `quote` scope and replace it.\n\n``` elixir\ndefmodule Integers.Macro do\n  defmacro def_add_N(base_addend) do\n    quote do\n      def add_N(addend), do: unquote(base_addend) + addend\n    end\n  end\nend\n#...\nIntegers.Macro.def_add_N(2)\n# Generates\ndef add_N(addend), do: 2 + addend\n```\n\nWe could stop here but my perfectionism wants to provide you with a useless but coherent code. We can introduce another parameter `literal_name` to produce different declarations:\n\n``` elixir\ndefmodule Integers.Macro do\n  defmacro def_add_N(name, base_addend) do\n    quote do\n      def unquote(:\"add_#{name}\")(addend), do: unquote(base_addend) + addend\n    end\n  end\nend\n#...\nIntegers.Macro.def_add_N \"two\", 2\n# Generates\ndef add_two(addend), do: 2 + addend\n```\n\nWhat i used here is a little trick: in Elixir (and Erlang), all methods are identified by an `atom`, so i generate the `atom` in the unquoted code. As you can see unquoting can also be used to execute plain Elixir code within the `macro`.\n\n## Your turn to play\n\nI've exposed here all i knew about generating code with Elixir `macro`. I hope that it has motivated you to dig a bit more into the language. As a cautious developer, I would not suggest you to use macro everywhere in your code since it could severely hinders readability.\n\nOh and for the explanation of the [html_sanitize_ex](https://github.com/rrrene/html_sanitize_ex) snippet, i strongly suggest that you read the [module defining the macro](https://github.com/rrrene/html_sanitize_ex/blob/v1.0.1/lib/html_sanitize_ex/scrubber/meta.ex) 🙂</p>","language":"en","shareable":false,"publication_date":"2017-01-13T14:32:26+00:00","current_slug":"quick-introduction-to-macro-in-elixir","previous_slugs":[]},{"post_id":"5d59755a-f670-46d5-9a17-a02af197e8fc","version":0,"title":"Experimenting pushstate to boost page loading","markdown_content":"After some nice surfing on [dev.to](https://dev.to), i realized the loading of articles was blazing fast. After a little investigation, i found out they're using [instantClick](http://instantclick.io), a javascript library that speeds page display by loading content on `mouseover` event, once the user clicks on the link the content is displayed in a flash since it's already downloaded! Although i could have simply used the library, i wanted to experiment with the underlining concept: `pjax`, the contraction of `pushState` and `Ajax`.\n\nI don't need to explain `Ajax`, but `pushState` needs a little explanation. It is the DOM api that allows you to manipulate the browser history. Simply put, you can change the url without page reloading. Most frontend frameworks like angular, vuejs or react provide router library using this api under the hood. As usual, the best documentation you can get is available at [MDN](https://developer.mozilla.org/en-US/docs/Web/API/History_API).\n\n## pushState: a naive approach\n\nWhen i first read the documentation, my first thought was *\"great! it is as simple as the `location` api\"*, and i tried without any further information. The code ended up like that:\n\n``` javascript\nconst link = document.getElementById('some_link');\nlink.addEventListener('click', (e) => {\n  e.preventDefault();\n  fetch(link.href)\n  .then((response) => {\n    // modify the dom accordingly\n    history.pushState(null, null, link.href);\n  });\n});\n```\n\nProud of my new toy like a child, i tested it right away and it seemed to work properly. Okay the code isn't that clean, but if it is that easy, it would not be a problem to clean it, would it? How naive was I! The problem here is if you hit the back button or run `history.back()`. The content the page will not be restored as expected, only the url...\n\nWhat happens here? As you might have noticed, the method is not called `setNewUrlWithSomeModification`. The browser has no information on what the page content was before the url changed, `pushState` segregates content loading from url changes. In order to let us manage it, the browser will trigger a `popstate` event. In our current example with a single link, we could simply do that:\n\n``` javascript\nwindow.addEventListener('popstate', () => {\n  // recover original content\n});\n```\n\nWith this, we covered a very simplified use case of `pjax`.\n\n## A less naive approach\n\nThe case of having a single link in your web application is highly unrealistic. Let's imagine the user would browse from `/blog` to `/blog/first-article` and finally `/blog/last-article` with the current implementation. By hitting back, the user would get to the content of `/blog`, pretty embarassing.\n\nFortunately, there's a solution to that. As you might have noticed, <code>pushState</code> takes 3 arguments. I've already showed the usage of the third one: changing the url. The first argument will save our problem. MDN defines it as follows:\n\n> **state object —** The state object is a JavaScript object which is associated with the new history entry created by pushState(). Whenever the user navigates to the new state, a popstate event is fired, and the state property of the event contains a copy of the history entry's state object.\n\nYou can put whatever information is enough for you to recover the corresponding state. The following code could make it:\n\n``` javascript\nconst links = document.querySelectorAll('a');\nfor (let link of links) {\n  link.addEventListener('click', (e) => {\n    e.preventDefault();\n    fetch(link.href)\n    .then((response) => {\n      // modify the dom accordingly\n      history.pushState({href: link.href}, null, link.href);\n    });\n  });\n}\nwindow.addEventListener('popstate', (e) => {\n  if (e.state === null) {\n    // recover original content\n  } else {\n    fetch(e.state.href)\n    .then((response) => {\n      // modify the dom accordingly\n    });\n  }\n});\n```\n\nThe state saved as `{href: link.href}` is recovered whenever the history comes back and `popstate` event is triggered. The code will cover the basic of history manipulation, making sure that content and history are always coherent.\n\n## Why not using pushState explicitly\n\nI strongly recommend you to use `pjax` library or the routing functionalities of your framework. If you tried the above code, you will have experienced how imperfect it is: we don't save scroll in page navigation, the listener for `click` event intercept links opened in a new tab, if the content download takes time, there is no proper loading indication... However i do recommend you to try the api as it is fun and a small reminder of how frameworks make our lifes way easier!\n\n---\n\n*ps: if you want to go further, you can also implement a history cache instead of fetching the content at every changes.*","language":"en","shareable":false,"publication_date":"2016-12-21T14:52:18+00:00","current_slug":"experimenting-pushstate-to-boost-page-loading","previous_slugs":[]},{"post_id":"274fdc80-8d70-4824-9d01-7a734586ecd5","version":1,"title":"Developer's Proust Questionnaire","markdown_content":"<figure><img src=\"https://s3.eu-central-1.amazonaws.com/sadraskol/Marcel_Proust_1900.jpg\" alt=\"Marcel Proust\" width=\"220\" height=\"292\" /><figcaption> Marcel Proust</figcaption></figure>\r\n\r\nAfter finishing reading the *Search of Lost Time* by Marcel Proust, I desperately craved to connect it with my job. It took me a while to realize that the best way to do that is to complete a *developer's Proust questionnaire*.\r\n\r\nThe questionnaire has one goal: capture time. We have long term thoughts that we consider defining our identity. But our relationship with those thoughts change through our lifetime. Proust wrote in *Search of Lost Time* to capture and make us wonder what we've been doing all these years. I suggest you try reading this wonderful book, although i admit it is particularly hard to read.\r\n\r\nWhat do you have to do ? Simply answer the *questionnaire.* You'll look back to it In maybe 5, 10 or 15 years from now and i guarantee you that your older self will be very surprised how your younger self is (not) that stupid.\r\n\r\n## My developer's Proust questionnaire\r\n\r\n<table class=\"table is-narrow is-bordered is-striped\">\r\n<tbody>\r\n<tr>\r\n<td>Languages/environment you master</td>\r\n<td>Java, Ruby, Nodejs, Php</td>\r\n</tr>\r\n<tr>\r\n<td>Framework you master</td>\r\n<td>Ruby on rails</td>\r\n</tr>\r\n<tr>\r\n<td>Language you're interested in</td>\r\n<td>Rust, Elixir &amp; Golang</td>\r\n</tr>\r\n<tr>\r\n<td>Your favorite Guru</td>\r\n<td>Kent Beck</td>\r\n</tr>\r\n<tr>\r\n<td>The Guru you despise</td>\r\n<td>Bob Martin</td>\r\n</tr>\r\n<tr>\r\n<td>Your favorite Open source project</td>\r\n<td>Linux</td>\r\n</tr>\r\n<tr>\r\n<td>Your favorite Design pattern</td>\r\n<td>Null Object Pattern</td>\r\n</tr>\r\n<tr>\r\n<td>In the air technique you want to practice</td>\r\n<td>CQRS</td>\r\n</tr>\r\n<tr>\r\n<td>Dream job</td>\r\n<td>Software architect in a small cooperative</td>\r\n</tr>\r\n<tr>\r\n<td>Your favorite book</td>\r\n<td><a href=\"http://www.growing-object-oriented-software.com/\">Growing Object-Oriented Software Guided by Tests</a></td>\r\n</tr>\r\n<tr>\r\n<td>The information website</td>\r\n<td>Ars Technica</td>\r\n</tr>\r\n<tr>\r\n<td>The most memorable snippet of code</td>\r\n<td>\r\n<pre><code>return object.isSomething() ? Boolean.TRUE : Boolean.FALSE;</code></pre>\r\n</td>\r\n</tr>\r\n<tr>\r\n<td>The worst coding task</td>\r\n<td>Having to design user interface</td>\r\n</tr>\r\n<tr>\r\n<td>Your favorite qualities in code</td>\r\n<td>Readability</td>\r\n</tr>\r\n<tr>\r\n<td>Qualities you achieve in your code</td>\r\n<td>Testability</td>\r\n</tr>\r\n<tr>\r\n<td>Editor you use</td>\r\n<td>Atom</td>\r\n</tr>\r\n<tr>\r\n<td>Software company you admire</td>\r\n<td>Github</td>\r\n</tr>\r\n<tr>\r\n<td>What convinced you to join your current company ?</td>\r\n<td>Being surrounded with talented people</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n\r\nIf you have any suggestion or simply want to talk, you can tweet me [@sadraskol](https://twitter.com/sadraskol).","language":"en","shareable":false,"publication_date":"2016-05-17T19:58:45+00:00","current_slug":"developer-s-proust-questionnaire","previous_slugs":["developers-proust-questionnaire"]},{"post_id":"c112f021-a802-468e-a9f9-3b63ee617907","version":1,"title":"If-less game of life","markdown_content":"Let's implement an if-less [game of life](https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life). I discovered this game during a [code retreat](http://coderetreat.org) and the simplicity of its rules make it the perfect field to experiment patterns.\r\n\r\n## The rules\r\n\r\nThe game of life consists of a two dimension board filled with cells. Each cell can be either dead or alive. For simplicity sake, we'll only implement the behavior at the cell level. At each step, a cell behavior follows those 4 rules :\r\n\r\n1. Any live cell with fewer than two live neighbors dies.\r\n2. Any live cell with more than three live neighbors dies.\r\n3. Any live cell with two or three live neighbors lives on to the next generation.\r\n4. Any dead cell with exactly three live neighbors becomes a live cell.\r\n\r\nApplying those simple rules on every cell of the board and you can come up with surprising and intriguing self-generated structures.\r\n\r\n<figure><img src=\"https://s3.eu-central-1.amazonaws.com/sadraskol/2g3_fontaine.gif\" width=\"148\" height=\"121\" /><figcaption> Game of life fontain pattern</figcaption></figure>\r\n\r\nDuring a code retreat session, you have 45 minutes to craft the most beautiful code that implements the Game of Life. At the end of the 45 minutes, you drop the code and restart from scratch with a new constraints. The constraint can be \"use a different paradigm editor (vim/eclipse)\", \"only 4 lines of code per methods\" or, you guessed it \"no conditional statement\". You can find a lot more activities [here](http://coderetreat.org/group/facilitators/forum/topics/what-are-some-exercises-and-constraints-that-people-use-during-se).\r\n\r\nNow, let's dig in the coding of an if-less Game of life!\r\n\r\n## First draft\r\n\r\nLet's say that, after a first round of test-implement-refactor on all the different states of the cell, we have the following class for the cell:\r\n\r\n``` java\r\nclass Cell {\r\n private final boolean isAlive;\r\n\r\n Cell(final boolean isAlive) {\r\n   this.isAlive = isAlive;\r\n }\r\n\r\n public Cell mutate(int neighbors) {\r\n   if (neighbors &lt; 2 &amp;&amp; neighbors &gt; 3) {\r\n     return new Cell(false);\r\n   } else if (this.isAlive || (!this.isAlive &amp;&amp; neighbors == 3)) {\r\n     return new Cell(true);\r\n   } else {\r\n     return new Cell(false);\r\n   }\r\n }\r\n}\r\n```\r\n\r\nOkay the code is ugly. But hey! it's your first time and we only wanted to get familiar with the game of life \"business\". We have plenty of space for improvement so let's get started and achieve this if-less game of life. We'll first remove the boolean member of the class.\r\n\r\n### Alive and dead cells\r\n\r\nThe first concept that we can implement and that is explicit in the rules is the concept of living and dying cells. We will get rid of the boolean that hang some how in there and simplify the big *if-else if-else* conditional.\r\n\r\n``` java\r\nclass LivingCell implements Cell {\r\n  public Cell mutate(int neighbors) {\r\n    if (neighbors &lt; 2 &amp;&amp; neighbors &gt; 3) {\r\n      return new DeadCell();\r\n    } else {\r\n      return new LivingCell();\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n``` java\r\nclass DeadCell implements Cell {\r\n  public Cell mutate(int neighbors) {\r\n    if (neighbors == 3) {\r\n      return new LivingCell();\r\n    } else {\r\n      return new DeadCell();\r\n  }\r\n}\r\n```\r\n\r\nBy having more fine grained classes, we remove a level of ifs and clearly improved readability. I guess that a colleague, or the future you, would better understand what `new LivingCell()`is rather than `new Cell(true)` when reading those lines. To convince you, just read it out loud, you'll feel more natural to say that it \"returns new living cell\".\r\n\r\nBut it's not enough to achieve if-less game of life. We need to find an alternative to `int` for the concept of neighbors.\r\n\r\n### Extract concept from the rules\r\n\r\nDepending on the population surrounding the cell, it is modified. But currently, the cell decides if the population is worth living or dying. It is too much responsibilities for a single cell. So instead of passing an `int` we'll pass a `Population` and let it decide when to switch the cell state.\r\n\r\n``` java\r\nclass LivingCell implements Cell {\r\n  public Cell mutate(Population population) {\r\n    return population.mutateLivingCell();\r\n  }\r\n}\r\n```\r\n\r\n``` java\r\nclass DeadCell implements Cell {\r\n  public Cell mutate(Population population) {\r\n    return population.mutateDeadCell();\r\n  }\r\n}\r\n```\r\n\r\nOkay, there's no ifs in there but we don't go really very far, do we ? What should we do with the populations ? First let's categories them. We have three type of population:\r\n\r\n- When there is not enough neighbors or too much any cell dies. Let's call that a `DeadlyPopulation`.\r\n- The opposite case: any cell with a perfect amount (3) of neighbors will come to live whatever state it had before. Let's call that a `PerfectPopulation`.\r\n- Finally, there's a population for which any dead cell remains dead and living cells remain alive. Let's call that a `FragilePopulation`.\r\n\r\n``` java\r\nclass DeadlyPopulation implements Population {\r\n  public Cell mutateDeadCell() {\r\n    return new DeadCell();\r\n  }\r\n  public Cell mutateLivingCell() {\r\n    return new DeadCell();\r\n  }\r\n}\r\n```\r\n\r\n``` java\r\nclass PerfectPopulation implements Population {\r\n  public Cell mutateDeadCell() {\r\n    return new LivingCell();\r\n  }\r\n  public Cell mutateLivingCell() {\r\n    return new LivingCell();\r\n  }\r\n}\r\n```\r\n\r\n``` java\r\nclass FragilePopulation implements Population {\r\n  public Cell mutateDeadCell() {\r\n    return new DeadCell();\r\n  }\r\n  public Cell mutateLivingCell() {\r\n    return new LivingCell();\r\n  }\r\n}\r\n```\r\n\r\nAnd that's it! I skipped the test-refactor test to keep the code as readable as possible. But to explain quickly, I start with the `LivingCell` removing the *if* and introducing the concept of population. The tests should be red, saying that the `Population`, `DeadlyPopulation`, etc. don't exists and then implements their tests, adding their methods, implementing them. Once done it's pretty straight forward to add the `DeadCell` cases.\r\n\r\nAnd that's it, we've implemented an if-less game of life, or to be more precise the set of rules for the cell, since the board logic is nowhere to be seen.\r\n\r\n## Wrapping up\r\n\r\nWhat have we done really ? There is no conditional statement in the cells behavior now, but it does not mean that we really made them disappear from the implementation, we just *postponed* them to another class. For instance it could be the grid's responsibility to choose what kind of population is around the cell. The benefit of this postponement is that we don't have to stick with the rules, if we decide to change the *perfect* population to 6 neighbors, this piece of code would not change.\r\n\r\nOne might argue that the use of a [strategy pattern](https://en.wikipedia.org/wiki/Strategy_pattern) is over zealous in this case, could impair readability. I will not discuss if it is good or bad to use this pattern, but to knowing it gives you another tool that you can think of when encountering a problem you can't sort out.\r\n\r\nThe goal of retreat coding or other type of katas is not to make you program \"better\" but to broaden your skills. There is a nice word to describe the process of learning from constraints: *maieutics*. It comes from Socrates philosophy and means giving birth with the mind. Think of the birth of Athena: Zeus ate Metis, goddess of intelligence. After a while he felt some headaches. Hephaestus took an axe and opened the head of Zeus and so was Athena, goddess of wisdom, born. The process of eliminating conditional statements is as painful as Zeus headaches since we have to unlearn the way we are thinking to discover techniques that we already know. In our case, getting rid of booleans and conditional to implement a variation of the strategy pattern to obtain an if-less game of life.\r\n\r\n*I hoped you liked this quick and dirty presentation. I will continue writing on other patterns you can experiment implementing the game of life. If you have any questions or feedback to make, feel free to contact me on [twitter](https://twitter.com/sadraskol).*","language":"en","shareable":false,"publication_date":"2016-05-10T20:07:46+00:00","current_slug":"if-less-game-of-life","previous_slugs":["ifless-game-life"]},{"post_id":"67013fde-d337-4c96-ac0c-c73f7c0cd489","version":0,"title":"Kafka n'est pas kafkaïen","markdown_content":"*TL;DR; Utilisez kafkaïen pas « digne de Kafka », machiavélique pas « une politique proche de Machiavel »*\n\n---\n\nLa modernité et l’avènement d'internet nous pousse à écrire nos opinions de plus en plus rapidement, à les partager inlassablement, quitte à négliger nos formulations. Bien que twitter nous a quelque peu forcé à raccourcir nos phrases, à compresser notre pensée dans le plus petit espace possible, il nous arrive encore de rallonger notre texte, pensant que l'utilisation d'une phrase plus alambiquée serait le reflet d'un esprit plus vif.\n\nAinsi en est-il des journalistes qui qualifie des procès, des situations « [digne d'un roman de Kafka](https://www.google.fr/search?q=digne+d%27un+roman+de+Kafka) » (j'admets avoir perdu la référence qui m'inspire ce billet), facilité renforcée par l'origine de l'adjectif qui se trouve évidemment dans le nom de l’écrivain Pragois. « Quel malheur à utiliser ce terme ? » Pourriez vous vous demander.\n\nL'adjectif kafkaïen désigne à l'origine ce qui appartient à l'œuvre de Kafka. Par glissement, on l'utilise surtout pour « [caractériser des situations absurdes ou sans issue de la vie moderne](http://www.cnrtl.fr/definition/kafkaien) » avec une propension particulière pour les démarches administratives. L'utilisation de ce mot en dehors de tout rapport avec l'œuvre de Kafka lui a donné une indépendance, une liberté. Cette liberté a un prix : les situations qu'il décrit n'ont plus rien à voir avec les romans de Kafka.\n\nOn pourrait penser que la situation que présente génialement « Les 12 Travaux d'Astérix » dans l'épreuve de la maison des fous a tout de Kafka, l'absurdité autodestructrice de l'administration. Ce n'est pourtant pas le cas. Les héros de ses romans sont pris au piège de leurs désirs plutôt que ceux que leur impose leur environnement.\n\n<iframe src=\"https://www.youtube.com/embed/c45FtDhdDoY\" width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen=\"allowfullscreen\"></iframe>\n\nDans « Le Procès », K. est victime de de vertiges dans la salle principale du palais de justice, étouffé par l'air vicié du palais. Il manque alors un rendez-vous important qui aurait pu l'éclairer sur sa situation, rendant impossible pour lui de savoir le motif de son accusation. Plus loin dans le roman, il va préférer coucher avec l'assistante de son avocat plutôt que de « travailler » à son procès. Il va séduire l'assistante du greffier, jouer avec les enfants qui sont dans le palais. Bref, K. se distrait et évite toutes les confrontations, tous les rendez-vous que les autres personnages lui proposent et qui pourraient le sauver.\n\nDe la même façon l'arpenteur du « Château » s'éprend et épouse l'amante de l'administrateur responsable de sa situation au château. Loin de nous embarquer dans l'absurdité de l'administration, Kafka nous fait voyager dans notre propre absurdité et notre incapacité à comprendre ce qui nous entoure. Si vous voulez approfondir le sujet, je vous conseille l'écoute de [cette excellente émission](http://www.franceculture.fr/emissions/les-nouveaux-chemins-de-la-connaissance/kafka-14-le-chateau).\n\nVous comprendrez à présent la distance qui sépare les romans de Kafka et l'adjectif qui en est issu. Kafka n'est pas la seule victime de cette incompréhension, Machiavel est bien souvent confondu avec son adjectif. On confond souvent l'amoralité de son enseignement avec l'immoralité de l'action des politiques. Je vous renvoie vers mon [article sur Machiavel](https://thomas-bracher.fr/pourquoi-software-and-machiavel) pour creuser son cas.\n\nLa prochaine fois que vous voulez utiliser un mot dérivé d'un nom d'auteur, pensez-y à deux fois avant d'utiliser le nom dudit auteur en pensant faire de l'esprit, vous risquez de passer pour un snob.","language":"fr","shareable":false,"publication_date":"2016-04-26T21:28:31+00:00","current_slug":"kafka-n-est-pas-kafkaien","previous_slugs":[]},{"post_id":"c08463a5-a01e-47d2-9712-6aff68257676","version":0,"title":"Ode à l'esperluette","markdown_content":"Autrefois 27ème lettre de l'alphabet, aujourd'hui haï pour son nom et son utilisation trop commercial, la beauté de l'esperluette a peut-être trouvé refuge dans la chaleur de nos lignes de code. L'esperluette a toujours un rôle mystérieux qui convient à son apparence tourmentée, sa graphie sinueuse, emmêlée et convoluée.\n\nEn C++, l'esperluette a repris souffle. Reprenant les opérations qu'elle supportait déjà dans le simplissime C, la voilà en charge des références. Combien d'étudiants et de développeurs chevronnés auront pensé à ses belles courbes avant de déclarer un argument de fonction par référence ?\n\n<figure><img src=\"https://s3.eu-central-1.amazonaws.com/sadraskol/200px-Ampersand_(italic%2C_Adobe_Jenson).svg.png\" alt=\"Esperluette italique\" width=\"200\" height=\"167\" /><figcaption> Esperluette italique</figcaption></figure>\n\nOn peut regretter que les polices de caractère monospace ne supportent pas l'italique, nous pourrions alors apprécier sa jolie ligature. Mais devant l'évidence que ce n'est qu'un « e » et un « t » assemblés timidement, nous aurions reconnu ses origines et peut être voulu lui réserver un rôle plus évident, la confiner dans les opérations binaires et booléenne.\n\nSes confrère le « + » et le « - », cantonnés à leur signification mathématique, n'ont pas eu le destin glorieux de l'esperluette. Qui peut encore imaginer l'image du Christ mourant, le destin d'un Saint Sébastien ou le simple carrefour routier dans la croix aseptisée qui pullule dans nos codes ?\n\nSi la plupart des langages abandonne peu à peu l'utilisation de l'esperluette, nous aurons toujours le plaisir de penser à elle lorsque nous nous demandons en HTML si on doit l'accompagner avec sa contraction anglaise : `&amp;` ou si on peut garder ses élégantes arabesques intactes.","language":"fr","shareable":false,"publication_date":"2016-04-22T21:53:00+00:00","current_slug":"ode-a-lesperluette","previous_slugs":[]},{"post_id":"babc9761-25e9-42c8-9f8a-4feb1effa073","version":0,"title":"L'éthique libérale et l'esprit de l'Agile","markdown_content":"Dans son livre *L'Éthique protestante et l'esprit du capitalisme*, Max Weber a montré l'influence des courants protestants sur le développement du capitalisme dans l'Europe du 18ème siècle. Cette démarche d'archéologie des idées est très inspirante (je vous conseille l'écoute de [ce podcast](http://www.franceculture.fr/emission-les-nouveaux-chemins-de-la-connaissance-max-weber-14-la-cage-d%E2%80%99acier-du-capitalisme-2014-03) sur le sujet), nous allons nous en inspirer pour comprendre la particularité de la méthode Agile dans l'écosystème des méthodes de l'entreprise et comprendre les risques de sa propagation au delà du monde de l'entreprise.\n\n## Agile, discipline et efficacité\n\nLes valeurs de l'Agile sont avant tout des valeurs d'entreprise, rien de surprenant dans cela, c'est le domaine dans lequel l'Agile a vocation de se déployer. Parmi les douze principes de son [manifeste](http://agilemanifesto.org/iso/fr/), le premier pourrai servir de définition du capitalisme :\n\n> *Notre plus haute priorité est de satisfaire le client\n  en livrant rapidement et régulièrement des fonctionnalités\n  à grande valeur ajoutée.*\n  \nLa définition que Max Weber donne est \"[le capitalisme] repose sur l'espoir d'un profit par l'exploitation des possibilités d'échange\". Ici le client et l'entité échange de satisfaction pour de la valeur ajouté. L'Agile repose bien sur l'espoir des \"chances pacifiques de profit\". Les objets de ces concepts sont l'entreprise, son profit et celui de son client.\n\nPeu de principes parlent des individus engagés dans la production du logiciels. Seul le cinquième évoque le traitement des membres d'une équipe :\n\n> *Réalisez les projets avec des personnes motivées.\n  Fournissez-leur l’environnement et le soutien dont ils\n  ont besoin et faites-leur confiance pour atteindre les\n  objectifs fixés.*\n  \nDans le reste des principes, les individus sont réduits à leur fonction. Or la première valeur privilégiée dans l'entreprise d'après le manifeste est \"les individus et les interactions\". Mais alors comment privilégier l'individu quand celui-ci est silencieusement rappelé au plus important : la satisfaction du client. Une qualité qui est omniprésente dans la littérature Agile qui n'apparaît pourtant pas dans le manifeste est la discipline. Kent Beck l'évoque le plus explicitement dans son livre *Extreme Programming Explained: Embrace Change* : pour lui la discipline est la première qualité qui l'a frappée quand il a rencontré l'équipe de Martin Fowler (tel Proust, je cite de mémoire, corrigez moi si je me trompe).\n\nPourtant pour qu'un système s'accomplisse dans la discipline, il faut pouvoir faire régner une peur dans l'esprit des membres de l'équipe, ai-je besoin de vous rappeler le titre du blog ?! La discipline et l'ordre sont au cœur de l'objectif gouvernemental chez Machiavel, car il n'y saurait y avoir d'état dans le désordre et l'indiscipline.\n\n## Agile et le panoptique\n\nLa notion de panoptique est assez riche pour mériter son détour dans ce billet. Utilisé par le philosophe Michel Foucault dans son livre *Surveiller et Punir* pour montrer l'évolution de la justice dans les sociétés occidentales modernes, le panoptique est un dispositif architectural permettant la surveillance des individus. [L'article wikipédia](https://fr.wikipedia.org/wiki/Panoptique) explique mieux que moi le dispositif. Ce dont il faut se souvenir c'est que c'est un dispositif qui permet de voir sans être vu, ainsi le prisonnier ne peut savoir s'il est surveillé et donc est dans un état de surveillance constante. La force de ce dispositif est d'être normatif, car la surveillance étant à la fois permanente et implicite, elle oblige le détenu à se surveiller son comportement à tout moment. C'est donc un outil de surveillance générale d'une efficacité sans égal.\n\nIl est intéressant que l'Agile ait épousé des dispositifs que l'on pourrait qualifier de panoptiques. Par exemple l'utilisation de l'aménagement en open space, qui est loin d'être spécifique à l'Agile, est typiquement un environnement de normalisation par la surveillance aveugle de tout un chacun. La diminution de l'espace intime permet de mieux réduire l'individu à sa fonction.\n\nDe la même façon, l'utilisation des tableaux d'avancement Kanban est un dispositif qui, plus discrètement que l'open space, permet la normalisation des comportements par la simple possibilité que tout un chacun puisse observer l'avancement du travail de son voisin à tout moment.\n\nNotons que l'open space et le tableau Kanban ne sont pas des dispositifs panoptiques à proprement parlé, Oscar Gnouros décrit justement dans [son blog](http://www.morbleu.com/l-open-space-et-le-panoptique-le-pouvoir-et-le-travail/) que l'open space est un espace de contrôle et non un espace disciplinaire au sens où Foucault définissait le panoptique. Cette distinction a relativement peu d'importance pour l'entreprise, ce sont tout de même des espaces où peut s’exercer son pouvoir. Enfin, au crédit de l'entreprise, l'évolution vers ses outils ne lui est pas reprochable, ils servent son intérêt et s'ils sont quelque peu déshumanisants, leur objectif s'aligne avec celui de l'entreprise : l'efficacité.\n\n## Inefficacité philosophique\n\nVoici le paradoxe de l'Agile : il impose la primauté des intérêts de l'entreprise comme étant le cœur de l'activité de l'individu. Pourtant le manifeste affirme haut et fort que c'est l'auto-organisation des équipes, voire leur confort, qui permet l'émergence des \"meilleures architectures\". Il est bien clair que l'adjectif \"meilleur\" désigne ici la capacité de l'architecture à répondre aux besoins du client, pas de répondre aux besoins des individus engagés dans la réalisation de cette architecture. Une liberté de façade fait opposition à une surveillance silencieuse au nom d'une efficacité qui efface l'individu.\n\nEn concentrant tout ses objectifs sur l'efficacité, la performance, l'amélioration continue, elle en devient un outil trop moderne et peu humain. Moderne car la recherche de la performance, de l'amélioration est propre d'un temps où il n'y a plus d'Histoire et où nous nous répétons sans cesse que nous n'avons qu'une vie. Inhumaine, car pauvre philosophiquement, elle ne propose aucun chemin pour une sagesse de l'individu.\n\nForce est de reconnaître que l'Agile a donné naissance à une myriade de pratiques (le [TDD](https://en.wikipedia.org/wiki/Test-driven_development)), de méthodes (Kanban, Lean, etc.), d'outils ([Ruby on Rails](https://pragprog.com/book/rails4/agile-web-development-with-rails-4), etc.) et à une littérature d'une étendue sans précédent dans l'informatique. Au point où l'Agile déborde du cadre de l'entreprise, comme en atteste cette présentation sur [l'Agile en famille](https://www.youtube.com/watch?v=EJv6TQWgclI) ou encore la [pédagogie Agile](http://pedagogieagile.com). Je ne me permettrai pas de critiquer ces pratiques, qui n'utilise pas tant le mot Agile pour référer au manifeste du même nom mais pour signifier leur modernité et leur anti-conformisme. Je pense néanmoins qu'il faut se méfier de la tentative de pénétration d'une éthique fortement capitaliste et normalisatrice en dehors des systèmes dans lesquels elle est destinée.\n\n*Post-scriptum : [l'article du slate.fr](http://www.slate.fr/story/113619/surveiller-punir-jouir), éclaire parfaitement sur le glissement de la punition vers une surveillance plus lente et insidieuse chez Foucault.*\n\n*ps: la publication de cet article est antérieur à la création de ce blog.*","language":"fr","shareable":false,"publication_date":"2016-02-06T19:44:39+00:00","current_slug":"lethique-liberale-et-lesprit-de-lagile","previous_slugs":[]},{"post_id":"cd25b33e-f579-4c32-9177-03f6b9467295","version":2,"title":"L'argument ontologique de l'agilité","markdown_content":"L'agilité est-elle un Dieu ?\r\n\r\n> please please please before starting to write another 'what's wrong with agile' article, rename it to 'what's wrong with my organisation'\r\n>\r\n> __— Gojko Adzic (@gojkoadzic)__ [May 25, 2015](https://twitter.com/gojkoadzic/status/602855825170898945)\r\n\r\nSi j'en crois ce tweet, l'agilité n'est pas une méthode théorisée par de simples mortelles, mais est belle et bien un Dieu. Qui ne peut souffrir de reproches si ce n'est Dieu ? On appelle cela l'<a href=\"http://fr.wikipedia.org/wiki/Argument_ontologique\">argument ontologique de l'existence de Dieu</a>.\r\n\r\n\r\n## L'hégémonie de l'agilité\r\n\r\n\r\nQuel sont les autres méthodes que l'agilité ? La méthode la plus citée dans les livres est le \"waterfall\". On peut s'étonner de l'augmentation du nombre de citation de cette méthode à partir des années 2000 dans la littérature anglaise.\r\n\r\n<iframe src=\"https://books.google.com/ngrams/interactive_chart?content=Agile+manifesto%2C+waterfall+methodology&amp;case_insensitive=on&amp;year_start=1980&amp;year_end=2015&amp;corpus=15&amp;smoothing=3&amp;share=&amp;direct_url=t4%3B%2CAgile%20manifesto%3B%2Cc0%3B%2Cs0%3B%3BAgile%20Manifesto%3B%2Cc0%3B%3Bagile%20manifesto%3B%2Cc0%3B%3BAgile%20manifesto%3B%2Cc0%3B.t4%3B%2Cwaterfall%20methodology%3B%2Cc0%3B%2Cs0%3B%3Bwaterfall%20methodology%3B%2Cc0%3B%3BWaterfall%20methodology%3B%2Cc0%3B%3BWaterfall%20Methodology%3B%2Cc0\" name=\"ngram_chart\" width=\"100%\" height=\"250\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\"></iframe>\r\n\r\nQui est cet adversaire que la \"waterfall methodology\" dont la popularité\r\nsemble grandir ? Qui la théorise et qui la supporte ? La réponse se trouve\r\nà quelque clics wikipédien de là : [cette méthode n'existe pas](http://www.idinews.com/waterfall.html).\r\nIl est étonnant de voir l'agilité se donner comme un adversaire invisible,\r\nun Mal qui s'ignore pour un Dieu qui domine.\r\n\r\nIl n'est pourtant pas surprenant de trouver dans d'autres domaines la multiplicité des\r\napproches théorisées, des méthodes comparées et des ouvrages expliquant leur origine. \r\nDans le domaine du design, deux écoles se confrontent : une vision mercatique \r\n(dont Raymond Lowry est l'idéal type) et une vision humaniste (dont Jacques Viénot est le\r\nleader intellectuel). Elles ont données naissance à des méthodologies différentes et variés\r\ntrès bien présentées dans *[Le design](http://www.puf.com/Que_sais-je:Le_design)* de Stéphane\r\nVial (collection Que sais-je). Pourquoi l'informatique n'a pas d'équivalent ?\r\n\r\n## La théorie de l’ingénierie de l'informatique\r\n\r\nReprenons notre fil rouge, Machiavel. En réduisant les différentes méthodes (scrum, kanban, lean, extreme programming, etc.) à un nom unique, on les rend interchangeables, on cherche à gommer leurs différences. Or, à chaque situation sa solution. Machiavel décrit dans *Le Prince* le cas de dirigeants qui ont gardés leur pouvoir en tyrannisant leur peuple et d'autres qui ont été renversés voire tués à la demande de leur peuple. Ce n'est pas la méthode qui prouve son efficacité c'est le contexte dans lequel elle est appliquée.\r\n\r\nJe refuse de voir l'agilité comme une solution qui s'applique à tous mes problèmes, je refuse que l'agilité soit le seul outil qui me soit donné, aussi séduisant et élégant soit-il.","language":"fr","shareable":false,"publication_date":"2015-05-28T18:37:40+00:00","current_slug":"l-argument-ontologique-de-l-agilite","previous_slugs":["largument-ontologique-de-lagilite"]},{"post_id":"ab82e7ce-bdd9-4150-9cd6-d7e8c0634ca2","version":0,"title":"Pourquoi Software & Machiavel ?","markdown_content":"J'écris ce blog pour rassembler mes idées, abouties ou non, sur la programmation, le développement logiciel, mon travail en somme, en regard de mes lectures.\n\n## Pourquoi Machiavel ?\n\nRien de surprenant que Machiavel soit une source d'inspiration transcendant la politique ou le militaire, ce n'est pas tant le contenu de son oeuvre qui soit digne d'intérêt, mais sa méthode. En ignorant sciemment l'éducation chrétienne moralisante de ses lecteurs, il a produit une une analyse de la situation politique de son époque en des termes nouveaux ouvrant la voie à une science politique délivrée de la morale.\n\nC'est cette position amorale (et non immorale) que je vais essayer de conserver tout au long du blog et ainsi dépasser les positions simplificatrices.\n\n## La morale de la science\n\nMais si les vertus morales de la chrétienté sont faciles à définir, car institutionnalisées par l'Eglise, quelles sont les morales dont il faudrait se méfier dans le développement logiciel ? Aidons-nous d'un autre penseur, admirateur de Machiavel parmi d'autres : Nietzsche. Celui qui affirma que \"Dieu est mort\", ne fustigeait pas pour autant une perte de religiosité de l'occident, bien au contraire, il détestait les morales qui tombent du Ciel mais aussi la morale de la science ([Plus d'info ici](https://www.youtube.com/watch?v=Y68mGbvZZZg&amp;index=4&amp;list=PLghL9V9QTN0jve4SE0fs33K1VEoXyL-Mn)\">).\n\nEn effet, comment ne pas remarquer la morale de la Science, qui est élevée comme vérité absolue. Je vous renvoie à cette vidéo, qui comprend bien des approximations (philosophiques, non scientifiques), qui illustre à merveille les propos de Nietzsche :\n\n<iframe src=\"https://www.youtube.com/embed/6WQ9sqIHBCA\" width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen=\"allowfullscreen\"></iframe>\n\nJe cite la conclusion de l'expérience (passage de 4:59 à 5:10 dans la vidéo) :\n\n> [...] alors dans ces conditions je vois pas comment on peut dire que le libre-arbitre existe, si avant même que j'aie décidé de bouger le type qui regarde l'IRM, il sait quand je vais me bouger et il sait si je vais bouger ma main droite ou ma main gauche [...]\n\nCette manière de montrer que le déterminisme montre que le déterminisme est vérité, alors qu'il ne s'agit que d'un modèle pour mieux appréhender le monde, on se retrouve dans le cadre d'une religion. Les scientifiques sont les moines, les commentateurs les prêtres et ce que la sainte science affirme est vérité absolue. Je tiens, avant que l'on critique mon argumentaire très peu fourni, à noter la simplification de la problématique du choix qui dans de nombreuses vidéos de vulgarisation scientifique se limite à l'expression \"Le cerveau, il ...\" comme si notre personne était toute entière dans le cerveau, comme si le \"moi\", complexe et indéfinissable, et le modèle scientifique du cerveau comme centre de décision étaient confondus.\n\n## La morale du développement informatique\n\nIl est facile de reconnaître les sources de la morale informatique. N'utilisons-nous pas le terme de Gourou pour désigner ceux que nous vénérons ? dissimulant à peine notre rapport religieux avec les penseurs de l'informatique. Oublions le code \"clean\", le développeur \"agile\", arrêtons de nous émerveiller devant la \"beauté\" des pattern. Allons au-delà du bien et du mal et embrassons le code machiavélique !\n\nEn espérant que vous apprécierez les articles qui le composeront, que vous me pardonnerez mes provocations, je vous souhaite la bienvenue sur mon blog !","language":"fr","shareable":false,"publication_date":"2015-05-19T16:18:06+00:00","current_slug":"pourquoi-software-and-machiavel","previous_slugs":[]}]